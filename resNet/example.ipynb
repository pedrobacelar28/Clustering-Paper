{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([16, 12, 2560])\n",
      "Output shape: torch.Size([16, 2])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model import ECG_ResNeXt\n",
    "\n",
    "# Function to process the ECG data before feeding it into the model\n",
    "def get_inputs(device, ecg_batch, apply=\"non_zero\", signal_crop_len=2560):\n",
    "    # Process ECG data\n",
    "    if ecg_batch.shape[1] > ecg_batch.shape[2]:\n",
    "        ecg_batch = ecg_batch.permute(0, 2, 1)\n",
    "    B, n_leads, signal_len = ecg_batch.shape\n",
    "\n",
    "    if apply == \"non_zero\":\n",
    "        transformed_ecg = torch.zeros(B, n_leads, signal_crop_len)\n",
    "        for b in range(B):\n",
    "            # Infer signal_non_zero_start dynamically for each ECG\n",
    "            start = torch.nonzero(ecg_batch[b, :, :], as_tuple=False)\n",
    "            if start.nelement() == 0:\n",
    "                start = 0\n",
    "            else:\n",
    "                start = start[0, 1].item()\n",
    "            \n",
    "            end = start + signal_crop_len\n",
    "            # Adjust start and end if end exceeds signal_len\n",
    "            if end > signal_len:\n",
    "                end = signal_len\n",
    "                start = end - signal_crop_len\n",
    "                if start < 0:\n",
    "                    start = 0\n",
    "\n",
    "            for l in range(n_leads):\n",
    "                transformed_ecg[b, l, :] = ecg_batch[b, l, start:end]\n",
    "    else:\n",
    "        transformed_ecg = ecg_batch\n",
    "\n",
    "    return transformed_ecg.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model parameters\n",
    "n_classes = 2\n",
    "num_blocks = 3\n",
    "channels = [64, 128, 192, 256]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the ECG_ResNeXt model and move it to the device\n",
    "model = ECG_ResNeXt(n_classes=n_classes, num_blocks=num_blocks, channels=channels).to(device)\n",
    "\n",
    "# Generate a random ECG signal (batch size of 16, 12 leads, signal length of 4096)\n",
    "batch_size = 16\n",
    "signal_len = 4096\n",
    "n_leads = 12\n",
    "\n",
    "# Create a random ECG signal\n",
    "ecg_batch = torch.randn(batch_size, n_leads, signal_len).to(device)\n",
    "\n",
    "# Process the ECG batch using the get_inputs function\n",
    "processed_ecg = get_inputs(device, ecg_batch, signal_crop_len=2560)\n",
    "\n",
    "# Perform a forward pass\n",
    "logits = model(processed_ecg)\n",
    "\n",
    "# Print the input shape and output shape\n",
    "print(f\"Input shape: {processed_ecg.shape}\")\n",
    "print(f\"Output shape: {logits.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas ecg_normal_linhas: 5352\n",
      "Número de linhas ecg_doente_linhas: 3219\n",
      "Tirando Interferência:\n",
      "Número de linhas ecg_normal_linhas: 5259\n",
      "Número de linhas ecg_doente_linhas: 3146\n",
      "Número de ecgs pra clusterizar: 1000\n",
      "Número de ecgs pra clusterizar: 1000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#CARREGAR OS DADOS\n",
    "caminho_arquivo = \"../Projeto/Database/exams.csv\"\n",
    "dados = pd.read_csv(caminho_arquivo)\n",
    "arquivos_usados = [\"exams_part2.hdf5\", \"exams_part3.hdf5\", \"exams_par4.hdf5\", \"exams_part5.hdf5\",\n",
    "                   \"exams_part6.hdf5\", \"exams_part7.hdf5\", \"exams_par8.hdf5\", \"exams_part9.hdf5\",\n",
    "                   \"exams_part10.hdf5\", \"exams_part11.hdf5\", \"exams_part12.hdf5\", \"exams_part13.hdf5\", \n",
    "                   \"exams_part14.hdf5\", \"exams_part15.hdf5\", \"exams_part16.hdf5\", \"exams_part17.hdf5\"]\n",
    "\n",
    "ecg_normal_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados))  & \n",
    "                                (dados.iloc[:, 14].isin(arquivos_usados)) & \n",
    "                                (dados.iloc[:, 4] == False) & \n",
    "                                (dados.iloc[:, 5] == False) & \n",
    "                                (dados.iloc[:, 6] == False) & \n",
    "                                (dados.iloc[:, 7] == False) & \n",
    "                                (dados.iloc[:, 8] == True) & \n",
    "                                (dados.iloc[:, 9] == False)]\n",
    "\n",
    "ecg_doente_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) & \n",
    "                                (dados.iloc[:, 4] == True) & \n",
    "                                (dados.iloc[:, 5] == False) & \n",
    "                                (dados.iloc[:, 6] == False) & \n",
    "                                (dados.iloc[:, 7] == False) & \n",
    "                                (dados.iloc[:, 8] == False) & \n",
    "                                (dados.iloc[:, 9] == False)]\n",
    "\n",
    "print(\"Número de linhas ecg_normal_linhas:\", len(ecg_normal_linhas))\n",
    "print(\"Número de linhas ecg_doente_linhas:\", len(ecg_doente_linhas))\n",
    "\n",
    "caminho_interferencias = \"../Projeto/Database/resultados_interferencia.csv\"\n",
    "interferencias = pd.read_csv(caminho_interferencias)\n",
    "interferencias_ids = interferencias['exam_id'].tolist()\n",
    "\n",
    "ecg_normal_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                (dados.iloc[:, 14].isin(arquivos_usados))  & \n",
    "                                (dados.iloc[:, 14].isin(arquivos_usados)) & \n",
    "                                (dados.iloc[:, 4] == False) & \n",
    "                                (dados.iloc[:, 5] == False) & \n",
    "                                (dados.iloc[:, 6] == False) & \n",
    "                                (dados.iloc[:, 7] == False) & \n",
    "                                (dados.iloc[:, 8] == True) & \n",
    "                                (dados.iloc[:, 9] == False)]\n",
    "\n",
    "ecg_doente_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                (dados.iloc[:, 14].isin(arquivos_usados)) & \n",
    "                                (dados.iloc[:, 4] == True) & \n",
    "                                (dados.iloc[:, 5] == False) & \n",
    "                                (dados.iloc[:, 6] == False) & \n",
    "                                (dados.iloc[:, 7] == False) & \n",
    "                                (dados.iloc[:, 8] == False) & \n",
    "                                (dados.iloc[:, 9] == False)]\n",
    "\n",
    "print(\"Tirando Interferência:\")\n",
    "print(\"Número de linhas ecg_normal_linhas:\", len(ecg_normal_linhas))\n",
    "print(\"Número de linhas ecg_doente_linhas:\", len(ecg_doente_linhas))\n",
    "\n",
    "ecg_doente_id = dados.iloc[ecg_doente_linhas, 0].tolist()\n",
    "ecg_normal_id = dados.iloc[ecg_normal_linhas, 0].tolist()\n",
    "\n",
    "#ecg_doente = ecg_doente_id[]\n",
    "ecg_normal = ecg_normal_id[:500]\n",
    "\n",
    "ids_ecgs= ecg_doente_id[:500] + ecg_normal\n",
    "print(\"Número de ecgs pra clusterizar:\", len(ids_ecgs))\n",
    "\n",
    "y_doente = [1] * len(ecg_doente_id[:500])  # Rótulo 1 para os doentes\n",
    "y_normal = [0] * len(ecg_normal[:500])     # Rótulo 0 para os normais\n",
    "\n",
    "# Concatena os labels\n",
    "Y = y_doente + y_normal\n",
    "\n",
    "print(\"Número de ecgs pra clusterizar:\", len(Y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de ecgs que eram pra ser processados: 1000\n",
      "Número total de traçados processados: 1000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import h5py\n",
    "#X\n",
    "\n",
    "arquivos_hdf5 = [\"../Projeto/Database/filtered_exams_2_3.hdf5\",  \"../Projeto/Database/filtered_exams_4_5.hdf5\",\n",
    "                 \"../Projeto/Database/filtered_exams_6_7.hdf5\",  \"../Projeto/Database/filtered_exams_8_9.hdf5\",\n",
    "                 \"../Projeto/Database/filtered_exams_10_11.hdf5\",  \"../Projeto/Database/filtered_exams_12_13.hdf5\",\n",
    "                 \"../Projeto/Database/filtered_exams_14_15.hdf5\", \"../Projeto/Database/filtered_exams_16_17.hdf5\"]\n",
    "\n",
    "def get_ecg_data(file_path, exam_id):\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        # Obter os IDs dos exames\n",
    "        exam_ids = np.array(f['exam_id'])\n",
    "\n",
    "        # Encontrar o índice correspondente ao exam_id de interesse\n",
    "        exam_index = np.where(exam_ids == exam_id)[0]\n",
    "\n",
    "        if len(exam_index) == 0:\n",
    "            raise ValueError(\"Exam ID não encontrado.\")\n",
    "        else:\n",
    "            exam_index = exam_index[0]\n",
    "            # Acessar os tracings de ECG correspondentes ao exam_index\n",
    "            exam_tracings = f['tracings'][exam_index]\n",
    "            # Preencher tracings nulos com epsilon\n",
    "            return exam_tracings\n",
    "\n",
    "exam_ids_to_cluster = ids_ecgs  # Substitua pelos IDs reais dos exames\n",
    "\n",
    "# Lista para armazenar todos os tracings de ECG\n",
    "all_tracings = []\n",
    "\n",
    "# Obter os tracings de ECG para cada exam_id e armazenar na lista\n",
    "for exam_id in exam_ids_to_cluster:\n",
    "    found = False  # Sinalizador para verificar se o exame foi encontrado em algum arquivo\n",
    "    for arquivo in arquivos_hdf5:\n",
    "        try:\n",
    "            tracings = get_ecg_data(arquivo, exam_id)\n",
    "            if tracings is not None:\n",
    "                tracing_transposto = np.array(tracings).T\n",
    "                all_tracings.append(tracing_transposto)\n",
    "                found = True  # Sinalizador para indicar que o exame foi encontrado\n",
    "                break  # Se encontrou, não precisa continuar buscando nos outros arquivos\n",
    "        except ValueError as e:\n",
    "            i = 0\n",
    "        except Exception as e:\n",
    "            i = 0\n",
    "    \n",
    "    if not found:\n",
    "        print(f\"Erro: exame ID {exam_id} não encontrado em nenhum dos arquivos.\")\n",
    "\n",
    "# Verifique o tamanho da lista all_tracings para garantir que os dados foram coletados corretamente\n",
    "print(\"Número de ecgs que eram pra ser processados:\", len(ids_ecgs))\n",
    "print(f\"Número total de traçados processados: {len(all_tracings)}\")\n",
    "\n",
    "# X será um array com um único array dentro, contendo todos os números do tracings.T\n",
    "X = np.array(all_tracings)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 520.8836\n",
      "Epoch [2/5], Loss: 394.6088\n",
      "Epoch [3/5], Loss: 761.9548\n",
      "Epoch [4/5], Loss: 212.4404\n",
      "Epoch [5/5], Loss: 259.2702\n",
      "Test Accuracy: 0.6100\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize model parameters\n",
    "n_classes = 2\n",
    "num_blocks = 3\n",
    "channels = [64, 128, 192, 256]\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the ECG_ResNeXt model and move it to the device\n",
    "model = ECG_ResNeXt(n_classes=n_classes, num_blocks=num_blocks, channels=channels).to(device)\n",
    "\n",
    "# Create random ECG signals and labels\n",
    "batch_size = 1000\n",
    "signal_len = 4096\n",
    "n_leads = 12\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)  # Converte X em um tensor de ponto flutuante\n",
    "Y = torch.tensor(Y, dtype=torch.long)     # Converte Y em um tensor de labels inteiros\n",
    "\n",
    "\n",
    "\n",
    "X = get_inputs(device, X, signal_crop_len=2560)\n",
    "# Split dataset into training (80%) and testing (20%)\n",
    "train_size = int(0.9 * len(X))\n",
    "test_size = len(X) - train_size\n",
    "train_dataset, test_dataset = random_split(TensorDataset(X, Y), [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Simplified training loop\n",
    "n_epochs = 5  # Reduzi o número de épocas para agilizar o treinamento\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()  # Modo de treinamento\n",
    "    train_loss = 0.0\n",
    "    for ecg_batch, labels in train_loader:\n",
    "        ecg_batch, labels = ecg_batch.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(ecg_batch)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{n_epochs}], Loss: {train_loss/len(train_loader):.4f}\")\n",
    "\n",
    "# Simplified evaluation (no detailed metrics, just accuracy)\n",
    "model.eval()  # Modo de avaliação\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():  # Desativa cálculo de gradientes para acelerar\n",
    "    for ecg_batch, labels in test_loader:\n",
    "        ecg_batch, labels = ecg_batch.to(device), labels.to(device)\n",
    "        outputs = model(ecg_batch)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.append(preds.cpu())\n",
    "        all_labels.append(labels.cpu())\n",
    "\n",
    "all_preds = torch.cat(all_preds)\n",
    "all_labels = torch.cat(all_labels)\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
