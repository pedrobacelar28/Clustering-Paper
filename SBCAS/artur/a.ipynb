{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "import random\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.datasets import KarateClub\n",
    "from torch_geometric.utils import to_networkx # Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import Linear                   # Define layers\n",
    "from torch_geometric.nn import GCNConv\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.ndimage import gaussian_filter1d \n",
    "import pywt # pip install PyWavelets\n",
    "from scipy.signal import medfilt\n",
    "import cv2 # pip install opencv-python  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARREGAR OS DADOS\n",
    "\n",
    "def carregar_ecgs(unlabel, umdavb, rbbb, lbbb, sb, st, af, filtrado):\n",
    "\n",
    "    caminho_arquivo = \"../../Projeto/Database/exams.csv\"\n",
    "    dados = pd.read_csv(caminho_arquivo)\n",
    "    arquivos_usados = [\"exams_part0.hdf5\", \"exams_part1.hdf5\",\n",
    "                    \"exams_part2.hdf5\", \"exams_part3.hdf5\", \"exams_par4.hdf5\", \"exams_part5.hdf5\",\n",
    "                    \"exams_part6.hdf5\", \"exams_part7.hdf5\", \"exams_par8.hdf5\", \"exams_part9.hdf5\",\n",
    "                    \"exams_part10.hdf5\", \"exams_part11.hdf5\", \"exams_part12.hdf5\", \"exams_part13.hdf5\", \n",
    "                    \"exams_part14.hdf5\", \"exams_part15.hdf5\", \"exams_part16.hdf5\", \"exams_part17.hdf5\"]\n",
    "\n",
    "    ecg_normal_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) ]\n",
    "    \n",
    "    ecg_umdavb_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == True) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_rbbb_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == True) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_lbbb_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == True) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_sb_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == True) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_st_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == True) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_af_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == True) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Número de linhas ecg_normal_linhas:\", len(ecg_normal_linhas))\n",
    "    print(\"Número de linhas ecg_umdavb_linhas:\", len(ecg_umdavb_linhas))\n",
    "    print(\"Número de linhas ecg_rbbb_linhas:\", len(ecg_rbbb_linhas))\n",
    "    print(\"Número de linhas ecg_lbbb_linhas:\", len(ecg_lbbb_linhas))\n",
    "    print(\"Número de linhas ecg_sb_linhas:\", len(ecg_sb_linhas))\n",
    "    print(\"Número de linhas ecg_st_linhas:\", len(ecg_st_linhas))\n",
    "    print(\"Número de linhas ecg_af_linhas:\", len(ecg_af_linhas))\n",
    "\n",
    "    caminho_interferencias = \"../../Projeto/Database/resultados_interferencia.csv\"\n",
    "    interferencias = pd.read_csv(caminho_interferencias)\n",
    "    interferencias_ids = interferencias['exam_id'].tolist()\n",
    "\n",
    "    ecg_normal_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) ]\n",
    "    \n",
    "    ecg_umdavb_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == True) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_rbbb_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == True) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_lbbb_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == True) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_sb_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == True) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_st_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == True) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_af_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == True) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "\n",
    "    print(\"Tirando Interferência:\")\n",
    "    print(\"Número de linhas ecg_normal_linhas:\", len(ecg_normal_linhas))\n",
    "    print(\"Número de linhas ecg_umdavb_linhas:\", len(ecg_umdavb_linhas))\n",
    "    print(\"Número de linhas ecg_rbbb_linhas:\", len(ecg_rbbb_linhas))\n",
    "    print(\"Número de linhas ecg_lbbb_linhas:\", len(ecg_lbbb_linhas))\n",
    "    print(\"Número de linhas ecg_sb_linhas:\", len(ecg_sb_linhas))\n",
    "    print(\"Número de linhas ecg_st_linhas:\", len(ecg_st_linhas))\n",
    "    print(\"Número de linhas ecg_af_linhas:\", len(ecg_af_linhas))\n",
    "\n",
    "    ecg_normal_id = dados.iloc[ecg_normal_linhas, 0].tolist()\n",
    "    ecg_umdavb_id = dados.iloc[ecg_umdavb_linhas, 0].tolist()\n",
    "    ecg_rbbb_id = dados.iloc[ecg_rbbb_linhas, 0].tolist()\n",
    "    ecg_lbbb_id = dados.iloc[ecg_lbbb_linhas, 0].tolist()\n",
    "    ecg_sb_id = dados.iloc[ecg_sb_linhas, 0].tolist()\n",
    "    ecg_st_id = dados.iloc[ecg_st_linhas, 0].tolist()\n",
    "    ecg_af_id = dados.iloc[ecg_af_linhas, 0].tolist()\n",
    "\n",
    "    random.seed(42) \n",
    "\n",
    "    ecg_normal_sample = random.sample(ecg_normal_id, unlabel) if len(ecg_normal_id) >= unlabel else ecg_normal_id\n",
    "    ecg_umdavb_sample = random.sample(ecg_umdavb_id, umdavb) if len(ecg_umdavb_id) >= umdavb else ecg_umdavb_id\n",
    "    ecg_rbbb_sample = random.sample(ecg_rbbb_id, rbbb) if len(ecg_rbbb_id) >= rbbb else ecg_rbbb_id\n",
    "    ecg_lbbb_sample = random.sample(ecg_lbbb_id, lbbb) if len(ecg_lbbb_id) >= lbbb else ecg_lbbb_id\n",
    "    ecg_sb_sample = random.sample(ecg_sb_id, sb) if len(ecg_sb_id) >= sb else ecg_sb_id\n",
    "    ecg_st_sample = random.sample(ecg_st_id, st) if len(ecg_st_id) >= st else ecg_st_id\n",
    "    ecg_af_sample = random.sample(ecg_af_id, af) if len(ecg_af_id) >= af else ecg_af_id\n",
    "\n",
    "    ids_ecgs = ecg_normal_sample + ecg_umdavb_sample + ecg_rbbb_sample + ecg_lbbb_sample + ecg_sb_sample + ecg_st_sample + ecg_af_sample\n",
    "\n",
    "    print(\"Número de ecgs pra usar:\", len(ids_ecgs))\n",
    "\n",
    "    \n",
    "    if filtrado == True: arquivos_hdf5 = [\"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_0_1.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_2_3.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_4_5.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_6_7.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_8_9.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_10_11.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_12_13.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_14_15.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_16_17.hdf5\"]\n",
    "    \n",
    "    else: arquivos_hdf5 = ['/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part0.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part1.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part2.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part3.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part4.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part5.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part6.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part7.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part8.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part9.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part10.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part11.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part12.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part13.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part14.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part15.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part16.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part17.hdf5']\n",
    "        \n",
    "    \n",
    "\n",
    "    def get_ecg_data(file_path, exam_id):\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            # Obter os IDs dos exames\n",
    "            exam_ids = np.array(f['exam_id'])\n",
    "\n",
    "            # Encontrar o índice correspondente ao exam_id de interesse\n",
    "            exam_index = np.where(exam_ids == exam_id)[0]\n",
    "\n",
    "            if len(exam_index) == 0:\n",
    "                raise ValueError(\"Exam ID não encontrado.\")\n",
    "            else:\n",
    "                exam_index = exam_index[0]\n",
    "                # Acessar os tracings de ECG correspondentes ao exam_index\n",
    "                exam_tracings = f['tracings'][exam_index]\n",
    "                # Preencher tracings nulos com epsilon\n",
    "                return exam_tracings\n",
    "\n",
    "    exam_ids_to_cluster = ids_ecgs  # Substitua pelos IDs reais dos exames\n",
    "\n",
    "    # Lista para armazenar todos os tracings de ECG\n",
    "    all_tracings = []\n",
    "\n",
    "    # Obter os tracings de ECG para cada exam_id e armazenar na lista\n",
    "    for exam_id in exam_ids_to_cluster:\n",
    "        found = False  # Sinalizador para verificar se o exame foi encontrado em algum arquivo\n",
    "        for arquivo in arquivos_hdf5:\n",
    "            try:\n",
    "                tracings = get_ecg_data(arquivo, exam_id)\n",
    "                if tracings is not None:\n",
    "                    tracing_transposto = np.array(tracings).T\n",
    "                    all_tracings.append(tracing_transposto)\n",
    "                    found = True  # Sinalizador para indicar que o exame foi encontrado\n",
    "                    break  # Se encontrou, não precisa continuar buscando nos outros arquivos\n",
    "            except ValueError as e:\n",
    "                i = 0\n",
    "            except Exception as e:\n",
    "                i = 0\n",
    "        \n",
    "        if not found:\n",
    "            print(f\"Erro: exame ID {exam_id} não encontrado em nenhum dos arquivos.\")\n",
    "\n",
    "    # Verifique o tamanho da lista all_tracings para garantir que os dados foram coletados corretamente\n",
    "    print(\"Número de ecgs que eram pra ser processados:\", len(ids_ecgs))\n",
    "    print(f\"Número total de traçados processados: {len(all_tracings)}\")\n",
    "\n",
    "    # X será um array com um único array dentro, contendo todos os números do tracings.T\n",
    "    X = np.array(all_tracings)\n",
    "    return X , ids_ecgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas ecg_normal_linhas: 272407\n",
      "Número de linhas ecg_umdavb_linhas: 3735\n",
      "Número de linhas ecg_rbbb_linhas: 6808\n",
      "Número de linhas ecg_lbbb_linhas: 4176\n",
      "Número de linhas ecg_sb_linhas: 4300\n",
      "Número de linhas ecg_st_linhas: 6146\n",
      "Número de linhas ecg_af_linhas: 4964\n",
      "Tirando Interferência:\n",
      "Número de linhas ecg_normal_linhas: 252167\n",
      "Número de linhas ecg_umdavb_linhas: 3651\n",
      "Número de linhas ecg_rbbb_linhas: 6703\n",
      "Número de linhas ecg_lbbb_linhas: 4122\n",
      "Número de linhas ecg_sb_linhas: 4248\n",
      "Número de linhas ecg_st_linhas: 6038\n",
      "Número de linhas ecg_af_linhas: 4804\n",
      "Número de ecgs pra usar: 70\n",
      "Número de ecgs que eram pra ser processados: 70\n",
      "Número total de traçados processados: 70\n"
     ]
    }
   ],
   "source": [
    "X, ids_ecgs = carregar_ecgs(unlabel=10,umdavb=10,rbbb=10,lbbb=10,sb=10,st=10,af=10,filtrado=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão dos dados carregados: (70, 12, 4096)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensão dos dados carregados:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_my_dataset(X, unlabel=10,umdavb=10,rbbb=10,lbbb=10,sb=10,st=10,af=10,train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Prepara o dataset de ECG para o treinamento.\n",
    "    \n",
    "    Parâmetros:\n",
    "      - X: array de ECG (formato: [n_samples, n_channels, length])\n",
    "      - os números de amostras por classe (deve coincidir com a ordem de concatenação na função carregar_ecgs)\n",
    "      - train_ratio: proporção dos dados para treinamento\n",
    "      \n",
    "    Retorna:\n",
    "      - X (possivelmente normalizado),\n",
    "      - y: vetor de labels (0: normal, 1: umdavb, 2: rbbb, 3: lbbb, 4: sb, 5: st, 6: af)\n",
    "      - train_idx: índices de treinamento\n",
    "      - test_idx: índices de teste\n",
    "    \"\"\"\n",
    "    \n",
    "    total_samples = unlabel + umdavb + rbbb + lbbb + sb + st + af\n",
    "    if X.shape[0] != total_samples:\n",
    "        raise ValueError(f\"O número de traçados em X ({X.shape[0]}) não corresponde à soma esperada ({total_samples}).\")\n",
    "    \n",
    "    # Cria os labels de acordo com a ordem de concatenação\n",
    "    y = np.array([0]*unlabel + \n",
    "                 [1]*umdavb + \n",
    "                 [2]*rbbb + \n",
    "                 [3]*lbbb + \n",
    "                 [4]*sb + \n",
    "                 [5]*st + \n",
    "                 [6]*af)\n",
    "    \n",
    "    # Aqui assumimos que a normalização é feita sobre o último eixo (tempo)\n",
    "    X_norm = X.copy().astype(np.float32)\n",
    "    for i in range(X_norm.shape[0]):\n",
    "        # Evita divisão por zero\n",
    "        mean_val = X_norm[i].mean()\n",
    "        std_val = X_norm[i].std() if X_norm[i].std() != 0 else 1.0\n",
    "        X_norm[i] = (X_norm[i] - mean_val) / std_val\n",
    "    \n",
    "    # Cria a divisão em treinamento e teste (shuffle dos índices)\n",
    "    indices = np.arange(total_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(train_ratio * total_samples)\n",
    "    train_idx = indices[:split]\n",
    "    test_idx = indices[split:]\n",
    "    \n",
    "    return X_norm, y, train_idx, test_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "import torch.utils.data\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "class SimTSCTrainer:\n",
    "    def __init__(self, device, logger):\n",
    "        self.device = device\n",
    "        self.logger = logger\n",
    "        self.tmp_dir = 'tmp'\n",
    "        if not os.path.exists(self.tmp_dir):\n",
    "            os.makedirs(self.tmp_dir)\n",
    "\n",
    "    def fit(self, model, X, y, train_idx, distances, K, alpha, test_idx=None, report_test=False, batch_size=128, epochs=500):\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "\n",
    "        train_batch_size = min(batch_size//2, len(train_idx))\n",
    "        other_idx = np.array([i for i in range(len(X)) if i not in train_idx])\n",
    "        other_batch_size = min(batch_size - train_batch_size, len(other_idx))\n",
    "        train_dataset = Dataset(train_idx)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "        if report_test and test_idx is not None:\n",
    "            test_batch_size = min(batch_size//2, len(test_idx))\n",
    "            other_idx_test = np.array([i for i in range(len(X)) if i not in test_idx])\n",
    "            other_batch_size_test = min(batch_size - test_batch_size, len(other_idx_test))\n",
    "            test_dataset = Dataset(test_idx)\n",
    "            test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "        self.adj = torch.from_numpy(distances.astype(np.float32))\n",
    "        self.X, self.y = torch.from_numpy(X), torch.from_numpy(y)\n",
    "        file_path = os.path.join(self.tmp_dir, str(uuid.uuid4()))\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=4e-3)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            for sampled_train_idx in train_loader:\n",
    "                sampled_other_idx = np.random.choice(other_idx, other_batch_size, replace=False)\n",
    "                idx = np.concatenate((sampled_train_idx, sampled_other_idx))\n",
    "                _X = self.X[idx].to(self.device)\n",
    "                _y = self.y[sampled_train_idx].to(self.device)\n",
    "                _adj = self.adj[idx][:, idx]\n",
    "                outputs = model(_X, _adj, K, alpha)\n",
    "                loss = F.nll_loss(outputs[:len(sampled_train_idx)], _y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            acc = compute_accuracy(\n",
    "                model, self.X, self.y, self.adj, self.K, self.alpha,\n",
    "                train_loader, self.device, other_idx, other_batch_size\n",
    "            )\n",
    "            \n",
    "            # --------------------------------------------------------------------------\n",
    "            # ADIÇÃO DO F1 SCORE: cálculo do F1 para o conjunto de treinamento\n",
    "            # --------------------------------------------------------------------------\n",
    "            f1 = compute_f1(\n",
    "                model, self.X, self.y, self.adj, self.K, self.alpha,\n",
    "                train_loader, self.device, other_idx, other_batch_size\n",
    "            )\n",
    "\n",
    "            if acc >= best_acc:\n",
    "                best_acc = acc\n",
    "                torch.save(model.state_dict(), file_path)\n",
    "\n",
    "            if report_test and test_idx is not None:\n",
    "                test_acc = compute_accuracy(\n",
    "                    model, self.X, self.y, self.adj, self.K, self.alpha,\n",
    "                    test_loader, self.device, other_idx_test, other_batch_size_test\n",
    "                )\n",
    "                \n",
    "                # ----------------------------------------------------------------------\n",
    "                # ADIÇÃO DO F1 SCORE: cálculo do F1 para o conjunto de teste\n",
    "                # ----------------------------------------------------------------------\n",
    "                test_f1 = compute_f1(\n",
    "                    model, self.X, self.y, self.adj, self.K, self.alpha,\n",
    "                    test_loader, self.device, other_idx_test, other_batch_size_test\n",
    "                )\n",
    "\n",
    "                self.logger.log('--> Epoch {}: loss {:5.4f}; accuracy: {:5.4f}; best accuracy: {:5.4f}; test accuracy: {:5.4f}'.format(\n",
    "                    epoch, loss.item(), acc, best_acc, test_acc\n",
    "                ))\n",
    "                # Log separado do F1 Score (não alteramos a linha existente; apenas adicionamos)\n",
    "                self.logger.log('----> F1: {:5.4f}; Test F1: {:5.4f}'.format(f1, test_f1))\n",
    "\n",
    "            else:\n",
    "                self.logger.log('--> Epoch {}: loss {:5.4f}; accuracy: {:5.4f}; best accuracy: {:5.4f}'.format(\n",
    "                    epoch, loss.item(), acc, best_acc\n",
    "                ))\n",
    "                # Log separado do F1 Score\n",
    "                self.logger.log('----> F1: {:5.4f}'.format(f1))\n",
    "\n",
    "        model.load_state_dict(torch.load(file_path))\n",
    "        model.eval()\n",
    "        os.remove(file_path)\n",
    "        return model\n",
    "\n",
    "    def test(self, model, test_idx, batch_size=128):\n",
    "        test_batch_size = min(batch_size//2, len(test_idx))\n",
    "        other_idx_test = np.array([i for i in range(len(self.X)) if i not in test_idx])\n",
    "        other_batch_size_test = min(batch_size - test_batch_size, len(other_idx_test))\n",
    "        test_dataset = Dataset(test_idx)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True, num_workers=1)\n",
    "        acc = compute_accuracy(\n",
    "            model, self.X, self.y, self.adj, self.K, self.alpha,\n",
    "            test_loader, self.device, other_idx_test, other_batch_size_test\n",
    "        )\n",
    "        \n",
    "        # --------------------------------------------------------------------------\n",
    "        # ADIÇÃO DO F1 SCORE: cálculo do F1 no teste (apenas informado aqui)\n",
    "        # --------------------------------------------------------------------------\n",
    "        f1 = compute_f1(\n",
    "            model, self.X, self.y, self.adj, self.K, self.alpha,\n",
    "            test_loader, self.device, other_idx_test, other_batch_size_test\n",
    "        )\n",
    "\n",
    "        # Se quiser logar aqui, poderia adicionar algo como:\n",
    "        # self.logger.log(f'Test F1: {f1:.4f}')\n",
    "        \n",
    "        return acc.item()\n",
    "\n",
    "def compute_accuracy(model, X, y, adj, K, alpha, loader, device, other_idx, other_batch_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in loader:\n",
    "            sampled_other_idx = np.random.choice(other_idx, other_batch_size, replace=False)\n",
    "            idx = np.concatenate((batch_idx, sampled_other_idx))\n",
    "            _X = X[idx].to(device)\n",
    "            _y = y[idx][:len(batch_idx)].to(device)\n",
    "            _adj = adj[idx][:, idx]\n",
    "            outputs = model(_X, _adj, K, alpha)\n",
    "            preds = outputs[:len(batch_idx)].max(1)[1].type_as(_y)\n",
    "            _correct = preds.eq(_y).double()\n",
    "            correct += _correct.sum()\n",
    "            total += len(batch_idx)\n",
    "    acc = correct / total\n",
    "    return acc\n",
    "\n",
    "def compute_f1(model, X, y, adj, K, alpha, loader, device, other_idx, other_batch_size):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in loader:\n",
    "            sampled_other_idx = np.random.choice(other_idx, other_batch_size, replace=False)\n",
    "            idx = np.concatenate((batch_idx, sampled_other_idx))\n",
    "            _X = X[idx].to(device)\n",
    "            _y = y[idx][:len(batch_idx)].to(device)\n",
    "            _adj = adj[idx][:, idx]\n",
    "            outputs = model(_X, _adj, K, alpha)\n",
    "            preds = outputs[:len(batch_idx)].max(1)[1]\n",
    "            all_preds.extend(preds.cpu().numpy().tolist())\n",
    "            all_labels.extend(_y.cpu().numpy().tolist())\n",
    "    # Usamos 'macro' por ser comum em multi-classes (pode ajustar se preferir)\n",
    "    return f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "def compute_loss(model, X, y, adj, K, alpha, test_idx, device, batch_size=128):\n",
    "    criterion = nn.NLLLoss()\n",
    "    total_loss = 0.0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # Converter para tensores do PyTorch\n",
    "    X = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "    y = torch.tensor(y, dtype=torch.long, device=device)\n",
    "    adj = torch.tensor(adj, dtype=torch.float32, device=device)\n",
    "    \n",
    "    test_dataset = Dataset(test_idx)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx in test_loader:\n",
    "            _X = X[batch_idx]\n",
    "            _y = y[batch_idx]\n",
    "            _adj = adj[batch_idx][:, batch_idx]\n",
    "            outputs = model(_X, _adj, K, alpha)\n",
    "            loss = criterion(outputs, _y)\n",
    "            total_loss += loss.item() * len(batch_idx)\n",
    "            total_samples += len(batch_idx)\n",
    "    \n",
    "    return total_loss / total_samples\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def compute_f1_per_class(model, X, y, adj, K, alpha, test_idx, device, batch_size=128):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    # Converter para tensores do PyTorch\n",
    "    X = torch.tensor(X, dtype=torch.float32, device=device)\n",
    "    y = torch.tensor(y, dtype=torch.long, device=device)\n",
    "    adj = torch.tensor(adj, dtype=torch.float32, device=device)\n",
    "    \n",
    "    test_dataset = Dataset(test_idx)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=1)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx in test_loader:\n",
    "            _X = X[batch_idx]\n",
    "            _y = y[batch_idx]\n",
    "            _adj = adj[batch_idx][:, batch_idx]\n",
    "            outputs = model(_X, _adj, K, alpha)\n",
    "            preds = outputs.max(1)[1]\n",
    "            all_preds.extend(preds.cpu().numpy().tolist())\n",
    "            all_labels.extend(_y.cpu().numpy().tolist())\n",
    "    \n",
    "    f1_per_class = f1_score(all_labels, all_preds, average=None)  # F1 por classe\n",
    "    f1_macro = f1_score(all_labels, all_preds, average='macro')  # F1 macro\n",
    "    return f1_per_class, f1_macro\n",
    "\n",
    "class SimTSC(nn.Module):\n",
    "    def __init__(self, input_size, nb_classes, num_layers=1, n_feature_maps=64, dropout=0.5):\n",
    "        super(SimTSC, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.block_1 = ResNetBlock(input_size, n_feature_maps)\n",
    "        self.block_2 = ResNetBlock(n_feature_maps, n_feature_maps)\n",
    "        self.block_3 = ResNetBlock(n_feature_maps, n_feature_maps)\n",
    "        if self.num_layers == 1:\n",
    "            self.gc1 = GraphConvolution(n_feature_maps, nb_classes)\n",
    "        elif self.num_layers == 2:\n",
    "            self.gc1 = GraphConvolution(n_feature_maps, n_feature_maps)\n",
    "            self.gc2 = GraphConvolution(n_feature_maps, nb_classes)\n",
    "            self.dropout = dropout\n",
    "        elif self.num_layers == 3:\n",
    "            self.gc1 = GraphConvolution(n_feature_maps, n_feature_maps)\n",
    "            self.gc2 = GraphConvolution(n_feature_maps, n_feature_maps)\n",
    "            self.gc3 = GraphConvolution(n_feature_maps, nb_classes)\n",
    "            self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj, K, alpha):\n",
    "        ranks = torch.argsort(adj, dim=1)\n",
    "        sparse_index = [[], []]\n",
    "        sparse_value = []\n",
    "        for i in range(len(adj)):\n",
    "            _sparse_value = []\n",
    "            for j in ranks[i][:K]:\n",
    "                sparse_index[0].append(i)\n",
    "                sparse_index[1].append(j)\n",
    "                _sparse_value.append(1/np.exp(alpha*adj[i][j]))\n",
    "            _sparse_value = np.array(_sparse_value)\n",
    "            _sparse_value /= _sparse_value.sum()\n",
    "            sparse_value.extend(_sparse_value.tolist())\n",
    "        sparse_index = torch.LongTensor(sparse_index)\n",
    "        sparse_value = torch.FloatTensor(sparse_value)\n",
    "        adj = torch.sparse.FloatTensor(sparse_index, sparse_value, adj.size())\n",
    "        device = self.gc1.bias.device\n",
    "        adj = adj.to(device)\n",
    "\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1]).squeeze()\n",
    "\n",
    "        if self.num_layers == 1:\n",
    "            x = self.gc1(x, adj)\n",
    "        elif self.num_layers == 2:\n",
    "            x = F.relu(self.gc1(x, adj))\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = self.gc2(x, adj)\n",
    "        elif self.num_layers == 3:\n",
    "            x = F.relu(self.gc1(x, adj))\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = F.relu(self.gc2(x, adj))\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = self.gc3(x, adj)\n",
    "\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "class GraphConvolution(Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(0))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.expand = True if in_channels < out_channels else False\n",
    "        self.conv_x = nn.Conv1d(in_channels, out_channels, 7, padding=3)\n",
    "        self.bn_x = nn.BatchNorm1d(out_channels)\n",
    "        self.conv_y = nn.Conv1d(out_channels, out_channels, 5, padding=2)\n",
    "        self.bn_y = nn.BatchNorm1d(out_channels)\n",
    "        self.conv_z = nn.Conv1d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn_z = nn.BatchNorm1d(out_channels)\n",
    "        if self.expand:\n",
    "            self.shortcut_y = nn.Conv1d(in_channels, out_channels, 1)\n",
    "        self.bn_shortcut_y = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn_x(self.conv_x(x)))\n",
    "        out = F.relu(self.bn_y(self.conv_y(out)))\n",
    "        out = self.bn_z(self.conv_z(out))\n",
    "        if self.expand:\n",
    "            x = self.shortcut_y(x)\n",
    "        x = self.bn_shortcut_y(x)\n",
    "        out += x\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, idx):\n",
    "        self.idx = idx\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.idx[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Dispositivo de treinamento: cuda:0\n",
      "Calculando matriz DTW com paralelismo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculando DTW:   0%|          | 0/70 [00:00<?, ?linha/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculando DTW: 100%|██████████| 70/70 [00:00<00:00, 79.41linha/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cálculo DTW finalizado em 0.01 minutos.\n",
      "Iniciando o treinamento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3682582/1336770480.py:260: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:651.)\n",
      "  adj = torch.sparse.FloatTensor(sparse_index, sparse_value, adj.size())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Epoch 0: loss 1.9746; accuracy: 0.1071; best accuracy: 0.1071; test accuracy: 0.2857\n",
      "----> F1: 0.0276; Test F1: 0.0741\n",
      "--> Epoch 1: loss 1.9380; accuracy: 0.1071; best accuracy: 0.1071; test accuracy: 0.2857\n",
      "----> F1: 0.0276; Test F1: 0.0741\n",
      "--> Epoch 2: loss 1.9037; accuracy: 0.1071; best accuracy: 0.1071; test accuracy: 0.2857\n",
      "----> F1: 0.0276; Test F1: 0.0741\n",
      "--> Epoch 3: loss 1.8720; accuracy: 0.1071; best accuracy: 0.1071; test accuracy: 0.2857\n",
      "----> F1: 0.0276; Test F1: 0.0741\n",
      "--> Epoch 4: loss 1.8427; accuracy: 0.1071; best accuracy: 0.1071; test accuracy: 0.2857\n",
      "----> F1: 0.0276; Test F1: 0.0741\n",
      "--> Epoch 5: loss 1.8153; accuracy: 0.1071; best accuracy: 0.1071; test accuracy: 0.2857\n",
      "----> F1: 0.0276; Test F1: 0.0741\n",
      "--> Epoch 6: loss 1.7896; accuracy: 0.1071; best accuracy: 0.1071; test accuracy: 0.2857\n",
      "----> F1: 0.0276; Test F1: 0.0741\n",
      "--> Epoch 7: loss 1.7652; accuracy: 0.1071; best accuracy: 0.1071; test accuracy: 0.2857\n",
      "----> F1: 0.0276; Test F1: 0.0741\n",
      "--> Epoch 8: loss 1.7420; accuracy: 0.1071; best accuracy: 0.1071; test accuracy: 0.2857\n",
      "----> F1: 0.0276; Test F1: 0.0741\n",
      "--> Epoch 9: loss 1.7197; accuracy: 0.1071; best accuracy: 0.1071; test accuracy: 0.2857\n",
      "----> F1: 0.0276; Test F1: 0.0741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3682582/1336770480.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(file_path))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 132\u001b[0m\n\u001b[1;32m    129\u001b[0m X_norm \u001b[38;5;241m=\u001b[39m X_norm\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)  \n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Treinamento\u001b[39;00m\n\u001b[0;32m--> 132\u001b[0m model, test_accuracy, test_loss, f1_per_class, f1_macro \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_norm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m    135\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_accuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFinal test loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[7], line 42\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(X, y, train_idx, test_idx, distances, device, K, alpha, epochs)\u001b[0m\n\u001b[1;32m     35\u001b[0m model \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     36\u001b[0m     model, X, y, train_idx, distances, \n\u001b[1;32m     37\u001b[0m     K, alpha, test_idx\u001b[38;5;241m=\u001b[39mtest_idx, \n\u001b[1;32m     38\u001b[0m     report_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, epochs\u001b[38;5;241m=\u001b[39mepochs\n\u001b[1;32m     39\u001b[0m )\n\u001b[1;32m     41\u001b[0m acc \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtest(model, test_idx)\n\u001b[0;32m---> 42\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdistances\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m f1_per_class, f1_macro \u001b[38;5;241m=\u001b[39m compute_f1_per_class(model, X, y, distances, K, alpha, test_idx, device)\n\u001b[1;32m     45\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--> Test Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00macc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 190\u001b[0m, in \u001b[0;36mcompute_loss\u001b[0;34m(model, X, y, adj, K, alpha, test_idx, device, batch_size)\u001b[0m\n\u001b[1;32m    188\u001b[0m _y \u001b[38;5;241m=\u001b[39m y[batch_idx]\n\u001b[1;32m    189\u001b[0m _adj \u001b[38;5;241m=\u001b[39m adj[batch_idx][:, batch_idx]\n\u001b[0;32m--> 190\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_adj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    191\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, _y)\n\u001b[1;32m    192\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_idx)\n",
      "File \u001b[0;32m~/miniconda3/envs/ECG/lib/python3.11/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/ECG/lib/python3.11/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[6], line 254\u001b[0m, in \u001b[0;36mSimTSC.forward\u001b[0;34m(self, x, adj, K, alpha)\u001b[0m\n\u001b[1;32m    252\u001b[0m     sparse_index[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[1;32m    253\u001b[0m     sparse_index[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(j)\n\u001b[0;32m--> 254\u001b[0m     _sparse_value\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43madj\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    255\u001b[0m _sparse_value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(_sparse_value)\n\u001b[1;32m    256\u001b[0m _sparse_value \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m _sparse_value\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/miniconda3/envs/ECG/lib/python3.11/site-packages/torch/_tensor.py:1149\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m__array__, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1150\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from dtaidistance import dtw\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "        \n",
    "    def log(self, content):\n",
    "        print(content)\n",
    "        self.f.write(content + '\\n')\n",
    "        self.f.flush()\n",
    "\n",
    "def train_model(X, y, train_idx, test_idx, distances, device, K=3, alpha=0.3, epochs=50):\n",
    "    nb_classes = len(np.unique(y))\n",
    "    input_size = X.shape[1]\n",
    "    \n",
    "    model = SimTSC(input_size, nb_classes)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    log_dir = './logs'\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "        \n",
    "    log_path = os.path.join(log_dir, 'simtsc_ecg_log.txt')\n",
    "    with open(log_path, 'w') as f:\n",
    "        logger = Logger(f)\n",
    "        trainer = SimTSCTrainer(device, logger)\n",
    "        \n",
    "        print(\"Iniciando o treinamento...\")\n",
    "        model = trainer.fit(\n",
    "            model, X, y, train_idx, distances, \n",
    "            K, alpha, test_idx=test_idx, \n",
    "            report_test=True, epochs=epochs\n",
    "        )\n",
    "        \n",
    "        acc = trainer.test(model, test_idx)\n",
    "        loss = compute_loss(model, X, y, distances, K, alpha, test_idx, device)\n",
    "        f1_per_class, f1_macro = compute_f1_per_class(model, X, y, distances, K, alpha, test_idx, device)\n",
    "        \n",
    "        logger.log(f'--> Test Accuracy: {acc:.4f}')\n",
    "        logger.log(f'--> Test Loss: {loss:.4f}')\n",
    "        \n",
    "        class_labels = ['1dAVb', 'RBBB', 'LBBB', 'SB', 'ST', 'AF', 'normal']\n",
    "        \n",
    "        logger.log('\\nF1 Score por classe:')\n",
    "        for label, f1 in zip(class_labels, f1_per_class):\n",
    "            logger.log(f'{label}: {f1:.4f}')\n",
    "        \n",
    "        logger.log(f'\\nF1 Macro: {f1_macro:.4f}')\n",
    "    \n",
    "    return model, acc, loss, f1_per_class, f1_macro\n",
    "\n",
    "\n",
    "def process_i(i, X_single, n_samples, r):\n",
    "    \"\"\"\n",
    "    Processa a linha i da matriz de distâncias DTW de forma paralela.\n",
    "    \"\"\"\n",
    "    local_row = np.ascontiguousarray(X_single[i], dtype=np.float64).copy()\n",
    "    local_row.setflags(write=True)  # Garante que é mutável\n",
    "    \n",
    "    dists = []\n",
    "    for j in range(i, n_samples):\n",
    "        target = np.ascontiguousarray(X_single[j], dtype=np.float64).copy()\n",
    "        target.setflags(write=True)  # Garante que é mutável\n",
    "        \n",
    "        dist = dtw.distance_fast(local_row, target, window=r)\n",
    "        dists.append(dist)\n",
    "    \n",
    "    return i, dists\n",
    "\n",
    "def get_dtw_for_ecg_parallel(X, r=100, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Calcula a matriz de distâncias DTW usando paralelismo para acelerar a computação.\n",
    "    \n",
    "    Parâmetros:\n",
    "        X (numpy array): Dados de entrada (shape: [n amostras, canais, comprimento da série]).\n",
    "        r (int): Janela de restrição para o cálculo DTW.\n",
    "        n_jobs (int): Número de núcleos para paralelismo (-1 usa todos disponíveis).\n",
    "    \n",
    "    Retorna:\n",
    "        distances (numpy array): Matriz de distâncias DTW simétrica.\n",
    "    \"\"\"\n",
    "    # Garante que os dados estão no formato correto e mutáveis\n",
    "    X_single = np.asarray(X[:, 0, :], dtype=np.float64).copy()\n",
    "    X_single.setflags(write=True)\n",
    "    \n",
    "    n_samples = X_single.shape[0]\n",
    "    distances = np.zeros((n_samples, n_samples), dtype=np.float64)\n",
    "\n",
    "    print(\"Calculando matriz DTW com paralelismo...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Inicializa a barra de progresso\n",
    "    with tqdm(total=n_samples, desc=\"Calculando DTW\", unit=\"linha\") as pbar:\n",
    "        results = Parallel(n_jobs=n_jobs, backend=\"loky\", return_as=\"generator\")(\n",
    "            delayed(process_i)(i, X_single, n_samples, r) \n",
    "            for i in range(n_samples)\n",
    "        )\n",
    "\n",
    "        # Atualiza a barra de progresso enquanto preenche a matriz\n",
    "        for i, dists in results:\n",
    "            j_indices = np.arange(i, n_samples)\n",
    "            distances[i, j_indices] = dists\n",
    "            distances[j_indices, i] = dists  # Garante simetria\n",
    "            pbar.update(1)  # Atualiza a barra de progresso após cada linha processada\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"\\nCálculo DTW finalizado em {elapsed_time / 60:.2f} minutos.\")\n",
    "\n",
    "    return distances\n",
    "\n",
    "# Configuração do dispositivo\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"--> Dispositivo de treinamento: {device}\")\n",
    "\n",
    "# Pré-processamento com tipos corretos\n",
    "X_norm, y, train_idx, test_idx = get_my_dataset(X)\n",
    "X_norm = X_norm.astype(np.float64).copy()  # Mantém mutável para DTW\n",
    "\n",
    "# Cálculo DTW com paralelismo e barra de progresso\n",
    "distances = get_dtw_for_ecg_parallel(X_norm)\n",
    "\n",
    "# Treinamento (converter para float32 apenas se necessário pelo modelo)\n",
    "X_norm = X_norm.astype(np.float32)  \n",
    "\n",
    "# Treinamento\n",
    "model, test_accuracy, test_loss, f1_per_class, f1_macro = train_model(\n",
    "    X_norm, y, train_idx, test_idx, \n",
    "    distances, device, K=3, alpha=0.3, epochs=10\n",
    ")\n",
    "\n",
    "print(f\"Final accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Final test loss: {test_loss:.4f}\")\n",
    "print(\"F1 Score por classe:\")\n",
    "class_labels = ['1dAVb', 'RBBB', 'LBBB', 'SB', 'ST', 'AF', 'normal']\n",
    "for label, f1 in zip(class_labels, f1_per_class):\n",
    "    print(f\"{label}: {f1:.4f}\")\n",
    "print(f\"\\nF1 Macro: {f1_macro:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "def plot_accuracy(log_path):\n",
    "    epochs = []\n",
    "    accuracies = []\n",
    "    \n",
    "    epoch_pattern = re.compile(r'--> Epoch (\\d+): .* accuracy: ([\\d\\.]+);')\n",
    "    \n",
    "    with open(log_path, 'r') as f:\n",
    "        for line in f:\n",
    "            match = epoch_pattern.search(line)\n",
    "            if match:\n",
    "                epoch = int(match.group(1))\n",
    "                acc = float(match.group(2))\n",
    "                epochs.append(epoch)\n",
    "                accuracies.append(acc)\n",
    "    \n",
    "    if not epochs:\n",
    "        print(\"Nenhum dado de acurácia encontrado no log.\")\n",
    "        return\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(epochs, accuracies, linestyle='-', label='Training Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Training Accuracy Over Epochs')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "# Caminho do arquivo de log\n",
    "log_path = './logs/simtsc_ecg_log.txt'\n",
    "plot_accuracy(log_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
