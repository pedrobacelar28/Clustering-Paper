{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "import random\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.datasets import KarateClub\n",
    "from torch_geometric.utils import to_networkx # Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import Linear                   # Define layers\n",
    "from torch_geometric.nn import GCNConv\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.ndimage import gaussian_filter1d \n",
    "import pywt # pip install PyWavelets\n",
    "from scipy.signal import medfilt\n",
    "import cv2 # pip install opencv-python  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARREGAR OS DADOS\n",
    "\n",
    "def carregar_ecgs(unlabel, umdavb, rbbb, lbbb, sb, st, af, filtrado):\n",
    "\n",
    "    caminho_arquivo = \"../../Projeto/Database/exams.csv\"\n",
    "    dados = pd.read_csv(caminho_arquivo)\n",
    "    arquivos_usados = [\"exams_part0.hdf5\", \"exams_part1.hdf5\",\n",
    "                    \"exams_part2.hdf5\", \"exams_part3.hdf5\", \"exams_par4.hdf5\", \"exams_part5.hdf5\",\n",
    "                    \"exams_part6.hdf5\", \"exams_part7.hdf5\", \"exams_par8.hdf5\", \"exams_part9.hdf5\",\n",
    "                    \"exams_part10.hdf5\", \"exams_part11.hdf5\", \"exams_part12.hdf5\", \"exams_part13.hdf5\", \n",
    "                    \"exams_part14.hdf5\", \"exams_part15.hdf5\", \"exams_part16.hdf5\", \"exams_part17.hdf5\"]\n",
    "\n",
    "    ecg_normal_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) ]\n",
    "    \n",
    "    ecg_umdavb_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == True) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_rbbb_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == True) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_lbbb_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == True) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_sb_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == True) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_st_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == True) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_af_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == True) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Número de linhas ecg_normal_linhas:\", len(ecg_normal_linhas))\n",
    "    print(\"Número de linhas ecg_umdavb_linhas:\", len(ecg_umdavb_linhas))\n",
    "    print(\"Número de linhas ecg_rbbb_linhas:\", len(ecg_rbbb_linhas))\n",
    "    print(\"Número de linhas ecg_lbbb_linhas:\", len(ecg_lbbb_linhas))\n",
    "    print(\"Número de linhas ecg_sb_linhas:\", len(ecg_sb_linhas))\n",
    "    print(\"Número de linhas ecg_st_linhas:\", len(ecg_st_linhas))\n",
    "    print(\"Número de linhas ecg_af_linhas:\", len(ecg_af_linhas))\n",
    "\n",
    "    caminho_interferencias = \"../../Projeto/Database/resultados_interferencia.csv\"\n",
    "    interferencias = pd.read_csv(caminho_interferencias)\n",
    "    interferencias_ids = interferencias['exam_id'].tolist()\n",
    "\n",
    "    ecg_normal_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) ]\n",
    "    \n",
    "    ecg_umdavb_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == True) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_rbbb_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == True) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_lbbb_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == True) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_sb_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == True) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_st_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == True) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_af_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == True) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "\n",
    "    print(\"Tirando Interferência:\")\n",
    "    print(\"Número de linhas ecg_normal_linhas:\", len(ecg_normal_linhas))\n",
    "    print(\"Número de linhas ecg_umdavb_linhas:\", len(ecg_umdavb_linhas))\n",
    "    print(\"Número de linhas ecg_rbbb_linhas:\", len(ecg_rbbb_linhas))\n",
    "    print(\"Número de linhas ecg_lbbb_linhas:\", len(ecg_lbbb_linhas))\n",
    "    print(\"Número de linhas ecg_sb_linhas:\", len(ecg_sb_linhas))\n",
    "    print(\"Número de linhas ecg_st_linhas:\", len(ecg_st_linhas))\n",
    "    print(\"Número de linhas ecg_af_linhas:\", len(ecg_af_linhas))\n",
    "\n",
    "    ecg_normal_id = dados.iloc[ecg_normal_linhas, 0].tolist()\n",
    "    ecg_umdavb_id = dados.iloc[ecg_umdavb_linhas, 0].tolist()\n",
    "    ecg_rbbb_id = dados.iloc[ecg_rbbb_linhas, 0].tolist()\n",
    "    ecg_lbbb_id = dados.iloc[ecg_lbbb_linhas, 0].tolist()\n",
    "    ecg_sb_id = dados.iloc[ecg_sb_linhas, 0].tolist()\n",
    "    ecg_st_id = dados.iloc[ecg_st_linhas, 0].tolist()\n",
    "    ecg_af_id = dados.iloc[ecg_af_linhas, 0].tolist()\n",
    "\n",
    "    random.seed(42) \n",
    "\n",
    "    ecg_normal_sample = random.sample(ecg_normal_id, unlabel) if len(ecg_normal_id) >= unlabel else ecg_normal_id\n",
    "    ecg_umdavb_sample = random.sample(ecg_umdavb_id, umdavb) if len(ecg_umdavb_id) >= umdavb else ecg_umdavb_id\n",
    "    ecg_rbbb_sample = random.sample(ecg_rbbb_id, rbbb) if len(ecg_rbbb_id) >= rbbb else ecg_rbbb_id\n",
    "    ecg_lbbb_sample = random.sample(ecg_lbbb_id, lbbb) if len(ecg_lbbb_id) >= lbbb else ecg_lbbb_id\n",
    "    ecg_sb_sample = random.sample(ecg_sb_id, sb) if len(ecg_sb_id) >= sb else ecg_sb_id\n",
    "    ecg_st_sample = random.sample(ecg_st_id, st) if len(ecg_st_id) >= st else ecg_st_id\n",
    "    ecg_af_sample = random.sample(ecg_af_id, af) if len(ecg_af_id) >= af else ecg_af_id\n",
    "\n",
    "    ids_ecgs = ecg_normal_sample + ecg_umdavb_sample + ecg_rbbb_sample + ecg_lbbb_sample + ecg_sb_sample + ecg_st_sample + ecg_af_sample\n",
    "\n",
    "    print(\"Número de ecgs pra usar:\", len(ids_ecgs))\n",
    "\n",
    "    \n",
    "    if filtrado == True: arquivos_hdf5 = [\"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_0_1.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_2_3.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_4_5.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_6_7.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_8_9.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_10_11.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_12_13.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_14_15.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_16_17.hdf5\"]\n",
    "    \n",
    "    else: arquivos_hdf5 = ['/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part0.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part1.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part2.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part3.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part4.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part5.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part6.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part7.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part8.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part9.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part10.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part11.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part12.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part13.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part14.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part15.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part16.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part17.hdf5']\n",
    "        \n",
    "    \n",
    "\n",
    "    def get_ecg_data(file_path, exam_id):\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            # Obter os IDs dos exames\n",
    "            exam_ids = np.array(f['exam_id'])\n",
    "\n",
    "            # Encontrar o índice correspondente ao exam_id de interesse\n",
    "            exam_index = np.where(exam_ids == exam_id)[0]\n",
    "\n",
    "            if len(exam_index) == 0:\n",
    "                raise ValueError(\"Exam ID não encontrado.\")\n",
    "            else:\n",
    "                exam_index = exam_index[0]\n",
    "                # Acessar os tracings de ECG correspondentes ao exam_index\n",
    "                exam_tracings = f['tracings'][exam_index]\n",
    "                # Preencher tracings nulos com epsilon\n",
    "                return exam_tracings\n",
    "\n",
    "    exam_ids_to_cluster = ids_ecgs  # Substitua pelos IDs reais dos exames\n",
    "\n",
    "    # Lista para armazenar todos os tracings de ECG\n",
    "    all_tracings = []\n",
    "\n",
    "    # Obter os tracings de ECG para cada exam_id e armazenar na lista\n",
    "    for exam_id in exam_ids_to_cluster:\n",
    "        found = False  # Sinalizador para verificar se o exame foi encontrado em algum arquivo\n",
    "        for arquivo in arquivos_hdf5:\n",
    "            try:\n",
    "                tracings = get_ecg_data(arquivo, exam_id)\n",
    "                if tracings is not None:\n",
    "                    tracing_transposto = np.array(tracings).T\n",
    "                    all_tracings.append(tracing_transposto)\n",
    "                    found = True  # Sinalizador para indicar que o exame foi encontrado\n",
    "                    break  # Se encontrou, não precisa continuar buscando nos outros arquivos\n",
    "            except ValueError as e:\n",
    "                i = 0\n",
    "            except Exception as e:\n",
    "                i = 0\n",
    "        \n",
    "        if not found:\n",
    "            print(f\"Erro: exame ID {exam_id} não encontrado em nenhum dos arquivos.\")\n",
    "\n",
    "    # Verifique o tamanho da lista all_tracings para garantir que os dados foram coletados corretamente\n",
    "    print(\"Número de ecgs que eram pra ser processados:\", len(ids_ecgs))\n",
    "    print(f\"Número total de traçados processados: {len(all_tracings)}\")\n",
    "\n",
    "    # X será um array com um único array dentro, contendo todos os números do tracings.T\n",
    "    X = np.array(all_tracings)\n",
    "    return X , ids_ecgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas ecg_normal_linhas: 272407\n",
      "Número de linhas ecg_umdavb_linhas: 3735\n",
      "Número de linhas ecg_rbbb_linhas: 6808\n",
      "Número de linhas ecg_lbbb_linhas: 4176\n",
      "Número de linhas ecg_sb_linhas: 4300\n",
      "Número de linhas ecg_st_linhas: 6146\n",
      "Número de linhas ecg_af_linhas: 4964\n",
      "Tirando Interferência:\n",
      "Número de linhas ecg_normal_linhas: 252167\n",
      "Número de linhas ecg_umdavb_linhas: 3651\n",
      "Número de linhas ecg_rbbb_linhas: 6703\n",
      "Número de linhas ecg_lbbb_linhas: 4122\n",
      "Número de linhas ecg_sb_linhas: 4248\n",
      "Número de linhas ecg_st_linhas: 6038\n",
      "Número de linhas ecg_af_linhas: 4804\n",
      "Número de ecgs pra usar: 7000\n",
      "Número de ecgs que eram pra ser processados: 7000\n",
      "Número total de traçados processados: 7000\n"
     ]
    }
   ],
   "source": [
    "X, ids_ecgs = carregar_ecgs(unlabel=1000,umdavb=1000,rbbb=1000,lbbb=1000,sb=1000,st=1000,af=1000,filtrado=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensão dos dados carregados: (7000, 12, 4096)\n"
     ]
    }
   ],
   "source": [
    "print(\"Dimensão dos dados carregados:\", X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_my_dataset(X, unlabel=1000,umdavb=1000,rbbb=1000,lbbb=1000,sb=1000,st=1000,af=1000,train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Prepara o dataset de ECG para o treinamento.\n",
    "    \n",
    "    Parâmetros:\n",
    "      - X: array de ECG (formato: [n_samples, n_channels, length])\n",
    "      - os números de amostras por classe (deve coincidir com a ordem de concatenação na função carregar_ecgs)\n",
    "      - train_ratio: proporção dos dados para treinamento\n",
    "      \n",
    "    Retorna:\n",
    "      - X (possivelmente normalizado),\n",
    "      - y: vetor de labels (0: normal, 1: umdavb, 2: rbbb, 3: lbbb, 4: sb, 5: st, 6: af)\n",
    "      - train_idx: índices de treinamento\n",
    "      - test_idx: índices de teste\n",
    "    \"\"\"\n",
    "    \n",
    "    total_samples = unlabel + umdavb + rbbb + lbbb + sb + st + af\n",
    "    if X.shape[0] != total_samples:\n",
    "        raise ValueError(f\"O número de traçados em X ({X.shape[0]}) não corresponde à soma esperada ({total_samples}).\")\n",
    "    \n",
    "    # Cria os labels de acordo com a ordem de concatenação\n",
    "    y = np.array([0]*unlabel + \n",
    "                 [1]*umdavb + \n",
    "                 [2]*rbbb + \n",
    "                 [3]*lbbb + \n",
    "                 [4]*sb + \n",
    "                 [5]*st + \n",
    "                 [6]*af)\n",
    "    \n",
    "    # Aqui assumimos que a normalização é feita sobre o último eixo (tempo)\n",
    "    X_norm = X.copy().astype(np.float32)\n",
    "    for i in range(X_norm.shape[0]):\n",
    "        # Evita divisão por zero\n",
    "        mean_val = X_norm[i].mean()\n",
    "        std_val = X_norm[i].std() if X_norm[i].std() != 0 else 1.0\n",
    "        X_norm[i] = (X_norm[i] - mean_val) / std_val\n",
    "    \n",
    "    # Cria a divisão em treinamento e teste (shuffle dos índices)\n",
    "    indices = np.arange(total_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(train_ratio * total_samples)\n",
    "    train_idx = indices[:split]\n",
    "    test_idx = indices[split:]\n",
    "    \n",
    "    return X_norm, y, train_idx, test_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "import torch.utils.data\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "\n",
    "class SimTSCTrainer:\n",
    "    def __init__(self, device, logger):\n",
    "        self.device = device\n",
    "        self.logger = logger\n",
    "        self.tmp_dir = 'tmp'\n",
    "        if not os.path.exists(self.tmp_dir):\n",
    "            os.makedirs(self.tmp_dir)\n",
    "\n",
    "    def fit(self, model, X, y, train_idx, distances, K, alpha, test_idx=None, report_test=False, batch_size=128, epochs=500):\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "\n",
    "        train_batch_size = min(batch_size//2, len(train_idx))\n",
    "        other_idx = np.array([i for i in range(len(X)) if i not in train_idx])\n",
    "        other_batch_size = min(batch_size - train_batch_size, len(other_idx))\n",
    "        train_dataset = Dataset(train_idx)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "        if report_test and test_idx is not None:\n",
    "            test_batch_size = min(batch_size//2, len(test_idx))\n",
    "            other_idx_test = np.array([i for i in range(len(X)) if i not in test_idx])\n",
    "            other_batch_size_test = min(batch_size - test_batch_size, len(other_idx_test))\n",
    "            test_dataset = Dataset(test_idx)\n",
    "            test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "        self.adj = torch.from_numpy(distances.astype(np.float32))\n",
    "        self.X, self.y = torch.from_numpy(X), torch.from_numpy(y)\n",
    "        file_path = os.path.join(self.tmp_dir, str(uuid.uuid4()))\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=4e-3)\n",
    "        best_acc = 0.0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            for sampled_train_idx in train_loader:\n",
    "                sampled_other_idx = np.random.choice(other_idx, other_batch_size, replace=False)\n",
    "                idx = np.concatenate((sampled_train_idx, sampled_other_idx))\n",
    "                _X = self.X[idx].to(self.device)\n",
    "                _y = self.y[sampled_train_idx].to(self.device)\n",
    "                _adj = self.adj[idx][:, idx]\n",
    "                outputs = model(_X, _adj, K, alpha)\n",
    "                loss = F.nll_loss(outputs[:len(sampled_train_idx)], _y)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            model.eval()\n",
    "            acc = compute_accuracy(\n",
    "                model, self.X, self.y, self.adj, self.K, self.alpha,\n",
    "                train_loader, self.device, other_idx, other_batch_size\n",
    "            )\n",
    "            \n",
    "            # --------------------------------------------------------------------------\n",
    "            # ADIÇÃO DO F1 SCORE: cálculo do F1 para o conjunto de treinamento\n",
    "            # --------------------------------------------------------------------------\n",
    "            f1 = compute_f1(\n",
    "                model, self.X, self.y, self.adj, self.K, self.alpha,\n",
    "                train_loader, self.device, other_idx, other_batch_size\n",
    "            )\n",
    "\n",
    "            if acc >= best_acc:\n",
    "                best_acc = acc\n",
    "                torch.save(model.state_dict(), file_path)\n",
    "\n",
    "            if report_test and test_idx is not None:\n",
    "                test_acc = compute_accuracy(\n",
    "                    model, self.X, self.y, self.adj, self.K, self.alpha,\n",
    "                    test_loader, self.device, other_idx_test, other_batch_size_test\n",
    "                )\n",
    "                \n",
    "                # ----------------------------------------------------------------------\n",
    "                # ADIÇÃO DO F1 SCORE: cálculo do F1 para o conjunto de teste\n",
    "                # ----------------------------------------------------------------------\n",
    "                test_f1 = compute_f1(\n",
    "                    model, self.X, self.y, self.adj, self.K, self.alpha,\n",
    "                    test_loader, self.device, other_idx_test, other_batch_size_test\n",
    "                )\n",
    "\n",
    "                self.logger.log('--> Epoch {}: loss {:5.4f}; accuracy: {:5.4f}; best accuracy: {:5.4f}; test accuracy: {:5.4f}'.format(\n",
    "                    epoch, loss.item(), acc, best_acc, test_acc\n",
    "                ))\n",
    "                # Log separado do F1 Score (não alteramos a linha existente; apenas adicionamos)\n",
    "                self.logger.log('----> F1: {:5.4f}; Test F1: {:5.4f}'.format(f1, test_f1))\n",
    "\n",
    "            else:\n",
    "                self.logger.log('--> Epoch {}: loss {:5.4f}; accuracy: {:5.4f}; best accuracy: {:5.4f}'.format(\n",
    "                    epoch, loss.item(), acc, best_acc\n",
    "                ))\n",
    "                # Log separado do F1 Score\n",
    "                self.logger.log('----> F1: {:5.4f}'.format(f1))\n",
    "\n",
    "        model.load_state_dict(torch.load(file_path))\n",
    "        model.eval()\n",
    "        os.remove(file_path)\n",
    "        return model\n",
    "\n",
    "    def test(self, model, test_idx, batch_size=128):\n",
    "        test_batch_size = min(batch_size//2, len(test_idx))\n",
    "        other_idx_test = np.array([i for i in range(len(self.X)) if i not in test_idx])\n",
    "        other_batch_size_test = min(batch_size - test_batch_size, len(other_idx_test))\n",
    "        test_dataset = Dataset(test_idx)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True, num_workers=1)\n",
    "        acc = compute_accuracy(\n",
    "            model, self.X, self.y, self.adj, self.K, self.alpha,\n",
    "            test_loader, self.device, other_idx_test, other_batch_size_test\n",
    "        )\n",
    "        \n",
    "        # --------------------------------------------------------------------------\n",
    "        # ADIÇÃO DO F1 SCORE: cálculo do F1 no teste (apenas informado aqui)\n",
    "        # --------------------------------------------------------------------------\n",
    "        f1 = compute_f1(\n",
    "            model, self.X, self.y, self.adj, self.K, self.alpha,\n",
    "            test_loader, self.device, other_idx_test, other_batch_size_test\n",
    "        )\n",
    "\n",
    "        # Se quiser logar aqui, poderia adicionar algo como:\n",
    "        # self.logger.log(f'Test F1: {f1:.4f}')\n",
    "        \n",
    "        return acc.item()\n",
    "\n",
    "def compute_accuracy(model, X, y, adj, K, alpha, loader, device, other_idx, other_batch_size):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in loader:\n",
    "            sampled_other_idx = np.random.choice(other_idx, other_batch_size, replace=False)\n",
    "            idx = np.concatenate((batch_idx, sampled_other_idx))\n",
    "            _X = X[idx].to(device)\n",
    "            _y = y[idx][:len(batch_idx)].to(device)\n",
    "            _adj = adj[idx][:, idx]\n",
    "            outputs = model(_X, _adj, K, alpha)\n",
    "            preds = outputs[:len(batch_idx)].max(1)[1].type_as(_y)\n",
    "            _correct = preds.eq(_y).double()\n",
    "            correct += _correct.sum()\n",
    "            total += len(batch_idx)\n",
    "    acc = correct / total\n",
    "    return acc\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# ADIÇÃO DO F1 SCORE: função específica para computar o F1\n",
    "# ------------------------------------------------------------------------------\n",
    "def compute_f1(model, X, y, adj, K, alpha, loader, device, other_idx, other_batch_size):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in loader:\n",
    "            sampled_other_idx = np.random.choice(other_idx, other_batch_size, replace=False)\n",
    "            idx = np.concatenate((batch_idx, sampled_other_idx))\n",
    "            _X = X[idx].to(device)\n",
    "            _y = y[idx][:len(batch_idx)].to(device)\n",
    "            _adj = adj[idx][:, idx]\n",
    "            outputs = model(_X, _adj, K, alpha)\n",
    "            preds = outputs[:len(batch_idx)].max(1)[1]\n",
    "            all_preds.extend(preds.cpu().numpy().tolist())\n",
    "            all_labels.extend(_y.cpu().numpy().tolist())\n",
    "    # Usamos 'macro' por ser comum em multi-classes (pode ajustar se preferir)\n",
    "    return f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "class SimTSC(nn.Module):\n",
    "    def __init__(self, input_size, nb_classes, num_layers=1, n_feature_maps=64, dropout=0.5):\n",
    "        super(SimTSC, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.block_1 = ResNetBlock(input_size, n_feature_maps)\n",
    "        self.block_2 = ResNetBlock(n_feature_maps, n_feature_maps)\n",
    "        self.block_3 = ResNetBlock(n_feature_maps, n_feature_maps)\n",
    "        if self.num_layers == 1:\n",
    "            self.gc1 = GraphConvolution(n_feature_maps, nb_classes)\n",
    "        elif self.num_layers == 2:\n",
    "            self.gc1 = GraphConvolution(n_feature_maps, n_feature_maps)\n",
    "            self.gc2 = GraphConvolution(n_feature_maps, nb_classes)\n",
    "            self.dropout = dropout\n",
    "        elif self.num_layers == 3:\n",
    "            self.gc1 = GraphConvolution(n_feature_maps, n_feature_maps)\n",
    "            self.gc2 = GraphConvolution(n_feature_maps, n_feature_maps)\n",
    "            self.gc3 = GraphConvolution(n_feature_maps, nb_classes)\n",
    "            self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj, K, alpha):\n",
    "        ranks = torch.argsort(adj, dim=1)\n",
    "        sparse_index = [[], []]\n",
    "        sparse_value = []\n",
    "        for i in range(len(adj)):\n",
    "            _sparse_value = []\n",
    "            for j in ranks[i][:K]:\n",
    "                sparse_index[0].append(i)\n",
    "                sparse_index[1].append(j)\n",
    "                _sparse_value.append(1/np.exp(alpha*adj[i][j]))\n",
    "            _sparse_value = np.array(_sparse_value)\n",
    "            _sparse_value /= _sparse_value.sum()\n",
    "            sparse_value.extend(_sparse_value.tolist())\n",
    "        sparse_index = torch.LongTensor(sparse_index)\n",
    "        sparse_value = torch.FloatTensor(sparse_value)\n",
    "        adj = torch.sparse.FloatTensor(sparse_index, sparse_value, adj.size())\n",
    "        device = self.gc1.bias.device\n",
    "        adj = adj.to(device)\n",
    "\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1]).squeeze()\n",
    "\n",
    "        if self.num_layers == 1:\n",
    "            x = self.gc1(x, adj)\n",
    "        elif self.num_layers == 2:\n",
    "            x = F.relu(self.gc1(x, adj))\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = self.gc2(x, adj)\n",
    "        elif self.num_layers == 3:\n",
    "            x = F.relu(self.gc1(x, adj))\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = F.relu(self.gc2(x, adj))\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = self.gc3(x, adj)\n",
    "\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "class GraphConvolution(Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(0))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.expand = True if in_channels < out_channels else False\n",
    "        self.conv_x = nn.Conv1d(in_channels, out_channels, 7, padding=3)\n",
    "        self.bn_x = nn.BatchNorm1d(out_channels)\n",
    "        self.conv_y = nn.Conv1d(out_channels, out_channels, 5, padding=2)\n",
    "        self.bn_y = nn.BatchNorm1d(out_channels)\n",
    "        self.conv_z = nn.Conv1d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn_z = nn.BatchNorm1d(out_channels)\n",
    "        if self.expand:\n",
    "            self.shortcut_y = nn.Conv1d(in_channels, out_channels, 1)\n",
    "        self.bn_shortcut_y = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn_x(self.conv_x(x)))\n",
    "        out = F.relu(self.bn_y(self.conv_y(out)))\n",
    "        out = self.bn_z(self.conv_z(out))\n",
    "        if self.expand:\n",
    "            x = self.shortcut_y(x)\n",
    "        x = self.bn_shortcut_y(x)\n",
    "        out += x\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, idx):\n",
    "        self.idx = idx\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.idx[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Dispositivo de treinamento: cuda:0\n",
      "Calculando matriz DTW com paralelismo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculando DTW:   7%|▋         | 515/7000 [12:39<3:30:58,  1.95s/linha] IOStream.flush timed out\n",
      "Calculando DTW:   7%|▋         | 516/7000 [13:09<15:48:42,  8.78s/linha]IOStream.flush timed out\n",
      "Calculando DTW:   7%|▋         | 518/7000 [14:03<27:14:11, 15.13s/linha]IOStream.flush timed out\n",
      "Calculando DTW: 100%|██████████| 7000/7000 [1:25:17<00:00,  1.37linha/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cálculo DTW finalizado em 85.29 minutos.\n",
      "Iniciando o treinamento...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3347620/977832602.py:209: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:651.)\n",
      "  adj = torch.sparse.FloatTensor(sparse_index, sparse_value, adj.size())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Epoch 0: loss 1.4158; accuracy: 0.5030; best accuracy: 0.5030; test accuracy: 0.5064\n",
      "----> F1: 0.4548; Test F1: 0.4515\n",
      "--> Epoch 1: loss 1.2386; accuracy: 0.5346; best accuracy: 0.5346; test accuracy: 0.5407\n",
      "----> F1: 0.4952; Test F1: 0.4910\n",
      "--> Epoch 2: loss 1.4772; accuracy: 0.5339; best accuracy: 0.5346; test accuracy: 0.5429\n",
      "----> F1: 0.4921; Test F1: 0.4933\n",
      "--> Epoch 3: loss 1.2198; accuracy: 0.5864; best accuracy: 0.5864; test accuracy: 0.5914\n",
      "----> F1: 0.5590; Test F1: 0.5600\n",
      "--> Epoch 4: loss 1.0862; accuracy: 0.5504; best accuracy: 0.5864; test accuracy: 0.5529\n",
      "----> F1: 0.5072; Test F1: 0.5049\n",
      "--> Epoch 5: loss 1.2901; accuracy: 0.5955; best accuracy: 0.5955; test accuracy: 0.5893\n",
      "----> F1: 0.5599; Test F1: 0.5479\n",
      "--> Epoch 6: loss 1.0255; accuracy: 0.6061; best accuracy: 0.6061; test accuracy: 0.6071\n",
      "----> F1: 0.5722; Test F1: 0.5664\n",
      "--> Epoch 7: loss 0.8397; accuracy: 0.6521; best accuracy: 0.6521; test accuracy: 0.6271\n",
      "----> F1: 0.6209; Test F1: 0.5826\n",
      "--> Epoch 8: loss 0.8485; accuracy: 0.6052; best accuracy: 0.6521; test accuracy: 0.6100\n",
      "----> F1: 0.5975; Test F1: 0.5936\n",
      "--> Epoch 9: loss 1.1351; accuracy: 0.6205; best accuracy: 0.6521; test accuracy: 0.6064\n",
      "----> F1: 0.5975; Test F1: 0.5800\n",
      "--> Epoch 10: loss 0.8033; accuracy: 0.6002; best accuracy: 0.6521; test accuracy: 0.5971\n",
      "----> F1: 0.5587; Test F1: 0.5448\n",
      "--> Epoch 11: loss 1.0452; accuracy: 0.6420; best accuracy: 0.6521; test accuracy: 0.6186\n",
      "----> F1: 0.6274; Test F1: 0.5931\n",
      "--> Epoch 12: loss 1.0592; accuracy: 0.6538; best accuracy: 0.6538; test accuracy: 0.6543\n",
      "----> F1: 0.6243; Test F1: 0.6254\n",
      "--> Epoch 13: loss 0.8626; accuracy: 0.6491; best accuracy: 0.6538; test accuracy: 0.6557\n",
      "----> F1: 0.6362; Test F1: 0.6329\n",
      "--> Epoch 14: loss 0.7405; accuracy: 0.6684; best accuracy: 0.6684; test accuracy: 0.6550\n",
      "----> F1: 0.6342; Test F1: 0.6165\n",
      "--> Epoch 15: loss 0.7483; accuracy: 0.6471; best accuracy: 0.6684; test accuracy: 0.6386\n",
      "----> F1: 0.6100; Test F1: 0.5878\n",
      "--> Epoch 16: loss 0.8650; accuracy: 0.6918; best accuracy: 0.6918; test accuracy: 0.6857\n",
      "----> F1: 0.6695; Test F1: 0.6633\n",
      "--> Epoch 17: loss 0.8933; accuracy: 0.6786; best accuracy: 0.6918; test accuracy: 0.6714\n",
      "----> F1: 0.6729; Test F1: 0.6596\n",
      "--> Epoch 18: loss 0.8905; accuracy: 0.6889; best accuracy: 0.6918; test accuracy: 0.6771\n",
      "----> F1: 0.6765; Test F1: 0.6657\n",
      "--> Epoch 19: loss 0.7541; accuracy: 0.6779; best accuracy: 0.6918; test accuracy: 0.6743\n",
      "----> F1: 0.6617; Test F1: 0.6547\n",
      "--> Epoch 20: loss 0.9085; accuracy: 0.6839; best accuracy: 0.6918; test accuracy: 0.6757\n",
      "----> F1: 0.6781; Test F1: 0.6618\n",
      "--> Epoch 21: loss 0.7899; accuracy: 0.6779; best accuracy: 0.6918; test accuracy: 0.6650\n",
      "----> F1: 0.6686; Test F1: 0.6511\n",
      "--> Epoch 22: loss 0.5345; accuracy: 0.7154; best accuracy: 0.7154; test accuracy: 0.7036\n",
      "----> F1: 0.6987; Test F1: 0.6874\n",
      "--> Epoch 23: loss 0.5695; accuracy: 0.6977; best accuracy: 0.7154; test accuracy: 0.6907\n",
      "----> F1: 0.6837; Test F1: 0.6714\n",
      "--> Epoch 24: loss 0.8289; accuracy: 0.6773; best accuracy: 0.7154; test accuracy: 0.6643\n",
      "----> F1: 0.6751; Test F1: 0.6558\n",
      "--> Epoch 25: loss 0.6387; accuracy: 0.7171; best accuracy: 0.7171; test accuracy: 0.7050\n",
      "----> F1: 0.7016; Test F1: 0.6824\n",
      "--> Epoch 26: loss 0.9141; accuracy: 0.7475; best accuracy: 0.7475; test accuracy: 0.7429\n",
      "----> F1: 0.7462; Test F1: 0.7394\n",
      "--> Epoch 27: loss 0.6272; accuracy: 0.7359; best accuracy: 0.7475; test accuracy: 0.7071\n",
      "----> F1: 0.7171; Test F1: 0.6816\n",
      "--> Epoch 28: loss 0.5985; accuracy: 0.7212; best accuracy: 0.7475; test accuracy: 0.7136\n",
      "----> F1: 0.7056; Test F1: 0.7000\n",
      "--> Epoch 29: loss 0.7730; accuracy: 0.7329; best accuracy: 0.7475; test accuracy: 0.6971\n",
      "----> F1: 0.7230; Test F1: 0.6799\n",
      "--> Epoch 30: loss 0.9142; accuracy: 0.7139; best accuracy: 0.7475; test accuracy: 0.6957\n",
      "----> F1: 0.7094; Test F1: 0.6908\n",
      "--> Epoch 31: loss 0.5127; accuracy: 0.7234; best accuracy: 0.7475; test accuracy: 0.7029\n",
      "----> F1: 0.7037; Test F1: 0.6779\n",
      "--> Epoch 32: loss 0.5765; accuracy: 0.7375; best accuracy: 0.7475; test accuracy: 0.7193\n",
      "----> F1: 0.7358; Test F1: 0.7172\n",
      "--> Epoch 33: loss 0.5341; accuracy: 0.7434; best accuracy: 0.7475; test accuracy: 0.7357\n",
      "----> F1: 0.7254; Test F1: 0.7108\n",
      "--> Epoch 34: loss 0.7867; accuracy: 0.7607; best accuracy: 0.7607; test accuracy: 0.7393\n",
      "----> F1: 0.7516; Test F1: 0.7269\n",
      "--> Epoch 35: loss 0.9159; accuracy: 0.7311; best accuracy: 0.7607; test accuracy: 0.7243\n",
      "----> F1: 0.7231; Test F1: 0.7084\n",
      "--> Epoch 36: loss 0.7190; accuracy: 0.7064; best accuracy: 0.7607; test accuracy: 0.6921\n",
      "----> F1: 0.7034; Test F1: 0.6879\n",
      "--> Epoch 37: loss 0.9354; accuracy: 0.7321; best accuracy: 0.7607; test accuracy: 0.7307\n",
      "----> F1: 0.7252; Test F1: 0.7240\n",
      "--> Epoch 38: loss 0.7778; accuracy: 0.7177; best accuracy: 0.7607; test accuracy: 0.7007\n",
      "----> F1: 0.7054; Test F1: 0.6785\n",
      "--> Epoch 39: loss 0.9931; accuracy: 0.7266; best accuracy: 0.7607; test accuracy: 0.7107\n",
      "----> F1: 0.7182; Test F1: 0.6957\n",
      "--> Epoch 40: loss 0.6069; accuracy: 0.7721; best accuracy: 0.7721; test accuracy: 0.7336\n",
      "----> F1: 0.7682; Test F1: 0.7257\n",
      "--> Epoch 41: loss 0.9271; accuracy: 0.7404; best accuracy: 0.7721; test accuracy: 0.7243\n",
      "----> F1: 0.7284; Test F1: 0.7095\n",
      "--> Epoch 42: loss 0.5479; accuracy: 0.7516; best accuracy: 0.7721; test accuracy: 0.7279\n",
      "----> F1: 0.7455; Test F1: 0.7190\n",
      "--> Epoch 43: loss 0.6483; accuracy: 0.7605; best accuracy: 0.7721; test accuracy: 0.7493\n",
      "----> F1: 0.7552; Test F1: 0.7365\n",
      "--> Epoch 44: loss 0.8146; accuracy: 0.7743; best accuracy: 0.7743; test accuracy: 0.7393\n",
      "----> F1: 0.7689; Test F1: 0.7291\n",
      "--> Epoch 45: loss 0.6046; accuracy: 0.7886; best accuracy: 0.7886; test accuracy: 0.7529\n",
      "----> F1: 0.7862; Test F1: 0.7478\n",
      "--> Epoch 46: loss 0.8839; accuracy: 0.7788; best accuracy: 0.7886; test accuracy: 0.7357\n",
      "----> F1: 0.7698; Test F1: 0.7328\n",
      "--> Epoch 47: loss 0.5206; accuracy: 0.7907; best accuracy: 0.7907; test accuracy: 0.7600\n",
      "----> F1: 0.7850; Test F1: 0.7555\n",
      "--> Epoch 48: loss 0.3785; accuracy: 0.7914; best accuracy: 0.7914; test accuracy: 0.7586\n",
      "----> F1: 0.7905; Test F1: 0.7546\n",
      "--> Epoch 49: loss 0.6448; accuracy: 0.7743; best accuracy: 0.7914; test accuracy: 0.7536\n",
      "----> F1: 0.7686; Test F1: 0.7432\n",
      "--> Epoch 50: loss 0.8344; accuracy: 0.6968; best accuracy: 0.7914; test accuracy: 0.6871\n",
      "----> F1: 0.6757; Test F1: 0.6568\n",
      "--> Epoch 51: loss 0.8398; accuracy: 0.7527; best accuracy: 0.7914; test accuracy: 0.7443\n",
      "----> F1: 0.7468; Test F1: 0.7295\n",
      "--> Epoch 52: loss 0.6627; accuracy: 0.7566; best accuracy: 0.7914; test accuracy: 0.7407\n",
      "----> F1: 0.7486; Test F1: 0.7315\n",
      "--> Epoch 53: loss 0.4983; accuracy: 0.7680; best accuracy: 0.7914; test accuracy: 0.7264\n",
      "----> F1: 0.7669; Test F1: 0.7255\n",
      "--> Epoch 54: loss 0.5220; accuracy: 0.8055; best accuracy: 0.8055; test accuracy: 0.7771\n",
      "----> F1: 0.7972; Test F1: 0.7637\n",
      "--> Epoch 55: loss 0.6452; accuracy: 0.8130; best accuracy: 0.8130; test accuracy: 0.7679\n",
      "----> F1: 0.8099; Test F1: 0.7589\n",
      "--> Epoch 56: loss 0.6263; accuracy: 0.8234; best accuracy: 0.8234; test accuracy: 0.7757\n",
      "----> F1: 0.8188; Test F1: 0.7668\n",
      "--> Epoch 57: loss 0.5031; accuracy: 0.8186; best accuracy: 0.8234; test accuracy: 0.7900\n",
      "----> F1: 0.8149; Test F1: 0.7849\n",
      "--> Epoch 58: loss 0.5058; accuracy: 0.8063; best accuracy: 0.8234; test accuracy: 0.7750\n",
      "----> F1: 0.8004; Test F1: 0.7614\n",
      "--> Epoch 59: loss 1.1602; accuracy: 0.7841; best accuracy: 0.8234; test accuracy: 0.7364\n",
      "----> F1: 0.7806; Test F1: 0.7360\n",
      "--> Epoch 60: loss 0.4203; accuracy: 0.8232; best accuracy: 0.8234; test accuracy: 0.7829\n",
      "----> F1: 0.8199; Test F1: 0.7784\n",
      "--> Epoch 61: loss 0.6185; accuracy: 0.8214; best accuracy: 0.8234; test accuracy: 0.7886\n",
      "----> F1: 0.8134; Test F1: 0.7816\n",
      "--> Epoch 62: loss 0.5221; accuracy: 0.8245; best accuracy: 0.8245; test accuracy: 0.7864\n",
      "----> F1: 0.8280; Test F1: 0.7841\n",
      "--> Epoch 63: loss 0.4710; accuracy: 0.8064; best accuracy: 0.8245; test accuracy: 0.7729\n",
      "----> F1: 0.7954; Test F1: 0.7509\n",
      "--> Epoch 64: loss 0.4517; accuracy: 0.8255; best accuracy: 0.8255; test accuracy: 0.7900\n",
      "----> F1: 0.8238; Test F1: 0.7866\n",
      "--> Epoch 65: loss 0.5857; accuracy: 0.8159; best accuracy: 0.8255; test accuracy: 0.7921\n",
      "----> F1: 0.8048; Test F1: 0.7763\n",
      "--> Epoch 66: loss 0.6946; accuracy: 0.8386; best accuracy: 0.8386; test accuracy: 0.8043\n",
      "----> F1: 0.8384; Test F1: 0.8063\n",
      "--> Epoch 67: loss 0.5379; accuracy: 0.8250; best accuracy: 0.8386; test accuracy: 0.7793\n",
      "----> F1: 0.8175; Test F1: 0.7713\n",
      "--> Epoch 68: loss 0.6081; accuracy: 0.8455; best accuracy: 0.8455; test accuracy: 0.8014\n",
      "----> F1: 0.8446; Test F1: 0.7956\n",
      "--> Epoch 69: loss 0.3180; accuracy: 0.8568; best accuracy: 0.8568; test accuracy: 0.8114\n",
      "----> F1: 0.8539; Test F1: 0.8066\n",
      "--> Epoch 70: loss 0.6296; accuracy: 0.8350; best accuracy: 0.8568; test accuracy: 0.7986\n",
      "----> F1: 0.8292; Test F1: 0.7875\n",
      "--> Epoch 71: loss 0.5062; accuracy: 0.8350; best accuracy: 0.8568; test accuracy: 0.7750\n",
      "----> F1: 0.8334; Test F1: 0.7687\n",
      "--> Epoch 72: loss 0.4885; accuracy: 0.7986; best accuracy: 0.8568; test accuracy: 0.7693\n",
      "----> F1: 0.7923; Test F1: 0.7587\n",
      "--> Epoch 73: loss 0.6160; accuracy: 0.8082; best accuracy: 0.8568; test accuracy: 0.7700\n",
      "----> F1: 0.8096; Test F1: 0.7671\n",
      "--> Epoch 74: loss 0.4357; accuracy: 0.8254; best accuracy: 0.8568; test accuracy: 0.7836\n",
      "----> F1: 0.8209; Test F1: 0.7791\n",
      "--> Epoch 75: loss 0.8262; accuracy: 0.8336; best accuracy: 0.8568; test accuracy: 0.7936\n",
      "----> F1: 0.8326; Test F1: 0.7877\n",
      "--> Epoch 76: loss 0.6097; accuracy: 0.8230; best accuracy: 0.8568; test accuracy: 0.7871\n",
      "----> F1: 0.8168; Test F1: 0.7831\n",
      "--> Epoch 77: loss 0.4191; accuracy: 0.8255; best accuracy: 0.8568; test accuracy: 0.7871\n",
      "----> F1: 0.8239; Test F1: 0.7795\n",
      "--> Epoch 78: loss 0.4153; accuracy: 0.8375; best accuracy: 0.8568; test accuracy: 0.7943\n",
      "----> F1: 0.8332; Test F1: 0.7886\n",
      "--> Epoch 79: loss 0.3978; accuracy: 0.8202; best accuracy: 0.8568; test accuracy: 0.7586\n",
      "----> F1: 0.8223; Test F1: 0.7566\n",
      "--> Epoch 80: loss 0.6447; accuracy: 0.8175; best accuracy: 0.8568; test accuracy: 0.7800\n",
      "----> F1: 0.8051; Test F1: 0.7684\n",
      "--> Epoch 81: loss 0.3770; accuracy: 0.8427; best accuracy: 0.8568; test accuracy: 0.7821\n",
      "----> F1: 0.8467; Test F1: 0.7873\n",
      "--> Epoch 82: loss 0.5906; accuracy: 0.8361; best accuracy: 0.8568; test accuracy: 0.7907\n",
      "----> F1: 0.8283; Test F1: 0.7816\n",
      "--> Epoch 83: loss 0.7294; accuracy: 0.8484; best accuracy: 0.8568; test accuracy: 0.8071\n",
      "----> F1: 0.8494; Test F1: 0.8063\n",
      "--> Epoch 84: loss 0.3407; accuracy: 0.8652; best accuracy: 0.8652; test accuracy: 0.8257\n",
      "----> F1: 0.8603; Test F1: 0.8173\n",
      "--> Epoch 85: loss 0.4723; accuracy: 0.8716; best accuracy: 0.8716; test accuracy: 0.8057\n",
      "----> F1: 0.8696; Test F1: 0.8093\n",
      "--> Epoch 86: loss 0.3318; accuracy: 0.8496; best accuracy: 0.8716; test accuracy: 0.8100\n",
      "----> F1: 0.8458; Test F1: 0.8014\n",
      "--> Epoch 87: loss 0.2469; accuracy: 0.8438; best accuracy: 0.8716; test accuracy: 0.8007\n",
      "----> F1: 0.8446; Test F1: 0.7978\n",
      "--> Epoch 88: loss 0.4381; accuracy: 0.8711; best accuracy: 0.8716; test accuracy: 0.8121\n",
      "----> F1: 0.8693; Test F1: 0.8078\n",
      "--> Epoch 89: loss 0.5383; accuracy: 0.8662; best accuracy: 0.8716; test accuracy: 0.8114\n",
      "----> F1: 0.8655; Test F1: 0.8098\n",
      "--> Epoch 90: loss 0.3046; accuracy: 0.8634; best accuracy: 0.8716; test accuracy: 0.8093\n",
      "----> F1: 0.8589; Test F1: 0.8035\n",
      "--> Epoch 91: loss 0.4520; accuracy: 0.8259; best accuracy: 0.8716; test accuracy: 0.7707\n",
      "----> F1: 0.8258; Test F1: 0.7699\n",
      "--> Epoch 92: loss 0.5795; accuracy: 0.8054; best accuracy: 0.8716; test accuracy: 0.7693\n",
      "----> F1: 0.7929; Test F1: 0.7543\n",
      "--> Epoch 93: loss 0.3119; accuracy: 0.8359; best accuracy: 0.8716; test accuracy: 0.7864\n",
      "----> F1: 0.8356; Test F1: 0.7813\n",
      "--> Epoch 94: loss 0.4126; accuracy: 0.8709; best accuracy: 0.8716; test accuracy: 0.8129\n",
      "----> F1: 0.8678; Test F1: 0.8082\n",
      "--> Epoch 95: loss 0.5597; accuracy: 0.8421; best accuracy: 0.8716; test accuracy: 0.7757\n",
      "----> F1: 0.8426; Test F1: 0.7754\n",
      "--> Epoch 96: loss 0.4665; accuracy: 0.8337; best accuracy: 0.8716; test accuracy: 0.7800\n",
      "----> F1: 0.8312; Test F1: 0.7741\n",
      "--> Epoch 97: loss 0.3235; accuracy: 0.8248; best accuracy: 0.8716; test accuracy: 0.7771\n",
      "----> F1: 0.8165; Test F1: 0.7638\n",
      "--> Epoch 98: loss 0.4523; accuracy: 0.7927; best accuracy: 0.8716; test accuracy: 0.7436\n",
      "----> F1: 0.7918; Test F1: 0.7392\n",
      "--> Epoch 99: loss 0.2598; accuracy: 0.8439; best accuracy: 0.8716; test accuracy: 0.8036\n",
      "----> F1: 0.8373; Test F1: 0.7907\n",
      "--> Epoch 100: loss 0.4107; accuracy: 0.8691; best accuracy: 0.8716; test accuracy: 0.8129\n",
      "----> F1: 0.8687; Test F1: 0.8135\n",
      "--> Epoch 101: loss 0.3114; accuracy: 0.8946; best accuracy: 0.8946; test accuracy: 0.8200\n",
      "----> F1: 0.8926; Test F1: 0.8113\n",
      "--> Epoch 102: loss 0.2535; accuracy: 0.8943; best accuracy: 0.8946; test accuracy: 0.8321\n",
      "----> F1: 0.8925; Test F1: 0.8274\n",
      "--> Epoch 103: loss 0.5009; accuracy: 0.8884; best accuracy: 0.8946; test accuracy: 0.8150\n",
      "----> F1: 0.8886; Test F1: 0.8134\n",
      "--> Epoch 104: loss 0.2932; accuracy: 0.8775; best accuracy: 0.8946; test accuracy: 0.8050\n",
      "----> F1: 0.8817; Test F1: 0.8081\n",
      "--> Epoch 105: loss 0.3484; accuracy: 0.8629; best accuracy: 0.8946; test accuracy: 0.8000\n",
      "----> F1: 0.8539; Test F1: 0.7872\n",
      "--> Epoch 106: loss 0.4664; accuracy: 0.8577; best accuracy: 0.8946; test accuracy: 0.7964\n",
      "----> F1: 0.8590; Test F1: 0.7967\n",
      "--> Epoch 107: loss 0.3815; accuracy: 0.8161; best accuracy: 0.8946; test accuracy: 0.7679\n",
      "----> F1: 0.8058; Test F1: 0.7513\n",
      "--> Epoch 108: loss 0.4732; accuracy: 0.7911; best accuracy: 0.8946; test accuracy: 0.7493\n",
      "----> F1: 0.7957; Test F1: 0.7505\n",
      "--> Epoch 109: loss 0.4435; accuracy: 0.8298; best accuracy: 0.8946; test accuracy: 0.7686\n",
      "----> F1: 0.8177; Test F1: 0.7490\n",
      "--> Epoch 110: loss 0.4797; accuracy: 0.8409; best accuracy: 0.8946; test accuracy: 0.8021\n",
      "----> F1: 0.8403; Test F1: 0.7989\n",
      "--> Epoch 111: loss 0.4956; accuracy: 0.8446; best accuracy: 0.8946; test accuracy: 0.7786\n",
      "----> F1: 0.8436; Test F1: 0.7743\n",
      "--> Epoch 112: loss 0.4069; accuracy: 0.8698; best accuracy: 0.8946; test accuracy: 0.8086\n",
      "----> F1: 0.8721; Test F1: 0.8107\n",
      "--> Epoch 113: loss 0.3640; accuracy: 0.8738; best accuracy: 0.8946; test accuracy: 0.8136\n",
      "----> F1: 0.8727; Test F1: 0.8055\n",
      "--> Epoch 114: loss 0.2880; accuracy: 0.8677; best accuracy: 0.8946; test accuracy: 0.7964\n",
      "----> F1: 0.8685; Test F1: 0.7946\n",
      "--> Epoch 115: loss 0.3274; accuracy: 0.8641; best accuracy: 0.8946; test accuracy: 0.7943\n",
      "----> F1: 0.8600; Test F1: 0.7859\n",
      "--> Epoch 116: loss 0.4206; accuracy: 0.8712; best accuracy: 0.8946; test accuracy: 0.7993\n",
      "----> F1: 0.8687; Test F1: 0.7969\n",
      "--> Epoch 117: loss 0.3852; accuracy: 0.8821; best accuracy: 0.8946; test accuracy: 0.8271\n",
      "----> F1: 0.8806; Test F1: 0.8241\n",
      "--> Epoch 118: loss 0.3026; accuracy: 0.8879; best accuracy: 0.8946; test accuracy: 0.8064\n",
      "----> F1: 0.8844; Test F1: 0.7995\n",
      "--> Epoch 119: loss 0.3670; accuracy: 0.8659; best accuracy: 0.8946; test accuracy: 0.8029\n",
      "----> F1: 0.8616; Test F1: 0.7982\n",
      "--> Epoch 120: loss 0.4350; accuracy: 0.9020; best accuracy: 0.9020; test accuracy: 0.8229\n",
      "----> F1: 0.9022; Test F1: 0.8179\n",
      "--> Epoch 121: loss 0.2509; accuracy: 0.8977; best accuracy: 0.9020; test accuracy: 0.8136\n",
      "----> F1: 0.8954; Test F1: 0.8085\n",
      "--> Epoch 122: loss 0.3442; accuracy: 0.8966; best accuracy: 0.9020; test accuracy: 0.8250\n",
      "----> F1: 0.8964; Test F1: 0.8214\n",
      "--> Epoch 123: loss 0.3766; accuracy: 0.8641; best accuracy: 0.9020; test accuracy: 0.7979\n",
      "----> F1: 0.8676; Test F1: 0.7908\n",
      "--> Epoch 124: loss 0.4144; accuracy: 0.8743; best accuracy: 0.9020; test accuracy: 0.8043\n",
      "----> F1: 0.8744; Test F1: 0.7970\n",
      "--> Epoch 125: loss 0.5358; accuracy: 0.8227; best accuracy: 0.9020; test accuracy: 0.7643\n",
      "----> F1: 0.8170; Test F1: 0.7612\n",
      "--> Epoch 126: loss 0.5726; accuracy: 0.8371; best accuracy: 0.9020; test accuracy: 0.7743\n",
      "----> F1: 0.8331; Test F1: 0.7665\n",
      "--> Epoch 127: loss 0.2524; accuracy: 0.8575; best accuracy: 0.9020; test accuracy: 0.7871\n",
      "----> F1: 0.8518; Test F1: 0.7742\n",
      "--> Epoch 128: loss 0.4579; accuracy: 0.8673; best accuracy: 0.9020; test accuracy: 0.7929\n",
      "----> F1: 0.8663; Test F1: 0.7988\n",
      "--> Epoch 129: loss 0.3004; accuracy: 0.8775; best accuracy: 0.9020; test accuracy: 0.8057\n",
      "----> F1: 0.8738; Test F1: 0.7908\n",
      "--> Epoch 130: loss 0.4761; accuracy: 0.8602; best accuracy: 0.9020; test accuracy: 0.7807\n",
      "----> F1: 0.8635; Test F1: 0.7782\n",
      "--> Epoch 131: loss 0.4967; accuracy: 0.8400; best accuracy: 0.9020; test accuracy: 0.7714\n",
      "----> F1: 0.8320; Test F1: 0.7571\n",
      "--> Epoch 132: loss 0.1961; accuracy: 0.8423; best accuracy: 0.9020; test accuracy: 0.7729\n",
      "----> F1: 0.8448; Test F1: 0.7691\n",
      "--> Epoch 133: loss 0.4935; accuracy: 0.8570; best accuracy: 0.9020; test accuracy: 0.7893\n",
      "----> F1: 0.8548; Test F1: 0.7878\n",
      "--> Epoch 134: loss 0.3290; accuracy: 0.8580; best accuracy: 0.9020; test accuracy: 0.7821\n",
      "----> F1: 0.8555; Test F1: 0.7814\n",
      "--> Epoch 135: loss 0.2408; accuracy: 0.8805; best accuracy: 0.9020; test accuracy: 0.8193\n",
      "----> F1: 0.8800; Test F1: 0.8088\n",
      "--> Epoch 136: loss 0.1343; accuracy: 0.8879; best accuracy: 0.9020; test accuracy: 0.8071\n",
      "----> F1: 0.8884; Test F1: 0.8038\n",
      "--> Epoch 137: loss 0.2417; accuracy: 0.8909; best accuracy: 0.9020; test accuracy: 0.8136\n",
      "----> F1: 0.8898; Test F1: 0.8119\n",
      "--> Epoch 138: loss 0.1890; accuracy: 0.8886; best accuracy: 0.9020; test accuracy: 0.8129\n",
      "----> F1: 0.8918; Test F1: 0.8137\n",
      "--> Epoch 139: loss 0.3332; accuracy: 0.8736; best accuracy: 0.9020; test accuracy: 0.8000\n",
      "----> F1: 0.8718; Test F1: 0.7940\n",
      "--> Epoch 140: loss 0.3894; accuracy: 0.8816; best accuracy: 0.9020; test accuracy: 0.8000\n",
      "----> F1: 0.8796; Test F1: 0.7972\n",
      "--> Epoch 141: loss 0.3041; accuracy: 0.8854; best accuracy: 0.9020; test accuracy: 0.8264\n",
      "----> F1: 0.8858; Test F1: 0.8174\n",
      "--> Epoch 142: loss 0.2609; accuracy: 0.9016; best accuracy: 0.9020; test accuracy: 0.8250\n",
      "----> F1: 0.8982; Test F1: 0.8164\n",
      "--> Epoch 143: loss 0.3591; accuracy: 0.9136; best accuracy: 0.9136; test accuracy: 0.8257\n",
      "----> F1: 0.9155; Test F1: 0.8274\n",
      "--> Epoch 144: loss 0.5547; accuracy: 0.8896; best accuracy: 0.9136; test accuracy: 0.8257\n",
      "----> F1: 0.8862; Test F1: 0.8182\n",
      "--> Epoch 145: loss 0.4956; accuracy: 0.8975; best accuracy: 0.9136; test accuracy: 0.8043\n",
      "----> F1: 0.9007; Test F1: 0.8019\n",
      "--> Epoch 146: loss 0.2689; accuracy: 0.8902; best accuracy: 0.9136; test accuracy: 0.8121\n",
      "----> F1: 0.8860; Test F1: 0.8075\n",
      "--> Epoch 147: loss 0.5529; accuracy: 0.9130; best accuracy: 0.9136; test accuracy: 0.8207\n",
      "----> F1: 0.9145; Test F1: 0.8180\n",
      "--> Epoch 148: loss 0.4080; accuracy: 0.9030; best accuracy: 0.9136; test accuracy: 0.8264\n",
      "----> F1: 0.8993; Test F1: 0.8146\n",
      "--> Epoch 149: loss 0.2970; accuracy: 0.8984; best accuracy: 0.9136; test accuracy: 0.7914\n",
      "----> F1: 0.8996; Test F1: 0.7953\n",
      "--> Epoch 150: loss 0.1447; accuracy: 0.8907; best accuracy: 0.9136; test accuracy: 0.8071\n",
      "----> F1: 0.8859; Test F1: 0.7973\n",
      "--> Epoch 151: loss 0.1937; accuracy: 0.9116; best accuracy: 0.9136; test accuracy: 0.8107\n",
      "----> F1: 0.9129; Test F1: 0.8096\n",
      "--> Epoch 152: loss 0.1553; accuracy: 0.8989; best accuracy: 0.9136; test accuracy: 0.8129\n",
      "----> F1: 0.8972; Test F1: 0.8016\n",
      "--> Epoch 153: loss 0.2513; accuracy: 0.8979; best accuracy: 0.9136; test accuracy: 0.8071\n",
      "----> F1: 0.8973; Test F1: 0.8030\n",
      "--> Epoch 154: loss 0.2036; accuracy: 0.8877; best accuracy: 0.9136; test accuracy: 0.8093\n",
      "----> F1: 0.8831; Test F1: 0.8033\n",
      "--> Epoch 155: loss 0.1058; accuracy: 0.9030; best accuracy: 0.9136; test accuracy: 0.8164\n",
      "----> F1: 0.9065; Test F1: 0.8149\n",
      "--> Epoch 156: loss 0.4382; accuracy: 0.8646; best accuracy: 0.9136; test accuracy: 0.7971\n",
      "----> F1: 0.8633; Test F1: 0.7889\n",
      "--> Epoch 157: loss 0.3352; accuracy: 0.9125; best accuracy: 0.9136; test accuracy: 0.8114\n",
      "----> F1: 0.9110; Test F1: 0.8109\n",
      "--> Epoch 158: loss 0.4356; accuracy: 0.8884; best accuracy: 0.9136; test accuracy: 0.8143\n",
      "----> F1: 0.8873; Test F1: 0.8065\n",
      "--> Epoch 159: loss 0.4222; accuracy: 0.9239; best accuracy: 0.9239; test accuracy: 0.8200\n",
      "----> F1: 0.9246; Test F1: 0.8245\n",
      "--> Epoch 160: loss 0.3197; accuracy: 0.9096; best accuracy: 0.9239; test accuracy: 0.8179\n",
      "----> F1: 0.9087; Test F1: 0.8095\n",
      "--> Epoch 161: loss 0.2887; accuracy: 0.9054; best accuracy: 0.9239; test accuracy: 0.7900\n",
      "----> F1: 0.9072; Test F1: 0.7949\n",
      "--> Epoch 162: loss 0.1946; accuracy: 0.9020; best accuracy: 0.9239; test accuracy: 0.8143\n",
      "----> F1: 0.8992; Test F1: 0.8047\n",
      "--> Epoch 163: loss 0.5622; accuracy: 0.8975; best accuracy: 0.9239; test accuracy: 0.8043\n",
      "----> F1: 0.8986; Test F1: 0.8038\n",
      "--> Epoch 164: loss 0.3510; accuracy: 0.8500; best accuracy: 0.9239; test accuracy: 0.7786\n",
      "----> F1: 0.8450; Test F1: 0.7673\n",
      "--> Epoch 165: loss 0.5008; accuracy: 0.8477; best accuracy: 0.9239; test accuracy: 0.7629\n",
      "----> F1: 0.8438; Test F1: 0.7601\n",
      "--> Epoch 166: loss 0.4679; accuracy: 0.8716; best accuracy: 0.9239; test accuracy: 0.7929\n",
      "----> F1: 0.8671; Test F1: 0.7876\n",
      "--> Epoch 167: loss 0.5829; accuracy: 0.8616; best accuracy: 0.9239; test accuracy: 0.7750\n",
      "----> F1: 0.8622; Test F1: 0.7823\n",
      "--> Epoch 168: loss 0.2646; accuracy: 0.9004; best accuracy: 0.9239; test accuracy: 0.8136\n",
      "----> F1: 0.8989; Test F1: 0.8022\n",
      "--> Epoch 169: loss 0.2016; accuracy: 0.9095; best accuracy: 0.9239; test accuracy: 0.8179\n",
      "----> F1: 0.9092; Test F1: 0.8131\n",
      "--> Epoch 170: loss 0.3071; accuracy: 0.9002; best accuracy: 0.9239; test accuracy: 0.8036\n",
      "----> F1: 0.8982; Test F1: 0.7946\n",
      "--> Epoch 171: loss 0.2410; accuracy: 0.9025; best accuracy: 0.9239; test accuracy: 0.8014\n",
      "----> F1: 0.9023; Test F1: 0.8064\n",
      "--> Epoch 172: loss 0.3990; accuracy: 0.8979; best accuracy: 0.9239; test accuracy: 0.7964\n",
      "----> F1: 0.8942; Test F1: 0.7970\n",
      "--> Epoch 173: loss 0.2704; accuracy: 0.9157; best accuracy: 0.9239; test accuracy: 0.8271\n",
      "----> F1: 0.9181; Test F1: 0.8209\n",
      "--> Epoch 174: loss 0.1107; accuracy: 0.9004; best accuracy: 0.9239; test accuracy: 0.8050\n",
      "----> F1: 0.9004; Test F1: 0.8010\n",
      "--> Epoch 175: loss 0.1417; accuracy: 0.9116; best accuracy: 0.9239; test accuracy: 0.8186\n",
      "----> F1: 0.9091; Test F1: 0.8094\n",
      "--> Epoch 176: loss 0.2407; accuracy: 0.9196; best accuracy: 0.9239; test accuracy: 0.8193\n",
      "----> F1: 0.9191; Test F1: 0.8161\n",
      "--> Epoch 177: loss 0.3009; accuracy: 0.9223; best accuracy: 0.9239; test accuracy: 0.8171\n",
      "----> F1: 0.9209; Test F1: 0.8115\n",
      "--> Epoch 178: loss 0.1768; accuracy: 0.9157; best accuracy: 0.9239; test accuracy: 0.8143\n",
      "----> F1: 0.9136; Test F1: 0.8089\n",
      "--> Epoch 179: loss 0.1701; accuracy: 0.9250; best accuracy: 0.9250; test accuracy: 0.8207\n",
      "----> F1: 0.9264; Test F1: 0.8160\n",
      "--> Epoch 180: loss 0.2637; accuracy: 0.9380; best accuracy: 0.9380; test accuracy: 0.8257\n",
      "----> F1: 0.9379; Test F1: 0.8246\n",
      "--> Epoch 181: loss 0.1574; accuracy: 0.9387; best accuracy: 0.9387; test accuracy: 0.8279\n",
      "----> F1: 0.9377; Test F1: 0.8163\n",
      "--> Epoch 182: loss 0.3545; accuracy: 0.9411; best accuracy: 0.9411; test accuracy: 0.8186\n",
      "----> F1: 0.9419; Test F1: 0.8149\n",
      "--> Epoch 183: loss 0.1024; accuracy: 0.9316; best accuracy: 0.9411; test accuracy: 0.8264\n",
      "----> F1: 0.9316; Test F1: 0.8180\n",
      "--> Epoch 184: loss 0.2700; accuracy: 0.9084; best accuracy: 0.9411; test accuracy: 0.7900\n",
      "----> F1: 0.9069; Test F1: 0.7868\n",
      "--> Epoch 185: loss 0.3245; accuracy: 0.8779; best accuracy: 0.9411; test accuracy: 0.7900\n",
      "----> F1: 0.8752; Test F1: 0.7788\n",
      "--> Epoch 186: loss 0.4984; accuracy: 0.8802; best accuracy: 0.9411; test accuracy: 0.7793\n",
      "----> F1: 0.8800; Test F1: 0.7788\n",
      "--> Epoch 187: loss 0.0588; accuracy: 0.9214; best accuracy: 0.9411; test accuracy: 0.8129\n",
      "----> F1: 0.9171; Test F1: 0.8064\n",
      "--> Epoch 188: loss 0.2423; accuracy: 0.9352; best accuracy: 0.9411; test accuracy: 0.8136\n",
      "----> F1: 0.9346; Test F1: 0.8050\n",
      "--> Epoch 189: loss 0.3952; accuracy: 0.9370; best accuracy: 0.9411; test accuracy: 0.8207\n",
      "----> F1: 0.9369; Test F1: 0.8106\n",
      "--> Epoch 190: loss 0.1838; accuracy: 0.9321; best accuracy: 0.9411; test accuracy: 0.7986\n",
      "----> F1: 0.9325; Test F1: 0.8086\n",
      "--> Epoch 191: loss 0.2421; accuracy: 0.9329; best accuracy: 0.9411; test accuracy: 0.8279\n",
      "----> F1: 0.9313; Test F1: 0.8182\n",
      "--> Epoch 192: loss 0.3529; accuracy: 0.9286; best accuracy: 0.9411; test accuracy: 0.7979\n",
      "----> F1: 0.9279; Test F1: 0.7995\n",
      "--> Epoch 193: loss 0.1972; accuracy: 0.9032; best accuracy: 0.9411; test accuracy: 0.7964\n",
      "----> F1: 0.9053; Test F1: 0.7954\n",
      "--> Epoch 194: loss 0.3081; accuracy: 0.9084; best accuracy: 0.9411; test accuracy: 0.7979\n",
      "----> F1: 0.9101; Test F1: 0.7932\n",
      "--> Epoch 195: loss 0.4673; accuracy: 0.9216; best accuracy: 0.9411; test accuracy: 0.8229\n",
      "----> F1: 0.9211; Test F1: 0.8183\n",
      "--> Epoch 196: loss 0.2395; accuracy: 0.9198; best accuracy: 0.9411; test accuracy: 0.7807\n",
      "----> F1: 0.9211; Test F1: 0.7878\n",
      "--> Epoch 197: loss 0.1416; accuracy: 0.9205; best accuracy: 0.9411; test accuracy: 0.8250\n",
      "----> F1: 0.9189; Test F1: 0.8165\n",
      "--> Epoch 198: loss 0.1714; accuracy: 0.9155; best accuracy: 0.9411; test accuracy: 0.7943\n",
      "----> F1: 0.9159; Test F1: 0.7913\n",
      "--> Epoch 199: loss 0.1297; accuracy: 0.9459; best accuracy: 0.9459; test accuracy: 0.8386\n",
      "----> F1: 0.9448; Test F1: 0.8308\n",
      "--> Epoch 200: loss 0.1201; accuracy: 0.9466; best accuracy: 0.9466; test accuracy: 0.8279\n",
      "----> F1: 0.9475; Test F1: 0.8235\n",
      "--> Epoch 201: loss 0.3409; accuracy: 0.9414; best accuracy: 0.9466; test accuracy: 0.8243\n",
      "----> F1: 0.9413; Test F1: 0.8185\n",
      "--> Epoch 202: loss 0.3037; accuracy: 0.9321; best accuracy: 0.9466; test accuracy: 0.8007\n",
      "----> F1: 0.9344; Test F1: 0.8027\n",
      "--> Epoch 203: loss 0.1827; accuracy: 0.9196; best accuracy: 0.9466; test accuracy: 0.8207\n",
      "----> F1: 0.9186; Test F1: 0.8091\n",
      "--> Epoch 204: loss 0.1394; accuracy: 0.9250; best accuracy: 0.9466; test accuracy: 0.7893\n",
      "----> F1: 0.9278; Test F1: 0.7978\n",
      "--> Epoch 205: loss 0.4101; accuracy: 0.9175; best accuracy: 0.9466; test accuracy: 0.8271\n",
      "----> F1: 0.9141; Test F1: 0.8156\n",
      "--> Epoch 206: loss 0.1443; accuracy: 0.9036; best accuracy: 0.9466; test accuracy: 0.7593\n",
      "----> F1: 0.9051; Test F1: 0.7644\n",
      "--> Epoch 207: loss 0.2245; accuracy: 0.9211; best accuracy: 0.9466; test accuracy: 0.8221\n",
      "----> F1: 0.9221; Test F1: 0.8134\n",
      "--> Epoch 208: loss 0.1791; accuracy: 0.9263; best accuracy: 0.9466; test accuracy: 0.8086\n",
      "----> F1: 0.9269; Test F1: 0.8090\n",
      "--> Epoch 209: loss 0.2459; accuracy: 0.9248; best accuracy: 0.9466; test accuracy: 0.8114\n",
      "----> F1: 0.9232; Test F1: 0.8030\n",
      "--> Epoch 210: loss 0.3035; accuracy: 0.9321; best accuracy: 0.9466; test accuracy: 0.8164\n",
      "----> F1: 0.9320; Test F1: 0.8152\n",
      "--> Epoch 211: loss 0.1137; accuracy: 0.9289; best accuracy: 0.9466; test accuracy: 0.8007\n",
      "----> F1: 0.9275; Test F1: 0.7979\n",
      "--> Epoch 212: loss 0.2283; accuracy: 0.9405; best accuracy: 0.9466; test accuracy: 0.8186\n",
      "----> F1: 0.9393; Test F1: 0.8164\n",
      "--> Epoch 213: loss 0.1962; accuracy: 0.9314; best accuracy: 0.9466; test accuracy: 0.8186\n",
      "----> F1: 0.9303; Test F1: 0.8159\n",
      "--> Epoch 214: loss 0.3173; accuracy: 0.9389; best accuracy: 0.9466; test accuracy: 0.8164\n",
      "----> F1: 0.9406; Test F1: 0.8187\n",
      "--> Epoch 215: loss 0.1537; accuracy: 0.9320; best accuracy: 0.9466; test accuracy: 0.8079\n",
      "----> F1: 0.9317; Test F1: 0.8066\n",
      "--> Epoch 216: loss 0.2409; accuracy: 0.9434; best accuracy: 0.9466; test accuracy: 0.8093\n",
      "----> F1: 0.9439; Test F1: 0.8077\n",
      "--> Epoch 217: loss 0.0471; accuracy: 0.9505; best accuracy: 0.9505; test accuracy: 0.8329\n",
      "----> F1: 0.9520; Test F1: 0.8331\n",
      "--> Epoch 218: loss 0.2703; accuracy: 0.9561; best accuracy: 0.9561; test accuracy: 0.8200\n",
      "----> F1: 0.9544; Test F1: 0.8190\n",
      "--> Epoch 219: loss 0.5097; accuracy: 0.9486; best accuracy: 0.9561; test accuracy: 0.8207\n",
      "----> F1: 0.9494; Test F1: 0.8163\n",
      "--> Epoch 220: loss 0.2641; accuracy: 0.9559; best accuracy: 0.9561; test accuracy: 0.8264\n",
      "----> F1: 0.9551; Test F1: 0.8230\n",
      "--> Epoch 221: loss 0.2351; accuracy: 0.9364; best accuracy: 0.9561; test accuracy: 0.8057\n",
      "----> F1: 0.9359; Test F1: 0.8041\n",
      "--> Epoch 222: loss 0.2286; accuracy: 0.9409; best accuracy: 0.9561; test accuracy: 0.8193\n",
      "----> F1: 0.9423; Test F1: 0.8187\n",
      "--> Epoch 223: loss 0.1518; accuracy: 0.9591; best accuracy: 0.9591; test accuracy: 0.8179\n",
      "----> F1: 0.9581; Test F1: 0.8130\n",
      "--> Epoch 224: loss 0.1824; accuracy: 0.9563; best accuracy: 0.9591; test accuracy: 0.8171\n",
      "----> F1: 0.9562; Test F1: 0.8129\n",
      "--> Epoch 225: loss 0.1018; accuracy: 0.9566; best accuracy: 0.9591; test accuracy: 0.8121\n",
      "----> F1: 0.9555; Test F1: 0.8084\n",
      "--> Epoch 226: loss 0.1045; accuracy: 0.9452; best accuracy: 0.9591; test accuracy: 0.8121\n",
      "----> F1: 0.9455; Test F1: 0.8174\n",
      "--> Epoch 227: loss 0.1205; accuracy: 0.9038; best accuracy: 0.9591; test accuracy: 0.7743\n",
      "----> F1: 0.9043; Test F1: 0.7646\n",
      "--> Epoch 228: loss 0.2552; accuracy: 0.9014; best accuracy: 0.9591; test accuracy: 0.7743\n",
      "----> F1: 0.9015; Test F1: 0.7675\n",
      "--> Epoch 229: loss 0.1040; accuracy: 0.8875; best accuracy: 0.9591; test accuracy: 0.7950\n",
      "----> F1: 0.8857; Test F1: 0.7886\n",
      "--> Epoch 230: loss 0.2073; accuracy: 0.9193; best accuracy: 0.9591; test accuracy: 0.7986\n",
      "----> F1: 0.9184; Test F1: 0.7930\n",
      "--> Epoch 231: loss 0.1981; accuracy: 0.9209; best accuracy: 0.9591; test accuracy: 0.7757\n",
      "----> F1: 0.9227; Test F1: 0.7715\n",
      "--> Epoch 232: loss 0.1106; accuracy: 0.9393; best accuracy: 0.9591; test accuracy: 0.8314\n",
      "----> F1: 0.9376; Test F1: 0.8180\n",
      "--> Epoch 233: loss 0.1953; accuracy: 0.9545; best accuracy: 0.9591; test accuracy: 0.8179\n",
      "----> F1: 0.9553; Test F1: 0.8154\n",
      "--> Epoch 234: loss 0.3051; accuracy: 0.9279; best accuracy: 0.9591; test accuracy: 0.8207\n",
      "----> F1: 0.9281; Test F1: 0.8102\n",
      "--> Epoch 235: loss 0.2350; accuracy: 0.9414; best accuracy: 0.9591; test accuracy: 0.8086\n",
      "----> F1: 0.9423; Test F1: 0.8071\n",
      "--> Epoch 236: loss 0.0850; accuracy: 0.9373; best accuracy: 0.9591; test accuracy: 0.8029\n",
      "----> F1: 0.9388; Test F1: 0.7958\n",
      "--> Epoch 237: loss 0.1695; accuracy: 0.9479; best accuracy: 0.9591; test accuracy: 0.8229\n",
      "----> F1: 0.9486; Test F1: 0.8143\n",
      "--> Epoch 238: loss 0.2371; accuracy: 0.9696; best accuracy: 0.9696; test accuracy: 0.8236\n",
      "----> F1: 0.9676; Test F1: 0.8205\n",
      "--> Epoch 239: loss 0.0809; accuracy: 0.9691; best accuracy: 0.9696; test accuracy: 0.8300\n",
      "----> F1: 0.9683; Test F1: 0.8250\n",
      "--> Epoch 240: loss 0.2289; accuracy: 0.9575; best accuracy: 0.9696; test accuracy: 0.8250\n",
      "----> F1: 0.9577; Test F1: 0.8171\n",
      "--> Epoch 241: loss 0.1884; accuracy: 0.9620; best accuracy: 0.9696; test accuracy: 0.8114\n",
      "----> F1: 0.9619; Test F1: 0.8094\n",
      "--> Epoch 242: loss 0.0564; accuracy: 0.9384; best accuracy: 0.9696; test accuracy: 0.8164\n",
      "----> F1: 0.9360; Test F1: 0.8092\n",
      "--> Epoch 243: loss 0.1047; accuracy: 0.9470; best accuracy: 0.9696; test accuracy: 0.8007\n",
      "----> F1: 0.9466; Test F1: 0.8057\n",
      "--> Epoch 244: loss 0.2003; accuracy: 0.9330; best accuracy: 0.9696; test accuracy: 0.8029\n",
      "----> F1: 0.9305; Test F1: 0.7914\n",
      "--> Epoch 245: loss 0.1048; accuracy: 0.9425; best accuracy: 0.9696; test accuracy: 0.7936\n",
      "----> F1: 0.9437; Test F1: 0.7969\n",
      "--> Epoch 246: loss 0.1313; accuracy: 0.9379; best accuracy: 0.9696; test accuracy: 0.8071\n",
      "----> F1: 0.9357; Test F1: 0.7985\n",
      "--> Epoch 247: loss 0.1304; accuracy: 0.9386; best accuracy: 0.9696; test accuracy: 0.7907\n",
      "----> F1: 0.9397; Test F1: 0.7909\n",
      "--> Epoch 248: loss 0.0632; accuracy: 0.9459; best accuracy: 0.9696; test accuracy: 0.8071\n",
      "----> F1: 0.9445; Test F1: 0.7999\n",
      "--> Epoch 249: loss 0.0716; accuracy: 0.9613; best accuracy: 0.9696; test accuracy: 0.8150\n",
      "----> F1: 0.9628; Test F1: 0.8145\n",
      "--> Epoch 250: loss 0.1198; accuracy: 0.9650; best accuracy: 0.9696; test accuracy: 0.8157\n",
      "----> F1: 0.9630; Test F1: 0.8090\n",
      "--> Epoch 251: loss 0.0616; accuracy: 0.9721; best accuracy: 0.9721; test accuracy: 0.8293\n",
      "----> F1: 0.9725; Test F1: 0.8320\n",
      "--> Epoch 252: loss 0.0307; accuracy: 0.9625; best accuracy: 0.9721; test accuracy: 0.8100\n",
      "----> F1: 0.9602; Test F1: 0.8002\n",
      "--> Epoch 253: loss 0.1260; accuracy: 0.9677; best accuracy: 0.9721; test accuracy: 0.8336\n",
      "----> F1: 0.9665; Test F1: 0.8317\n",
      "--> Epoch 254: loss 0.0715; accuracy: 0.9736; best accuracy: 0.9736; test accuracy: 0.8221\n",
      "----> F1: 0.9714; Test F1: 0.8182\n",
      "--> Epoch 255: loss 0.2094; accuracy: 0.9693; best accuracy: 0.9736; test accuracy: 0.8200\n",
      "----> F1: 0.9686; Test F1: 0.8168\n",
      "--> Epoch 256: loss 0.0971; accuracy: 0.9616; best accuracy: 0.9736; test accuracy: 0.8179\n",
      "----> F1: 0.9616; Test F1: 0.8161\n",
      "--> Epoch 257: loss 0.0847; accuracy: 0.9521; best accuracy: 0.9736; test accuracy: 0.8000\n",
      "----> F1: 0.9532; Test F1: 0.7913\n",
      "--> Epoch 258: loss 0.2200; accuracy: 0.9430; best accuracy: 0.9736; test accuracy: 0.8079\n",
      "----> F1: 0.9408; Test F1: 0.8105\n",
      "--> Epoch 259: loss 0.2261; accuracy: 0.9677; best accuracy: 0.9736; test accuracy: 0.8293\n",
      "----> F1: 0.9683; Test F1: 0.8193\n",
      "--> Epoch 260: loss 0.1758; accuracy: 0.9664; best accuracy: 0.9736; test accuracy: 0.8107\n",
      "----> F1: 0.9654; Test F1: 0.8128\n",
      "--> Epoch 261: loss 0.1781; accuracy: 0.9282; best accuracy: 0.9736; test accuracy: 0.7950\n",
      "----> F1: 0.9289; Test F1: 0.7894\n",
      "--> Epoch 262: loss 0.1946; accuracy: 0.9689; best accuracy: 0.9736; test accuracy: 0.8129\n",
      "----> F1: 0.9677; Test F1: 0.8052\n",
      "--> Epoch 263: loss 0.0906; accuracy: 0.9671; best accuracy: 0.9736; test accuracy: 0.8314\n",
      "----> F1: 0.9672; Test F1: 0.8302\n",
      "--> Epoch 264: loss 0.2014; accuracy: 0.9605; best accuracy: 0.9736; test accuracy: 0.8050\n",
      "----> F1: 0.9612; Test F1: 0.8021\n",
      "--> Epoch 265: loss 0.1087; accuracy: 0.9484; best accuracy: 0.9736; test accuracy: 0.7886\n",
      "----> F1: 0.9486; Test F1: 0.7854\n",
      "--> Epoch 266: loss 0.1533; accuracy: 0.9670; best accuracy: 0.9736; test accuracy: 0.8179\n",
      "----> F1: 0.9673; Test F1: 0.8166\n",
      "--> Epoch 267: loss 0.0498; accuracy: 0.9677; best accuracy: 0.9736; test accuracy: 0.8150\n",
      "----> F1: 0.9661; Test F1: 0.8150\n",
      "--> Epoch 268: loss 0.0734; accuracy: 0.9529; best accuracy: 0.9736; test accuracy: 0.8200\n",
      "----> F1: 0.9529; Test F1: 0.8141\n",
      "--> Epoch 269: loss 0.2193; accuracy: 0.9493; best accuracy: 0.9736; test accuracy: 0.8100\n",
      "----> F1: 0.9499; Test F1: 0.8075\n",
      "--> Epoch 270: loss 0.0603; accuracy: 0.9646; best accuracy: 0.9736; test accuracy: 0.8264\n",
      "----> F1: 0.9634; Test F1: 0.8196\n",
      "--> Epoch 271: loss 0.2827; accuracy: 0.9616; best accuracy: 0.9736; test accuracy: 0.8314\n",
      "----> F1: 0.9599; Test F1: 0.8250\n",
      "--> Epoch 272: loss 0.0803; accuracy: 0.9627; best accuracy: 0.9736; test accuracy: 0.8086\n",
      "----> F1: 0.9630; Test F1: 0.8056\n",
      "--> Epoch 273: loss 0.0437; accuracy: 0.9595; best accuracy: 0.9736; test accuracy: 0.8257\n",
      "----> F1: 0.9597; Test F1: 0.8206\n",
      "--> Epoch 274: loss 0.0639; accuracy: 0.9764; best accuracy: 0.9764; test accuracy: 0.8229\n",
      "----> F1: 0.9775; Test F1: 0.8148\n",
      "--> Epoch 275: loss 0.0758; accuracy: 0.9739; best accuracy: 0.9764; test accuracy: 0.8236\n",
      "----> F1: 0.9753; Test F1: 0.8195\n",
      "--> Epoch 276: loss 0.0906; accuracy: 0.9618; best accuracy: 0.9764; test accuracy: 0.8057\n",
      "----> F1: 0.9613; Test F1: 0.8036\n",
      "--> Epoch 277: loss 0.2048; accuracy: 0.9196; best accuracy: 0.9764; test accuracy: 0.7421\n",
      "----> F1: 0.9191; Test F1: 0.7368\n",
      "--> Epoch 278: loss 0.2085; accuracy: 0.9132; best accuracy: 0.9764; test accuracy: 0.7771\n",
      "----> F1: 0.9114; Test F1: 0.7735\n",
      "--> Epoch 279: loss 0.1192; accuracy: 0.9386; best accuracy: 0.9764; test accuracy: 0.8171\n",
      "----> F1: 0.9394; Test F1: 0.8126\n",
      "--> Epoch 280: loss 0.2531; accuracy: 0.9370; best accuracy: 0.9764; test accuracy: 0.8029\n",
      "----> F1: 0.9372; Test F1: 0.8021\n",
      "--> Epoch 281: loss 0.1035; accuracy: 0.9568; best accuracy: 0.9764; test accuracy: 0.8086\n",
      "----> F1: 0.9560; Test F1: 0.8068\n",
      "--> Epoch 282: loss 0.1564; accuracy: 0.9668; best accuracy: 0.9764; test accuracy: 0.8150\n",
      "----> F1: 0.9687; Test F1: 0.8115\n",
      "--> Epoch 283: loss 0.0524; accuracy: 0.9707; best accuracy: 0.9764; test accuracy: 0.8229\n",
      "----> F1: 0.9710; Test F1: 0.8180\n",
      "--> Epoch 284: loss 0.0486; accuracy: 0.9668; best accuracy: 0.9764; test accuracy: 0.8029\n",
      "----> F1: 0.9675; Test F1: 0.7935\n",
      "--> Epoch 285: loss 0.0965; accuracy: 0.9704; best accuracy: 0.9764; test accuracy: 0.8050\n",
      "----> F1: 0.9710; Test F1: 0.8074\n",
      "--> Epoch 286: loss 0.0885; accuracy: 0.9613; best accuracy: 0.9764; test accuracy: 0.8071\n",
      "----> F1: 0.9615; Test F1: 0.8003\n",
      "--> Epoch 287: loss 0.0839; accuracy: 0.9464; best accuracy: 0.9764; test accuracy: 0.7771\n",
      "----> F1: 0.9486; Test F1: 0.7815\n",
      "--> Epoch 288: loss 0.1247; accuracy: 0.9650; best accuracy: 0.9764; test accuracy: 0.8129\n",
      "----> F1: 0.9645; Test F1: 0.8015\n",
      "--> Epoch 289: loss 0.1458; accuracy: 0.9614; best accuracy: 0.9764; test accuracy: 0.8171\n",
      "----> F1: 0.9599; Test F1: 0.8131\n",
      "--> Epoch 290: loss 0.1345; accuracy: 0.9441; best accuracy: 0.9764; test accuracy: 0.7964\n",
      "----> F1: 0.9437; Test F1: 0.7889\n",
      "--> Epoch 291: loss 0.0870; accuracy: 0.9695; best accuracy: 0.9764; test accuracy: 0.8093\n",
      "----> F1: 0.9686; Test F1: 0.8120\n",
      "--> Epoch 292: loss 0.1423; accuracy: 0.9738; best accuracy: 0.9764; test accuracy: 0.8129\n",
      "----> F1: 0.9745; Test F1: 0.8062\n",
      "--> Epoch 293: loss 0.4159; accuracy: 0.9802; best accuracy: 0.9802; test accuracy: 0.8229\n",
      "----> F1: 0.9819; Test F1: 0.8179\n",
      "--> Epoch 294: loss 0.0642; accuracy: 0.9795; best accuracy: 0.9802; test accuracy: 0.8300\n",
      "----> F1: 0.9782; Test F1: 0.8232\n",
      "--> Epoch 295: loss 0.2158; accuracy: 0.9838; best accuracy: 0.9838; test accuracy: 0.8150\n",
      "----> F1: 0.9838; Test F1: 0.8111\n",
      "--> Epoch 296: loss 0.0232; accuracy: 0.9711; best accuracy: 0.9838; test accuracy: 0.8321\n",
      "----> F1: 0.9702; Test F1: 0.8277\n",
      "--> Epoch 297: loss 0.2290; accuracy: 0.9609; best accuracy: 0.9838; test accuracy: 0.7957\n",
      "----> F1: 0.9624; Test F1: 0.7969\n",
      "--> Epoch 298: loss 0.5938; accuracy: 0.9500; best accuracy: 0.9838; test accuracy: 0.8100\n",
      "----> F1: 0.9484; Test F1: 0.8058\n",
      "--> Epoch 299: loss 0.1166; accuracy: 0.9513; best accuracy: 0.9838; test accuracy: 0.7807\n",
      "----> F1: 0.9515; Test F1: 0.7858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3347620/977832602.py:108: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(file_path))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Test Accuracy: 0.8100\n",
      "Final accuracy: 0.8100\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from dtaidistance import dtw\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "        \n",
    "    def log(self, content):\n",
    "        print(content)\n",
    "        self.f.write(content + '\\n')\n",
    "        self.f.flush()\n",
    "\n",
    "def train_model(X, y, train_idx, test_idx, distances, device, K=3, alpha=0.3, epochs=300):\n",
    "    nb_classes = len(np.unique(y))\n",
    "    input_size = X.shape[1]\n",
    "    \n",
    "    model = SimTSC(input_size, nb_classes)\n",
    "    model = model.to(device)\n",
    "    \n",
    "    log_dir = './logs'\n",
    "    os.makedirs(log_dir, exist_ok=True)\n",
    "        \n",
    "    log_path = os.path.join(log_dir, 'simtsc_ecg_log.txt')\n",
    "    with open(log_path, 'w') as f:\n",
    "        logger = Logger(f)\n",
    "        trainer = SimTSCTrainer(device, logger)\n",
    "        \n",
    "        print(\"Iniciando o treinamento...\")\n",
    "        model = trainer.fit(\n",
    "            model, X, y, train_idx, distances, \n",
    "            K, alpha, test_idx=test_idx, \n",
    "            report_test=True, epochs=epochs\n",
    "        )\n",
    "        \n",
    "        acc = trainer.test(model, test_idx)\n",
    "        logger.log(f'--> Test Accuracy: {acc:.4f}')\n",
    "    \n",
    "    return model, acc\n",
    "\n",
    "def process_i(i, X_single, n_samples, r):\n",
    "    \"\"\"\n",
    "    Processa a linha i da matriz de distâncias DTW de forma paralela.\n",
    "    \"\"\"\n",
    "    local_row = np.ascontiguousarray(X_single[i], dtype=np.float64).copy()\n",
    "    local_row.setflags(write=True)  # Garante que é mutável\n",
    "    \n",
    "    dists = []\n",
    "    for j in range(i, n_samples):\n",
    "        target = np.ascontiguousarray(X_single[j], dtype=np.float64).copy()\n",
    "        target.setflags(write=True)  # Garante que é mutável\n",
    "        \n",
    "        dist = dtw.distance_fast(local_row, target, window=r)\n",
    "        dists.append(dist)\n",
    "    \n",
    "    return i, dists\n",
    "\n",
    "def get_dtw_for_ecg_parallel(X, r=100, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Calcula a matriz de distâncias DTW usando paralelismo para acelerar a computação.\n",
    "    \n",
    "    Parâmetros:\n",
    "        X (numpy array): Dados de entrada (shape: [n amostras, canais, comprimento da série]).\n",
    "        r (int): Janela de restrição para o cálculo DTW.\n",
    "        n_jobs (int): Número de núcleos para paralelismo (-1 usa todos disponíveis).\n",
    "    \n",
    "    Retorna:\n",
    "        distances (numpy array): Matriz de distâncias DTW simétrica.\n",
    "    \"\"\"\n",
    "    # Garante que os dados estão no formato correto e mutáveis\n",
    "    X_single = np.asarray(X[:, 0, :], dtype=np.float64).copy()\n",
    "    X_single.setflags(write=True)\n",
    "    \n",
    "    n_samples = X_single.shape[0]\n",
    "    distances = np.zeros((n_samples, n_samples), dtype=np.float64)\n",
    "\n",
    "    print(\"Calculando matriz DTW com paralelismo...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Inicializa a barra de progresso\n",
    "    with tqdm(total=n_samples, desc=\"Calculando DTW\", unit=\"linha\") as pbar:\n",
    "        results = Parallel(n_jobs=n_jobs, backend=\"loky\", return_as=\"generator\")(\n",
    "            delayed(process_i)(i, X_single, n_samples, r) \n",
    "            for i in range(n_samples)\n",
    "        )\n",
    "\n",
    "        # Atualiza a barra de progresso enquanto preenche a matriz\n",
    "        for i, dists in results:\n",
    "            j_indices = np.arange(i, n_samples)\n",
    "            distances[i, j_indices] = dists\n",
    "            distances[j_indices, i] = dists  # Garante simetria\n",
    "            pbar.update(1)  # Atualiza a barra de progresso após cada linha processada\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"\\nCálculo DTW finalizado em {elapsed_time / 60:.2f} minutos.\")\n",
    "\n",
    "    return distances\n",
    "\n",
    "# Configuração do dispositivo\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"--> Dispositivo de treinamento: {device}\")\n",
    "\n",
    "# Pré-processamento com tipos corretos\n",
    "X_norm, y, train_idx, test_idx = get_my_dataset(X)\n",
    "X_norm = X_norm.astype(np.float64).copy()  # Mantém mutável para DTW\n",
    "\n",
    "# Cálculo DTW com paralelismo e barra de progresso\n",
    "distances = get_dtw_for_ecg_parallel(X_norm)\n",
    "\n",
    "# Treinamento (converter para float32 apenas se necessário pelo modelo)\n",
    "X_norm = X_norm.astype(np.float32)  \n",
    "\n",
    "model, test_accuracy = train_model(\n",
    "    X_norm, y, train_idx, test_idx, \n",
    "    distances, device, K=3, alpha=0.3, epochs=300\n",
    ")\n",
    "\n",
    "print(f\"Final accuracy: {test_accuracy:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
