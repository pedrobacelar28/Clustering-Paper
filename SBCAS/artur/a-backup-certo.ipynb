{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import numpy as np\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import neurokit2 as nk\n",
    "import random\n",
    "import networkx as nx\n",
    "import torch\n",
    "from torch_geometric.datasets import KarateClub\n",
    "from torch_geometric.utils import to_networkx # Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import Linear                   # Define layers\n",
    "from torch_geometric.nn import GCNConv\n",
    "from scipy.signal import savgol_filter\n",
    "from scipy.ndimage import gaussian_filter1d \n",
    "import pywt # pip install PyWavelets\n",
    "from scipy.signal import medfilt\n",
    "import cv2 # pip install opencv-python  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARREGAR OS DADOS\n",
    "\n",
    "def carregar_ecgs(unlabel, umdavb, rbbb, lbbb, sb, st, af, filtrado):\n",
    "\n",
    "    caminho_arquivo = \"../../Projeto/Database/exams.csv\"\n",
    "    dados = pd.read_csv(caminho_arquivo)\n",
    "    arquivos_usados = [\"exams_part0.hdf5\", \"exams_part1.hdf5\",\n",
    "                    \"exams_part2.hdf5\", \"exams_part3.hdf5\", \"exams_par4.hdf5\", \"exams_part5.hdf5\",\n",
    "                    \"exams_part6.hdf5\", \"exams_part7.hdf5\", \"exams_par8.hdf5\", \"exams_part9.hdf5\",\n",
    "                    \"exams_part10.hdf5\", \"exams_part11.hdf5\", \"exams_part12.hdf5\", \"exams_part13.hdf5\", \n",
    "                    \"exams_part14.hdf5\", \"exams_part15.hdf5\", \"exams_part16.hdf5\", \"exams_part17.hdf5\"]\n",
    "\n",
    "    ecg_normal_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) ]\n",
    "    \n",
    "    ecg_umdavb_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == True) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_rbbb_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == True) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_lbbb_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == True) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_sb_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == True) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_st_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == True) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_af_linhas = dados.index[(dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == True) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Número de linhas ecg_normal_linhas:\", len(ecg_normal_linhas))\n",
    "    print(\"Número de linhas ecg_umdavb_linhas:\", len(ecg_umdavb_linhas))\n",
    "    print(\"Número de linhas ecg_rbbb_linhas:\", len(ecg_rbbb_linhas))\n",
    "    print(\"Número de linhas ecg_lbbb_linhas:\", len(ecg_lbbb_linhas))\n",
    "    print(\"Número de linhas ecg_sb_linhas:\", len(ecg_sb_linhas))\n",
    "    print(\"Número de linhas ecg_st_linhas:\", len(ecg_st_linhas))\n",
    "    print(\"Número de linhas ecg_af_linhas:\", len(ecg_af_linhas))\n",
    "\n",
    "    caminho_interferencias = \"../../Projeto/Database/resultados_interferencia.csv\"\n",
    "    interferencias = pd.read_csv(caminho_interferencias)\n",
    "    interferencias_ids = interferencias['exam_id'].tolist()\n",
    "\n",
    "    ecg_normal_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) ]\n",
    "    \n",
    "    ecg_umdavb_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == True) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_rbbb_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == True) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_lbbb_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == True) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_sb_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == True) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_st_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == True) &\n",
    "                                    (dados.iloc[:, 9] == False) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "    \n",
    "    ecg_af_linhas = dados.index[~dados['exam_id'].isin(interferencias_ids) &\n",
    "                                    (dados.iloc[:, 14].isin(arquivos_usados)) &\n",
    "                                    (dados.iloc[:, 4] == False) &\n",
    "                                    (dados.iloc[:, 5] == False) &\n",
    "                                    (dados.iloc[:, 6] == False) &\n",
    "                                    (dados.iloc[:, 7] == False) &\n",
    "                                    (dados.iloc[:, 8] == False) &\n",
    "                                    (dados.iloc[:, 9] == True) &\n",
    "                                    (dados.iloc[:, 13] == False)]\n",
    "\n",
    "    print(\"Tirando Interferência:\")\n",
    "    print(\"Número de linhas ecg_normal_linhas:\", len(ecg_normal_linhas))\n",
    "    print(\"Número de linhas ecg_umdavb_linhas:\", len(ecg_umdavb_linhas))\n",
    "    print(\"Número de linhas ecg_rbbb_linhas:\", len(ecg_rbbb_linhas))\n",
    "    print(\"Número de linhas ecg_lbbb_linhas:\", len(ecg_lbbb_linhas))\n",
    "    print(\"Número de linhas ecg_sb_linhas:\", len(ecg_sb_linhas))\n",
    "    print(\"Número de linhas ecg_st_linhas:\", len(ecg_st_linhas))\n",
    "    print(\"Número de linhas ecg_af_linhas:\", len(ecg_af_linhas))\n",
    "\n",
    "    ecg_normal_id = dados.iloc[ecg_normal_linhas, 0].tolist()\n",
    "    ecg_umdavb_id = dados.iloc[ecg_umdavb_linhas, 0].tolist()\n",
    "    ecg_rbbb_id = dados.iloc[ecg_rbbb_linhas, 0].tolist()\n",
    "    ecg_lbbb_id = dados.iloc[ecg_lbbb_linhas, 0].tolist()\n",
    "    ecg_sb_id = dados.iloc[ecg_sb_linhas, 0].tolist()\n",
    "    ecg_st_id = dados.iloc[ecg_st_linhas, 0].tolist()\n",
    "    ecg_af_id = dados.iloc[ecg_af_linhas, 0].tolist()\n",
    "\n",
    "    random.seed(42) \n",
    "\n",
    "    ecg_normal_sample = random.sample(ecg_normal_id, unlabel) if len(ecg_normal_id) >= unlabel else ecg_normal_id\n",
    "    ecg_umdavb_sample = random.sample(ecg_umdavb_id, umdavb) if len(ecg_umdavb_id) >= umdavb else ecg_umdavb_id\n",
    "    ecg_rbbb_sample = random.sample(ecg_rbbb_id, rbbb) if len(ecg_rbbb_id) >= rbbb else ecg_rbbb_id\n",
    "    ecg_lbbb_sample = random.sample(ecg_lbbb_id, lbbb) if len(ecg_lbbb_id) >= lbbb else ecg_lbbb_id\n",
    "    ecg_sb_sample = random.sample(ecg_sb_id, sb) if len(ecg_sb_id) >= sb else ecg_sb_id\n",
    "    ecg_st_sample = random.sample(ecg_st_id, st) if len(ecg_st_id) >= st else ecg_st_id\n",
    "    ecg_af_sample = random.sample(ecg_af_id, af) if len(ecg_af_id) >= af else ecg_af_id\n",
    "\n",
    "    ids_ecgs = ecg_normal_sample + ecg_umdavb_sample + ecg_rbbb_sample + ecg_lbbb_sample + ecg_sb_sample + ecg_st_sample + ecg_af_sample\n",
    "\n",
    "    print(\"Número de ecgs pra usar:\", len(ids_ecgs))\n",
    "\n",
    "    \n",
    "    if filtrado == True: arquivos_hdf5 = [\"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_0_1.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_2_3.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_4_5.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_6_7.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_8_9.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_10_11.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_12_13.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_14_15.hdf5\",\n",
    "                        \"/scratch/guilherme.evangelista/Clustering-Paper/Projeto/Database/filtered_exams_16_17.hdf5\"]\n",
    "    \n",
    "    else: arquivos_hdf5 = ['/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part0.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part1.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part2.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part3.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part4.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part5.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part6.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part7.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part8.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part9.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part10.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part11.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part12.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part13.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part14.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part15.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part16.hdf5',\n",
    "                 '/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams_part17.hdf5']\n",
    "        \n",
    "    \n",
    "\n",
    "    def get_ecg_data(file_path, exam_id):\n",
    "        with h5py.File(file_path, 'r') as f:\n",
    "            # Obter os IDs dos exames\n",
    "            exam_ids = np.array(f['exam_id'])\n",
    "\n",
    "            # Encontrar o índice correspondente ao exam_id de interesse\n",
    "            exam_index = np.where(exam_ids == exam_id)[0]\n",
    "\n",
    "            if len(exam_index) == 0:\n",
    "                raise ValueError(\"Exam ID não encontrado.\")\n",
    "            else:\n",
    "                exam_index = exam_index[0]\n",
    "                # Acessar os tracings de ECG correspondentes ao exam_index\n",
    "                exam_tracings = f['tracings'][exam_index]\n",
    "                # Preencher tracings nulos com epsilon\n",
    "                return exam_tracings\n",
    "\n",
    "    exam_ids_to_cluster = ids_ecgs  # Substitua pelos IDs reais dos exames\n",
    "\n",
    "    # Lista para armazenar todos os tracings de ECG\n",
    "    all_tracings = []\n",
    "\n",
    "    # Obter os tracings de ECG para cada exam_id e armazenar na lista\n",
    "    for exam_id in exam_ids_to_cluster:\n",
    "        found = False  # Sinalizador para verificar se o exame foi encontrado em algum arquivo\n",
    "        for arquivo in arquivos_hdf5:\n",
    "            try:\n",
    "                tracings = get_ecg_data(arquivo, exam_id)\n",
    "                if tracings is not None:\n",
    "                    tracing_transposto = np.array(tracings).T\n",
    "                    all_tracings.append(tracing_transposto)\n",
    "                    found = True  # Sinalizador para indicar que o exame foi encontrado\n",
    "                    break  # Se encontrou, não precisa continuar buscando nos outros arquivos\n",
    "            except ValueError as e:\n",
    "                i = 0\n",
    "            except Exception as e:\n",
    "                i = 0\n",
    "        \n",
    "        if not found:\n",
    "            print(f\"Erro: exame ID {exam_id} não encontrado em nenhum dos arquivos.\")\n",
    "\n",
    "    # Verifique o tamanho da lista all_tracings para garantir que os dados foram coletados corretamente\n",
    "    print(\"Número de ecgs que eram pra ser processados:\", len(ids_ecgs))\n",
    "    print(f\"Número total de traçados processados: {len(all_tracings)}\")\n",
    "\n",
    "    # X será um array com um único array dentro, contendo todos os números do tracings.T\n",
    "    X = np.array(all_tracings)\n",
    "    return X , ids_ecgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_my_dataset(X, unlabel=100,umdavb=100,rbbb=100,lbbb=100,sb=100,st=100,af=100,train_ratio=0.8):\n",
    "    \"\"\"\n",
    "    Prepara o dataset de ECG para o treinamento.\n",
    "    \n",
    "    Parâmetros:\n",
    "      - X: array de ECG (formato: [n_samples, n_channels, length])\n",
    "      - os números de amostras por classe (deve coincidir com a ordem de concatenação na função carregar_ecgs)\n",
    "      - train_ratio: proporção dos dados para treinamento\n",
    "      \n",
    "    Retorna:\n",
    "      - X (possivelmente normalizado),\n",
    "      - y: vetor de labels (0: normal, 1: umdavb, 2: rbbb, 3: lbbb, 4: sb, 5: st, 6: af)\n",
    "      - train_idx: índices de treinamento\n",
    "      - test_idx: índices de teste\n",
    "    \"\"\"\n",
    "    \n",
    "    total_samples = unlabel + umdavb + rbbb + lbbb + sb + st + af\n",
    "    if X.shape[0] != total_samples:\n",
    "        raise ValueError(f\"O número de traçados em X ({X.shape[0]}) não corresponde à soma esperada ({total_samples}).\")\n",
    "    \n",
    "    # Cria os labels de acordo com a ordem de concatenação\n",
    "    y = np.array([0]*unlabel + \n",
    "                 [1]*umdavb + \n",
    "                 [2]*rbbb + \n",
    "                 [3]*lbbb + \n",
    "                 [4]*sb + \n",
    "                 [5]*st + \n",
    "                 [6]*af)\n",
    "    \n",
    "    # Aqui assumimos que a normalização é feita sobre o último eixo (tempo)\n",
    "    X_norm = X.copy().astype(np.float32)\n",
    "    for i in range(X_norm.shape[0]):\n",
    "        # Evita divisão por zero\n",
    "        mean_val = X_norm[i].mean()\n",
    "        std_val = X_norm[i].std() if X_norm[i].std() != 0 else 1.0\n",
    "        X_norm[i] = (X_norm[i] - mean_val) / std_val\n",
    "    \n",
    "    # Cria a divisão em treinamento e teste (shuffle dos índices)\n",
    "    indices = np.arange(total_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    split = int(train_ratio * total_samples)\n",
    "    train_idx = indices[:split]\n",
    "    test_idx = indices[split:]\n",
    "    \n",
    "    return X_norm, y, train_idx, test_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "import torch.utils.data\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "class SimTSCTrainer:\n",
    "    def __init__(self, device, logger):\n",
    "        \"\"\"\n",
    "        device: Ex.: torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        logger: um objeto com método .log() para imprimir e/ou salvar logs.\n",
    "        \"\"\"\n",
    "        self.device = device\n",
    "        self.logger = logger\n",
    "        \n",
    "        # Diretório temporário, se necessário\n",
    "        self.tmp_dir = 'tmp'\n",
    "        if not os.path.exists(self.tmp_dir):\n",
    "            os.makedirs(self.tmp_dir)\n",
    "\n",
    "\n",
    "    def fit(self, model, X, y, train_idx, distances, K, alpha,\n",
    "            test_idx=None, report_test=False, batch_size=128, epochs=300):\n",
    "        \"\"\"\n",
    "        Treina o modelo SimTSC com base em:\n",
    "         - X: Tensores de ECG (torch.Tensor ou np.array convertido para torch.Tensor).\n",
    "         - y: Rótulos das classes.\n",
    "         - train_idx: Índices das amostras de treinamento.\n",
    "         - distances: Matriz de distâncias (float32) entre TODAS as amostras.\n",
    "         - K, alpha: Hiperparâmetros usados na construção do grafo.\n",
    "         - test_idx: Índices das amostras de teste (opcional).\n",
    "         - report_test: Se True, faz avaliação no conjunto de teste ao fim de cada época.\n",
    "         - batch_size: Tamanho do lote total (será dividido entre batch principal e \"outros\").\n",
    "         - epochs: Número de épocas de treinamento.\n",
    "         \n",
    "        Retorna o modelo com parâmetros carregados no melhor checkpoint (em acurácia).\n",
    "        \"\"\"\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # Garante que X e y sejam tensores no device\n",
    "        if not isinstance(X, torch.Tensor):\n",
    "            X = torch.from_numpy(X)\n",
    "        if not isinstance(y, torch.Tensor):\n",
    "            y = torch.from_numpy(y)\n",
    "        \n",
    "        self.X = X.to(self.device)\n",
    "        self.y = y.to(self.device)\n",
    "        \n",
    "        # distances deve ser np.array ou torch.Tensor; converte para Tensor float32\n",
    "        if not torch.is_tensor(distances):\n",
    "            distances = torch.from_numpy(distances.astype(np.float32))\n",
    "        self.adj = distances  # Armazenamos para uso no teste\n",
    "\n",
    "        # Divisão do batch em train_batch_size + other_batch_size\n",
    "        # As \"other\" samples servem para manter o subgrafo coerente\n",
    "        train_batch_size = min(batch_size // 2, len(train_idx))\n",
    "        other_idx = np.array([i for i in range(len(X)) if i not in train_idx])\n",
    "        other_batch_size = min(batch_size - train_batch_size, len(other_idx))\n",
    "        \n",
    "        # DataLoader para as amostras de treino\n",
    "        train_dataset = Dataset(train_idx)\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                                   batch_size=train_batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   num_workers=1)\n",
    "        \n",
    "        # Caso queiramos relatar métricas de teste a cada epoch\n",
    "        if report_test and test_idx is not None:\n",
    "            test_batch_size = min(batch_size // 2, len(test_idx))\n",
    "            other_idx_test = np.array([i for i in range(len(X)) if i not in test_idx])\n",
    "            other_batch_size_test = min(batch_size - test_batch_size, len(other_idx_test))\n",
    "            \n",
    "            test_dataset = Dataset(test_idx)\n",
    "            test_loader = torch.utils.data.DataLoader(test_dataset,\n",
    "                                                      batch_size=test_batch_size,\n",
    "                                                      shuffle=True,\n",
    "                                                      num_workers=1)\n",
    "        \n",
    "        # Otimizador\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=4e-3)\n",
    "        \n",
    "        # Checkpoint\n",
    "        file_path = os.path.join(self.tmp_dir, str(uuid.uuid4()))\n",
    "        best_acc = 0.0\n",
    "        \n",
    "        # Loop de treinamento\n",
    "        for epoch in range(epochs):\n",
    "            model.train()\n",
    "            epoch_losses = []\n",
    "            \n",
    "            # Loop pelos batches de treino\n",
    "            for sampled_train_idx in train_loader:\n",
    "                # Gera \"other\" para compor o subgrafo\n",
    "                sampled_other_idx = np.random.choice(other_idx, other_batch_size, replace=False)\n",
    "                idx = np.concatenate((sampled_train_idx, sampled_other_idx))\n",
    "                \n",
    "                # Monta tensores\n",
    "                _X = self.X[idx]\n",
    "                _y = self.y[sampled_train_idx]  # Rótulos apenas do batch principal\n",
    "                _adj = self.adj[idx][:, idx].to(self.device)\n",
    "\n",
    "                # Forward\n",
    "                outputs = model(_X, _adj, K, alpha)\n",
    "                # A parte de \"outputs\" referente ao batch principal é a [:len(sampled_train_idx)]\n",
    "                loss = F.nll_loss(outputs[:len(sampled_train_idx)], _y)\n",
    "                \n",
    "                # Backprop\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_losses.append(loss.item())\n",
    "            \n",
    "            # Avalia no final de cada época\n",
    "            model.eval()\n",
    "            \n",
    "            # Precisamos calcular a acurácia no treino ou no test?\n",
    "            # Aqui, calculamos no conjunto de treino (sem logging de F1, mas poderíamos).\n",
    "            acc = self._compute_accuracy(\n",
    "                model, self.X, self.y, self.adj, self.K, self.alpha,\n",
    "                train_loader, other_idx, other_batch_size\n",
    "            )\n",
    "            \n",
    "            # Verifica se essa é a melhor acurácia até agora\n",
    "            if acc >= best_acc:\n",
    "                best_acc = acc\n",
    "                torch.save(model.state_dict(), file_path)\n",
    "\n",
    "            # Se quisermos também relatar métricas no conjunto de teste\n",
    "            if report_test and test_idx is not None:\n",
    "                test_acc = self._compute_accuracy(\n",
    "                    model, self.X, self.y, self.adj, self.K, self.alpha,\n",
    "                    test_loader, other_idx_test, other_batch_size_test\n",
    "                )\n",
    "                # Podemos também computar F1 no teste\n",
    "                test_f1 = self._compute_f1(\n",
    "                    model, self.X, self.y, self.adj, self.K, self.alpha,\n",
    "                    test_loader, other_idx_test, other_batch_size_test\n",
    "                )\n",
    "                \n",
    "                mean_loss_epoch = np.mean(epoch_losses) if epoch_losses else 0.0\n",
    "                self.logger.log(\n",
    "                    f\"[Epoch {epoch}] Loss Treino: {mean_loss_epoch:.4f} | \"\n",
    "                    f\"Acurácia Treino: {acc:.4f} | Melhor Treino: {best_acc:.4f} | \"\n",
    "                    f\"Acurácia Teste: {test_acc:.4f} | F1 Teste: {test_f1:.4f}\"\n",
    "                )\n",
    "            else:\n",
    "                mean_loss_epoch = np.mean(epoch_losses) if epoch_losses else 0.0\n",
    "                self.logger.log(\n",
    "                    f\"[Epoch {epoch}] Loss Treino: {mean_loss_epoch:.4f} | \"\n",
    "                    f\"Acurácia Treino: {acc:.4f} | Melhor Treino: {best_acc:.4f}\"\n",
    "                )\n",
    "        \n",
    "        # Carrega o melhor checkpoint\n",
    "        model.load_state_dict(torch.load(file_path))\n",
    "        model.eval()\n",
    "        os.remove(file_path)\n",
    "        \n",
    "        return model\n",
    "\n",
    "\n",
    "    def test(self, model, test_idx, batch_size=128):\n",
    "        \"\"\"\n",
    "        Realiza o teste usando exatamente o mesmo esquema de subgrafo adotado no treinamento:\n",
    "         - Cria batch de teste\n",
    "         - Concatena com some \"other_idx_test\"\n",
    "         - Calcula forward no subgrafo e extrai métricas apenas das amostras do batch.\n",
    "         \n",
    "        Retorna:\n",
    "         - Um dicionário com:\n",
    "             'loss': loss média no conjunto de teste\n",
    "             'accuracy': acurácia final\n",
    "             'f1_macro': F1 média\n",
    "             'f1_per_class': array com F1 de cada classe\n",
    "        \"\"\"\n",
    "\n",
    "        # Preparação: tam. do batch e \"other\" no teste\n",
    "        test_batch_size = min(batch_size // 2, len(test_idx))\n",
    "        other_idx_test = np.array([i for i in range(len(self.X)) if i not in test_idx])\n",
    "        other_batch_size_test = min(batch_size - test_batch_size, len(other_idx_test))\n",
    "        \n",
    "        # DataLoader para o conjunto de teste\n",
    "        test_dataset = Dataset(test_idx)\n",
    "        test_loader = torch.utils.data.DataLoader(test_dataset, \n",
    "                                                 batch_size=test_batch_size, \n",
    "                                                 shuffle=True, \n",
    "                                                 num_workers=1)\n",
    "        \n",
    "        # Variáveis para acumular perda e computar métricas\n",
    "        total_loss = 0.0\n",
    "        total_count = 0\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        \n",
    "        # Modo eval\n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for batch_indices in test_loader:\n",
    "                # Seleciona \"others\"\n",
    "                sampled_other_idx = np.random.choice(other_idx_test, \n",
    "                                                     other_batch_size_test, \n",
    "                                                     replace=False)\n",
    "                combined_idx = np.concatenate((batch_indices, sampled_other_idx))\n",
    "                \n",
    "                # Monta tensores\n",
    "                _X = self.X[combined_idx]\n",
    "                _adj = self.adj[combined_idx][:, combined_idx].to(self.device)\n",
    "                \n",
    "                # Forward\n",
    "                outputs = model(_X, _adj, self.K, self.alpha)\n",
    "                \n",
    "                # Parte principal do lote\n",
    "                main_outputs = outputs[:len(batch_indices)]\n",
    "                main_labels = self.y[batch_indices]\n",
    "                \n",
    "                # Loss\n",
    "                batch_loss = F.nll_loss(main_outputs, main_labels, reduction='sum')\n",
    "                total_loss += batch_loss.item()\n",
    "                total_count += len(batch_indices)\n",
    "                \n",
    "                # Predições\n",
    "                preds = main_outputs.argmax(dim=1).cpu().numpy()\n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(main_labels.cpu().numpy())\n",
    "        \n",
    "        # Loss média\n",
    "        mean_loss = total_loss / total_count if total_count > 0 else 0.0\n",
    "        \n",
    "        # Acurácia\n",
    "        all_preds = np.array(all_preds)\n",
    "        all_labels = np.array(all_labels)\n",
    "        correct = (all_preds == all_labels).sum()\n",
    "        accuracy = correct / total_count if total_count > 0 else 0.0\n",
    "        \n",
    "        # F1\n",
    "        f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
    "        f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
    "        \n",
    "        # Log, se quiser\n",
    "        self.logger.log(f\"[TEST] Loss: {mean_loss:.4f} | Acc: {accuracy:.4f} | \"\n",
    "                        f\"F1(macro): {f1_macro:.4f} | F1 por classe: {f1_per_class}\")\n",
    "        \n",
    "        return {\n",
    "            'loss': mean_loss,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_macro': f1_macro,\n",
    "            'f1_per_class': f1_per_class\n",
    "        }\n",
    "\n",
    "\n",
    "    ###########################################################################\n",
    "    # Funções auxiliares internas para cálculo de acurácia e F1 no fit\n",
    "    ###########################################################################\n",
    "    def _compute_accuracy(self, model, X, y, adj, K, alpha,\n",
    "                         loader, other_idx, other_batch_size):\n",
    "        \"\"\"\n",
    "        Computa a acurácia, reproduzindo o esquema: (batch + other_idx).\n",
    "        \"\"\"\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx in loader:\n",
    "                # Monta as amostras \"externas\"\n",
    "                sampled_other_idx = np.random.choice(other_idx, other_batch_size, replace=False)\n",
    "                combined_idx = np.concatenate((batch_idx, sampled_other_idx))\n",
    "                _X = X[combined_idx]\n",
    "                _y = y[batch_idx]\n",
    "                _adj = adj[combined_idx][:, combined_idx].to(self.device)\n",
    "                \n",
    "                outputs = model(_X, _adj, K, alpha)\n",
    "                main_outputs = outputs[:len(batch_idx)]\n",
    "                preds = main_outputs.argmax(dim=1)\n",
    "                \n",
    "                correct += (preds == _y).sum().item()\n",
    "                total += len(batch_idx)\n",
    "        \n",
    "        return correct / total if total > 0 else 0.0\n",
    "\n",
    "    def _compute_f1(self, model, X, y, adj, K, alpha,\n",
    "                    loader, other_idx, other_batch_size):\n",
    "        \"\"\"\n",
    "        Computa o F1 (macro) usando o mesmo esquema de (batch + other_idx).\n",
    "        \"\"\"\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        with torch.no_grad():\n",
    "            for batch_idx in loader:\n",
    "                # Mesma lógica de subgrafo\n",
    "                sampled_other_idx = np.random.choice(other_idx, other_batch_size, replace=False)\n",
    "                combined_idx = np.concatenate((batch_idx, sampled_other_idx))\n",
    "                _X = X[combined_idx]\n",
    "                _y = y[batch_idx]\n",
    "                _adj = adj[combined_idx][:, combined_idx].to(self.device)\n",
    "                \n",
    "                outputs = model(_X, _adj, K, alpha)\n",
    "                main_outputs = outputs[:len(batch_idx)]\n",
    "                \n",
    "                preds = main_outputs.argmax(dim=1).cpu().numpy()\n",
    "                labels = _y.cpu().numpy()\n",
    "                \n",
    "                all_preds.extend(preds)\n",
    "                all_labels.extend(labels)\n",
    "        \n",
    "        if len(all_preds) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        return f1_score(all_labels, all_preds, average='macro')\n",
    "\n",
    "\n",
    "class SimTSC(nn.Module):\n",
    "    def __init__(self, input_size, nb_classes, num_layers=1, n_feature_maps=64, dropout=0.5):\n",
    "        super(SimTSC, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.block_1 = ResNetBlock(input_size, n_feature_maps)\n",
    "        self.block_2 = ResNetBlock(n_feature_maps, n_feature_maps)\n",
    "        self.block_3 = ResNetBlock(n_feature_maps, n_feature_maps)\n",
    "        if self.num_layers == 1:\n",
    "            self.gc1 = GraphConvolution(n_feature_maps, nb_classes)\n",
    "        elif self.num_layers == 2:\n",
    "            self.gc1 = GraphConvolution(n_feature_maps, n_feature_maps)\n",
    "            self.gc2 = GraphConvolution(n_feature_maps, nb_classes)\n",
    "            self.dropout = dropout\n",
    "        elif self.num_layers == 3:\n",
    "            self.gc1 = GraphConvolution(n_feature_maps, n_feature_maps)\n",
    "            self.gc2 = GraphConvolution(n_feature_maps, n_feature_maps)\n",
    "            self.gc3 = GraphConvolution(n_feature_maps, nb_classes)\n",
    "            self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj, K, alpha):\n",
    "        ranks = torch.argsort(adj, dim=1)\n",
    "        sparse_index = [[], []]\n",
    "        sparse_value = []\n",
    "        for i in range(len(adj)):\n",
    "            _sparse_value = []\n",
    "            for j in ranks[i][:K]:\n",
    "                sparse_index[0].append(i)\n",
    "                sparse_index[1].append(j)\n",
    "                _sparse_value.append(1/np.exp(alpha * adj[i][j].cpu().item()))\n",
    "            _sparse_value = np.array(_sparse_value)\n",
    "            _sparse_value /= _sparse_value.sum()\n",
    "            sparse_value.extend(_sparse_value.tolist())\n",
    "        sparse_index = torch.LongTensor(sparse_index)\n",
    "        sparse_value = torch.FloatTensor(sparse_value)\n",
    "        adj = torch.sparse.FloatTensor(sparse_index, sparse_value, adj.size())\n",
    "        device = self.gc1.bias.device\n",
    "        adj = adj.to(device)\n",
    "\n",
    "        x = self.block_1(x)\n",
    "        x = self.block_2(x)\n",
    "        x = self.block_3(x)\n",
    "        x = F.avg_pool1d(x, x.shape[-1]).squeeze()\n",
    "\n",
    "        if self.num_layers == 1:\n",
    "            x = self.gc1(x, adj)\n",
    "        elif self.num_layers == 2:\n",
    "            x = F.relu(self.gc1(x, adj))\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = self.gc2(x, adj)\n",
    "        elif self.num_layers == 3:\n",
    "            x = F.relu(self.gc1(x, adj))\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = F.relu(self.gc2(x, adj))\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = self.gc3(x, adj)\n",
    "\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "class GraphConvolution(Module):\n",
    "    def __init__(self, in_features, out_features, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1. / math.sqrt(self.weight.size(0))\n",
    "        self.weight.data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj):\n",
    "        support = torch.mm(input, self.weight)\n",
    "        output = torch.spmm(adj, support)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.expand = True if in_channels < out_channels else False\n",
    "        self.conv_x = nn.Conv1d(in_channels, out_channels, 7, padding=3)\n",
    "        self.bn_x = nn.BatchNorm1d(out_channels)\n",
    "        self.conv_y = nn.Conv1d(out_channels, out_channels, 5, padding=2)\n",
    "        self.bn_y = nn.BatchNorm1d(out_channels)\n",
    "        self.conv_z = nn.Conv1d(out_channels, out_channels, 3, padding=1)\n",
    "        self.bn_z = nn.BatchNorm1d(out_channels)\n",
    "        if self.expand:\n",
    "            self.shortcut_y = nn.Conv1d(in_channels, out_channels, 1)\n",
    "        self.bn_shortcut_y = nn.BatchNorm1d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn_x(self.conv_x(x)))\n",
    "        out = F.relu(self.bn_y(self.conv_y(out)))\n",
    "        out = self.bn_z(self.conv_z(out))\n",
    "        if self.expand:\n",
    "            x = self.shortcut_y(x)\n",
    "        x = self.bn_shortcut_y(x)\n",
    "        out += x\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, idx):\n",
    "        self.idx = idx\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.idx[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.idx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de linhas ecg_normal_linhas: 272407\n",
      "Número de linhas ecg_umdavb_linhas: 3735\n",
      "Número de linhas ecg_rbbb_linhas: 6808\n",
      "Número de linhas ecg_lbbb_linhas: 4176\n",
      "Número de linhas ecg_sb_linhas: 4300\n",
      "Número de linhas ecg_st_linhas: 6146\n",
      "Número de linhas ecg_af_linhas: 4964\n",
      "Tirando Interferência:\n",
      "Número de linhas ecg_normal_linhas: 252167\n",
      "Número de linhas ecg_umdavb_linhas: 3651\n",
      "Número de linhas ecg_rbbb_linhas: 6703\n",
      "Número de linhas ecg_lbbb_linhas: 4122\n",
      "Número de linhas ecg_sb_linhas: 4248\n",
      "Número de linhas ecg_st_linhas: 6038\n",
      "Número de linhas ecg_af_linhas: 4804\n",
      "Número de ecgs pra usar: 7000\n",
      "Número de ecgs que eram pra ser processados: 7000\n",
      "Número total de traçados processados: 7000\n",
      "X_norm shape: (7000, 12, 4096)\n",
      "Tamanho do y: 7000\n",
      "Número de amostras em train_idx: 5600\n",
      "Número de amostras em test_idx: 1400\n"
     ]
    }
   ],
   "source": [
    "# 1) Carregar e preparar dados\n",
    "X, ids_ecgs = carregar_ecgs(\n",
    "    unlabel=1000, umdavb=1000, rbbb=1000,\n",
    "    lbbb=1000, sb=1000, st=1000, af=1000,\n",
    "    filtrado=True\n",
    ")\n",
    "\n",
    "# Aqui fazemos a separação e normalização (exemplo com 80% train, 20% test)\n",
    "X_norm, y, train_idx, test_idx = get_my_dataset(\n",
    "    X, \n",
    "    unlabel=1000, umdavb=1000, rbbb=1000,\n",
    "    lbbb=1000, sb=1000, st=1000, af=1000,\n",
    "    train_ratio=0.8\n",
    ")\n",
    "print(\"X_norm shape:\", X_norm.shape)\n",
    "print(\"Tamanho do y:\", len(y))\n",
    "print(\"Número de amostras em train_idx:\", len(train_idx))\n",
    "print(\"Número de amostras em test_idx:\", len(test_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculando matriz DTW com paralelismo...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculando DTW: 100%|██████████| 7000/7000 [47:42<00:00,  2.45linha/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cálculo DTW finalizado em 47.70 minutos.\n",
      "Matriz de distâncias calculada com shape: (7000, 7000)\n",
      "Usando device: cuda\n",
      "Iniciando treinamento...\n",
      "[Epoch 0] Loss Treino: 1.6239 | Acurácia Treino: 0.5520 | Melhor Treino: 0.5520 | Acurácia Teste: 0.5193 | F1 Teste: 0.4827\n",
      "[Epoch 1] Loss Treino: 1.3185 | Acurácia Treino: 0.6179 | Melhor Treino: 0.6179 | Acurácia Teste: 0.5821 | F1 Teste: 0.5604\n",
      "[Epoch 2] Loss Treino: 1.1900 | Acurácia Treino: 0.6423 | Melhor Treino: 0.6423 | Acurácia Teste: 0.6107 | F1 Teste: 0.5840\n",
      "[Epoch 3] Loss Treino: 1.1017 | Acurácia Treino: 0.6580 | Melhor Treino: 0.6580 | Acurácia Teste: 0.6100 | F1 Teste: 0.5990\n",
      "[Epoch 4] Loss Treino: 1.0349 | Acurácia Treino: 0.6989 | Melhor Treino: 0.6989 | Acurácia Teste: 0.6679 | F1 Teste: 0.6562\n",
      "[Epoch 5] Loss Treino: 0.9770 | Acurácia Treino: 0.7155 | Melhor Treino: 0.7155 | Acurácia Teste: 0.6986 | F1 Teste: 0.6775\n",
      "[Epoch 6] Loss Treino: 0.9318 | Acurácia Treino: 0.7496 | Melhor Treino: 0.7496 | Acurácia Teste: 0.7129 | F1 Teste: 0.7094\n",
      "[Epoch 7] Loss Treino: 0.8838 | Acurácia Treino: 0.7223 | Melhor Treino: 0.7496 | Acurácia Teste: 0.6850 | F1 Teste: 0.6684\n",
      "[Epoch 8] Loss Treino: 0.8438 | Acurácia Treino: 0.7339 | Melhor Treino: 0.7496 | Acurácia Teste: 0.7064 | F1 Teste: 0.6958\n",
      "[Epoch 9] Loss Treino: 0.8108 | Acurácia Treino: 0.7802 | Melhor Treino: 0.7802 | Acurácia Teste: 0.7293 | F1 Teste: 0.7254\n",
      "[Epoch 10] Loss Treino: 0.7802 | Acurácia Treino: 0.8027 | Melhor Treino: 0.8027 | Acurácia Teste: 0.7457 | F1 Teste: 0.7429\n",
      "[Epoch 11] Loss Treino: 0.7540 | Acurácia Treino: 0.7768 | Melhor Treino: 0.8027 | Acurácia Teste: 0.7321 | F1 Teste: 0.7310\n",
      "[Epoch 12] Loss Treino: 0.7280 | Acurácia Treino: 0.8021 | Melhor Treino: 0.8027 | Acurácia Teste: 0.7464 | F1 Teste: 0.7452\n",
      "[Epoch 13] Loss Treino: 0.7004 | Acurácia Treino: 0.7712 | Melhor Treino: 0.8027 | Acurácia Teste: 0.7071 | F1 Teste: 0.6967\n",
      "[Epoch 14] Loss Treino: 0.6825 | Acurácia Treino: 0.8248 | Melhor Treino: 0.8248 | Acurácia Teste: 0.7643 | F1 Teste: 0.7624\n",
      "[Epoch 15] Loss Treino: 0.6551 | Acurácia Treino: 0.8352 | Melhor Treino: 0.8352 | Acurácia Teste: 0.7664 | F1 Teste: 0.7669\n",
      "[Epoch 16] Loss Treino: 0.6305 | Acurácia Treino: 0.8237 | Melhor Treino: 0.8352 | Acurácia Teste: 0.7671 | F1 Teste: 0.7600\n",
      "[Epoch 17] Loss Treino: 0.6213 | Acurácia Treino: 0.8402 | Melhor Treino: 0.8402 | Acurácia Teste: 0.7850 | F1 Teste: 0.7777\n",
      "[Epoch 18] Loss Treino: 0.6050 | Acurácia Treino: 0.8304 | Melhor Treino: 0.8402 | Acurácia Teste: 0.7700 | F1 Teste: 0.7662\n",
      "[Epoch 19] Loss Treino: 0.5900 | Acurácia Treino: 0.8493 | Melhor Treino: 0.8493 | Acurácia Teste: 0.7757 | F1 Teste: 0.7750\n",
      "[Epoch 20] Loss Treino: 0.5686 | Acurácia Treino: 0.8602 | Melhor Treino: 0.8602 | Acurácia Teste: 0.7871 | F1 Teste: 0.7880\n",
      "[Epoch 21] Loss Treino: 0.5552 | Acurácia Treino: 0.8480 | Melhor Treino: 0.8602 | Acurácia Teste: 0.7757 | F1 Teste: 0.7707\n",
      "[Epoch 22] Loss Treino: 0.5494 | Acurácia Treino: 0.8675 | Melhor Treino: 0.8675 | Acurácia Teste: 0.7807 | F1 Teste: 0.7858\n",
      "[Epoch 23] Loss Treino: 0.5333 | Acurácia Treino: 0.8516 | Melhor Treino: 0.8675 | Acurácia Teste: 0.7721 | F1 Teste: 0.7728\n",
      "[Epoch 24] Loss Treino: 0.5265 | Acurácia Treino: 0.8650 | Melhor Treino: 0.8675 | Acurácia Teste: 0.7814 | F1 Teste: 0.7821\n",
      "[Epoch 25] Loss Treino: 0.5121 | Acurácia Treino: 0.8729 | Melhor Treino: 0.8729 | Acurácia Teste: 0.7857 | F1 Teste: 0.7814\n",
      "[Epoch 26] Loss Treino: 0.5016 | Acurácia Treino: 0.8452 | Melhor Treino: 0.8729 | Acurácia Teste: 0.7679 | F1 Teste: 0.7717\n",
      "[Epoch 27] Loss Treino: 0.4854 | Acurácia Treino: 0.8748 | Melhor Treino: 0.8748 | Acurácia Teste: 0.7843 | F1 Teste: 0.7859\n",
      "[Epoch 28] Loss Treino: 0.4766 | Acurácia Treino: 0.8745 | Melhor Treino: 0.8748 | Acurácia Teste: 0.7864 | F1 Teste: 0.7850\n",
      "[Epoch 29] Loss Treino: 0.4637 | Acurácia Treino: 0.8736 | Melhor Treino: 0.8748 | Acurácia Teste: 0.7700 | F1 Teste: 0.7689\n",
      "[Epoch 30] Loss Treino: 0.4577 | Acurácia Treino: 0.8954 | Melhor Treino: 0.8954 | Acurácia Teste: 0.8043 | F1 Teste: 0.8039\n",
      "[Epoch 31] Loss Treino: 0.4452 | Acurácia Treino: 0.9030 | Melhor Treino: 0.9030 | Acurácia Teste: 0.8114 | F1 Teste: 0.8108\n",
      "[Epoch 32] Loss Treino: 0.4365 | Acurácia Treino: 0.8804 | Melhor Treino: 0.9030 | Acurácia Teste: 0.7779 | F1 Teste: 0.7732\n",
      "[Epoch 33] Loss Treino: 0.4291 | Acurácia Treino: 0.8957 | Melhor Treino: 0.9030 | Acurácia Teste: 0.8129 | F1 Teste: 0.8074\n",
      "[Epoch 34] Loss Treino: 0.4194 | Acurácia Treino: 0.9129 | Melhor Treino: 0.9129 | Acurácia Teste: 0.8114 | F1 Teste: 0.8142\n",
      "[Epoch 35] Loss Treino: 0.4119 | Acurácia Treino: 0.8718 | Melhor Treino: 0.9129 | Acurácia Teste: 0.7614 | F1 Teste: 0.7654\n",
      "[Epoch 36] Loss Treino: 0.4090 | Acurácia Treino: 0.8866 | Melhor Treino: 0.9129 | Acurácia Teste: 0.7771 | F1 Teste: 0.7736\n",
      "[Epoch 37] Loss Treino: 0.3930 | Acurácia Treino: 0.9102 | Melhor Treino: 0.9129 | Acurácia Teste: 0.7950 | F1 Teste: 0.7966\n",
      "[Epoch 38] Loss Treino: 0.3835 | Acurácia Treino: 0.9150 | Melhor Treino: 0.9150 | Acurácia Teste: 0.7950 | F1 Teste: 0.7968\n",
      "[Epoch 39] Loss Treino: 0.3752 | Acurácia Treino: 0.9075 | Melhor Treino: 0.9150 | Acurácia Teste: 0.7893 | F1 Teste: 0.7850\n",
      "[Epoch 40] Loss Treino: 0.3752 | Acurácia Treino: 0.9243 | Melhor Treino: 0.9243 | Acurácia Teste: 0.8079 | F1 Teste: 0.8063\n",
      "[Epoch 41] Loss Treino: 0.3684 | Acurácia Treino: 0.9141 | Melhor Treino: 0.9243 | Acurácia Teste: 0.8057 | F1 Teste: 0.8041\n",
      "[Epoch 42] Loss Treino: 0.3610 | Acurácia Treino: 0.9002 | Melhor Treino: 0.9243 | Acurácia Teste: 0.7929 | F1 Teste: 0.7906\n",
      "[Epoch 43] Loss Treino: 0.3547 | Acurácia Treino: 0.9052 | Melhor Treino: 0.9243 | Acurácia Teste: 0.8021 | F1 Teste: 0.8012\n",
      "[Epoch 44] Loss Treino: 0.3454 | Acurácia Treino: 0.9316 | Melhor Treino: 0.9316 | Acurácia Teste: 0.8143 | F1 Teste: 0.8166\n",
      "[Epoch 45] Loss Treino: 0.3404 | Acurácia Treino: 0.8916 | Melhor Treino: 0.9316 | Acurácia Teste: 0.7693 | F1 Teste: 0.7717\n",
      "[Epoch 46] Loss Treino: 0.3294 | Acurácia Treino: 0.9313 | Melhor Treino: 0.9316 | Acurácia Teste: 0.8021 | F1 Teste: 0.8087\n",
      "[Epoch 47] Loss Treino: 0.3311 | Acurácia Treino: 0.9236 | Melhor Treino: 0.9316 | Acurácia Teste: 0.8036 | F1 Teste: 0.7996\n",
      "[Epoch 48] Loss Treino: 0.3222 | Acurácia Treino: 0.9302 | Melhor Treino: 0.9316 | Acurácia Teste: 0.8114 | F1 Teste: 0.8028\n",
      "[Epoch 49] Loss Treino: 0.3126 | Acurácia Treino: 0.9473 | Melhor Treino: 0.9473 | Acurácia Teste: 0.8157 | F1 Teste: 0.8173\n",
      "[Epoch 50] Loss Treino: 0.3042 | Acurácia Treino: 0.9355 | Melhor Treino: 0.9473 | Acurácia Teste: 0.8071 | F1 Teste: 0.8126\n",
      "[Epoch 51] Loss Treino: 0.2999 | Acurácia Treino: 0.9379 | Melhor Treino: 0.9473 | Acurácia Teste: 0.8007 | F1 Teste: 0.8030\n",
      "[Epoch 52] Loss Treino: 0.2954 | Acurácia Treino: 0.9370 | Melhor Treino: 0.9473 | Acurácia Teste: 0.8036 | F1 Teste: 0.8112\n",
      "[Epoch 53] Loss Treino: 0.2924 | Acurácia Treino: 0.9313 | Melhor Treino: 0.9473 | Acurácia Teste: 0.7993 | F1 Teste: 0.7955\n",
      "[Epoch 54] Loss Treino: 0.2892 | Acurácia Treino: 0.9405 | Melhor Treino: 0.9473 | Acurácia Teste: 0.7957 | F1 Teste: 0.7921\n",
      "[Epoch 55] Loss Treino: 0.2819 | Acurácia Treino: 0.9486 | Melhor Treino: 0.9486 | Acurácia Teste: 0.8057 | F1 Teste: 0.8081\n",
      "[Epoch 56] Loss Treino: 0.2733 | Acurácia Treino: 0.9295 | Melhor Treino: 0.9486 | Acurácia Teste: 0.8029 | F1 Teste: 0.7981\n",
      "[Epoch 57] Loss Treino: 0.2743 | Acurácia Treino: 0.9298 | Melhor Treino: 0.9486 | Acurácia Teste: 0.8021 | F1 Teste: 0.7982\n",
      "[Epoch 58] Loss Treino: 0.2707 | Acurácia Treino: 0.9611 | Melhor Treino: 0.9611 | Acurácia Teste: 0.8100 | F1 Teste: 0.8140\n",
      "[Epoch 59] Loss Treino: 0.2542 | Acurácia Treino: 0.9623 | Melhor Treino: 0.9623 | Acurácia Teste: 0.8143 | F1 Teste: 0.8136\n",
      "[Epoch 60] Loss Treino: 0.2502 | Acurácia Treino: 0.9509 | Melhor Treino: 0.9623 | Acurácia Teste: 0.7964 | F1 Teste: 0.7980\n",
      "[Epoch 61] Loss Treino: 0.2480 | Acurácia Treino: 0.9457 | Melhor Treino: 0.9623 | Acurácia Teste: 0.7786 | F1 Teste: 0.7889\n",
      "[Epoch 62] Loss Treino: 0.2460 | Acurácia Treino: 0.9632 | Melhor Treino: 0.9632 | Acurácia Teste: 0.7986 | F1 Teste: 0.8047\n",
      "[Epoch 63] Loss Treino: 0.2395 | Acurácia Treino: 0.9679 | Melhor Treino: 0.9679 | Acurácia Teste: 0.8050 | F1 Teste: 0.8079\n",
      "[Epoch 64] Loss Treino: 0.2337 | Acurácia Treino: 0.9634 | Melhor Treino: 0.9679 | Acurácia Teste: 0.8079 | F1 Teste: 0.8151\n",
      "[Epoch 65] Loss Treino: 0.2260 | Acurácia Treino: 0.9677 | Melhor Treino: 0.9679 | Acurácia Teste: 0.8036 | F1 Teste: 0.8068\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "from dtaidistance import dtw\n",
    "from joblib import Parallel, delayed\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "# 2) Calcular a matriz de distâncias DTW (ou outra distância)\n",
    "def process_i(i, X_single, n_samples, r):\n",
    "    \"\"\"\n",
    "    Processa a linha i da matriz de distâncias DTW de forma paralela.\n",
    "    \"\"\"\n",
    "    local_row = np.ascontiguousarray(X_single[i], dtype=np.float64).copy()\n",
    "    local_row.setflags(write=True)  # Garante que é mutável\n",
    "    \n",
    "    dists = []\n",
    "    for j in range(i, n_samples):\n",
    "        target = np.ascontiguousarray(X_single[j], dtype=np.float64).copy()\n",
    "        target.setflags(write=True)  # Garante que é mutável\n",
    "        \n",
    "        dist = dtw.distance_fast(local_row, target, window=r)\n",
    "        dists.append(dist)\n",
    "    \n",
    "    return i, dists\n",
    "\n",
    "def get_dtw_for_ecg_parallel(X, r=100, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Calcula a matriz de distâncias DTW usando paralelismo para acelerar a computação.\n",
    "    \n",
    "    Parâmetros:\n",
    "        X (numpy array): Dados de entrada (shape: [n amostras, canais, comprimento da série]).\n",
    "        r (int): Janela de restrição para o cálculo DTW.\n",
    "        n_jobs (int): Número de núcleos para paralelismo (-1 usa todos disponíveis).\n",
    "    \n",
    "    Retorna:\n",
    "        distances (numpy array): Matriz de distâncias DTW simétrica.\n",
    "    \"\"\"\n",
    "    # Garante que os dados estão no formato correto e mutáveis\n",
    "    X_single = np.asarray(X[:, 0, :], dtype=np.float64).copy()\n",
    "    X_single.setflags(write=True)\n",
    "    \n",
    "    n_samples = X_single.shape[0]\n",
    "    distances = np.zeros((n_samples, n_samples), dtype=np.float64)\n",
    "\n",
    "    print(\"Calculando matriz DTW com paralelismo...\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Inicializa a barra de progresso\n",
    "    with tqdm(total=n_samples, desc=\"Calculando DTW\", unit=\"linha\") as pbar:\n",
    "        results = Parallel(n_jobs=n_jobs, backend=\"loky\", return_as=\"generator\")(\n",
    "            delayed(process_i)(i, X_single, n_samples, r) \n",
    "            for i in range(n_samples)\n",
    "        )\n",
    "\n",
    "        # Atualiza a barra de progresso enquanto preenche a matriz\n",
    "        for i, dists in results:\n",
    "            j_indices = np.arange(i, n_samples)\n",
    "            distances[i, j_indices] = dists\n",
    "            distances[j_indices, i] = dists  # Garante simetria\n",
    "            pbar.update(1)  # Atualiza a barra de progresso após cada linha processada\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f\"\\nCálculo DTW finalizado em {elapsed_time / 60:.2f} minutos.\")\n",
    "\n",
    "    return distances\n",
    "distances = get_dtw_for_ecg_parallel(X_norm, r=100, n_jobs=-1)  \n",
    "print(\"Matriz de distâncias calculada com shape:\", distances.shape)\n",
    "\n",
    "# 3) Criar o modelo SimTSC\n",
    "num_classes = len(np.unique(y))  # Exemplo: 7 classes\n",
    "input_size = X_norm.shape[1]     # number of channels depois do ResNet (?)\n",
    "model = SimTSC(\n",
    "    input_size=input_size,\n",
    "    nb_classes=num_classes,\n",
    "    num_layers=1,      # Exemplo: 1 ou 2 ou 3\n",
    "    n_feature_maps=64, # Pode ajustar\n",
    "    dropout=0.5\n",
    ")\n",
    "\n",
    "# 4) Definir o device e um logger\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(\"Usando device:\", device)\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, f):\n",
    "        self.f = f\n",
    "    def log(self, content):\n",
    "        print(content)\n",
    "        self.f.write(content + '\\n')\n",
    "        self.f.flush()\n",
    "\n",
    "log_path = \"./logs/simtsc_ecg_log.txt\"\n",
    "os.makedirs(os.path.dirname(log_path), exist_ok=True)\n",
    "f = open(log_path, 'w')\n",
    "logger = Logger(f)\n",
    "\n",
    "# 5) Criar o trainer (com a versão nova que calcula a loss no test)\n",
    "trainer = SimTSCTrainer(device=device, logger=logger)\n",
    "\n",
    "# 6) Treinar o modelo\n",
    "K = 3\n",
    "alpha = 0.3\n",
    "epochs = 300  # Ajustar conforme desejado\n",
    "print(\"Iniciando treinamento...\")\n",
    "\n",
    "model = trainer.fit(\n",
    "    model=model,\n",
    "    X=X_norm,\n",
    "    y=y,\n",
    "    train_idx=train_idx,\n",
    "    distances=distances,\n",
    "    K=K,\n",
    "    alpha=alpha,\n",
    "    test_idx=test_idx,   # se quiser acompanhar desempenho em teste durante epochs\n",
    "    report_test=True,    # loga o teste a cada epoch\n",
    "    batch_size=128,\n",
    "    epochs=epochs\n",
    ")\n",
    "\n",
    "# 7) Avaliar o modelo no conjunto de teste final\n",
    "\n",
    "class_names = [\"normal\", \"1dAVb\", \"RBBB\", \"LBBB\", \"SB\", \"ST\", \"AF\"]\n",
    "\n",
    "print(\"\\n--- Avaliação final no conjunto de teste ---\")\n",
    "results = trainer.test(model, test_idx, batch_size=128)\n",
    "print(\"\\nResultados finais:\")\n",
    "print(\"Loss no teste:\", results['loss'D  ])\n",
    "print(\"Acurácia no teste:\", results['accuracy'])\n",
    "print(\"F1 Macro:\", results['f1_macro'])\n",
    "print(\"F1 por classe:\")\n",
    "for class_name, f1_val in zip(class_names, results['f1_per_class']):\n",
    "    print(f\"  {class_name}: {f1_val:.4f}\")\n",
    "\n",
    "# Fecha o logger\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ECG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
