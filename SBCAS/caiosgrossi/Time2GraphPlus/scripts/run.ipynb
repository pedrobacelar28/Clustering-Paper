{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'time2graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpathos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhelpers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mp\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtime2graph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_gat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Time2GraphGAT\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01marchive\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload_usr_dataset\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_usr_dataset_by_name\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'time2graph'"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import argparse\n",
    "import warnings\n",
    "from pathos.helpers import mp\n",
    "from time2graph.core.model_gat import Time2GraphGAT\n",
    "from config import *\n",
    "from archive.load_usr_dataset import load_usr_dataset_by_name\n",
    "from time2graph.utils.base_utils import Debugger, evaluate_performance\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(action='ignore', category=RuntimeWarning)\n",
    "warnings.filterwarnings(action='ignore', category=FutureWarning)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    mp.set_start_method('spawn')\n",
    "    parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "    parser.add_argument('--dataset', type=str, default='ucr-Earthquakes')\n",
    "    parser.add_argument('--n_splits', type=int, default=5)\n",
    "    parser.add_argument('--nhidden', type=int, default=8)\n",
    "    parser.add_argument('--nheads', type=int, default=8)\n",
    "    parser.add_argument('--dropout', type=float, default=0.2)\n",
    "    parser.add_argument('--relu', type=float, default=0.2)\n",
    "    parser.add_argument('--data_size', type=int, default=1)\n",
    "    parser.add_argument('--opt_metric', type=str, default='f1')\n",
    "\n",
    "    parser.add_argument('--niter', type=int, default=1000)\n",
    "    parser.add_argument('--njobs', type=int, default=10)\n",
    "    parser.add_argument('--batch_size', type=int, default=100)\n",
    "    parser.add_argument('--percentile', type=int, default=80)\n",
    "\n",
    "    parser.add_argument('--diff', action='store_true', default=False)\n",
    "    parser.add_argument('--standard_scale', action='store_true', default=False)\n",
    "\n",
    "    parser.add_argument('--softmax', action='store_true', default=False)\n",
    "    parser.add_argument('--append', action='store_true', default=False)\n",
    "    parser.add_argument('--sort', action='store_true', default=False)\n",
    "    parser.add_argument('--ft_xgb', action='store_true', default=False)\n",
    "    parser.add_argument('--aggregate', action='store_true', default=False)\n",
    "    parser.add_argument('--feat_flag', action='store_true', default=False)\n",
    "    parser.add_argument('--feat_norm', action='store_true', default=False)\n",
    "    parser.add_argument('--debug', action='store_true', default=False)\n",
    "\n",
    "    parser.add_argument('--model_cache', action='store_true', default=False)\n",
    "    parser.add_argument('--shapelet_cache', action='store_true', default=False)\n",
    "    parser.add_argument('--gpu_enable', action='store_true', default=False)\n",
    "    parser.add_argument('--pretrain', action='store_true', default=False)\n",
    "    parser.add_argument('--finetune', action='store_true', default=False)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    Debugger.info_print('run with options: {}'.format(args.__dict__))\n",
    "    if path.isfile('{}/scripts/cache/{}_x_train.npy'.format(module_path, args.dataset)):\n",
    "        x_train = np.load('{}/scripts/cache/{}_x_train.npy'.format(module_path, args.dataset))\n",
    "        y_train = np.load('{}/scripts/cache/{}_y_train.npy'.format(module_path, args.dataset))\n",
    "        x_test = np.load('{}/scripts/cache/{}_x_test.npy'.format(module_path, args.dataset))\n",
    "        y_test = np.load('{}/scripts/cache/{}_y_test.npy'.format(module_path, args.dataset))\n",
    "    elif args.dataset.startswith('ucr'):\n",
    "        dataset = args.dataset.rstrip('\\n\\r').split('-')[-1]\n",
    "        x_train, y_train, x_test, y_test = load_usr_dataset_by_name(\n",
    "            fname=dataset, length=args.seg_length * args.num_segment)\n",
    "    else:\n",
    "        raise NotImplementedError()\n",
    "    Debugger.info_print('original training shape {}'.format(x_train.shape))\n",
    "    Debugger.info_print('basic statistics: max {:.4f}, min {:.4f}'.format(np.max(x_train), np.min(x_train)))\n",
    "    general_options = {\n",
    "        'kernel': 'xgb',\n",
    "        'opt_metric': args.opt_metric,\n",
    "        'init': 0,\n",
    "        'warp': 2,\n",
    "        'tflag': True,\n",
    "        'mode': 'embedding',\n",
    "        'candidate_method': 'greedy'\n",
    "    }\n",
    "    model_options = model_args[args.dataset]\n",
    "    xgb_options = xgb_args.get(args.dataset, {})\n",
    "    xgb_options['n_jobs'] = njobs\n",
    "    pretrain = None if not args.pretrain else xgb_options\n",
    "    model = Time2GraphGAT(\n",
    "        gpu_enable=args.gpu_enable, n_hidden=args.nhidden, n_heads=args.nheads, dropout=args.dropout, lk_relu=args.relu,\n",
    "        out_clf=True, softmax=args.softmax, data_size=args.data_size, dataset=args.dataset, njobs=args.njobs,\n",
    "        niter=args.niter, batch_size=args.batch_size, append=args.append, sort=args.sort, ft_xgb=args.ft_xgb,\n",
    "        ggregate=args.aggregate, feat_flag=args.feat_flag, feat_norm=args.feat_norm, pretrain=pretrain, diff=args.diff,\n",
    "        standard_scale=args.standard_scale, percentile=args.percentile, **general_options, **model_options, debug=args.debug\n",
    "    )\n",
    "    res = np.zeros(4, dtype=np.float32)\n",
    "    Debugger.info_print('in this split: training {} samples, with {} positive'.format(\n",
    "        len(x_train), sum(y_train)))\n",
    "    tflag_str = 'time_aware' if general_options['tflag'] else 'static'\n",
    "    shapelet_cache = '{}/scripts/cache/{}_{}_{}_{}_shapelets.cache'.format(\n",
    "        module_path, args.dataset, model_options['K'], model_options['seg_length'], tflag_str)\n",
    "\n",
    "    if path.isfile(shapelet_cache) and args.shapelet_cache:\n",
    "        model.load_shapelets(fpath=shapelet_cache)\n",
    "        Debugger.info_print('load shapelets from {}'.format(shapelet_cache))\n",
    "    else:\n",
    "        Debugger.info_print('train_size {}, label size {}'.format(x_train.shape, y_train.shape))\n",
    "        model.learn_shapelets(x=x_train, y=y_train, num_segment=model_options['num_segment'], data_size=args.data_size)\n",
    "        Debugger.info_print('learn {} shapelets done...'.format(tflag_str))\n",
    "        model.save_shapelets(shapelet_cache)\n",
    "\n",
    "    Debugger.info_print('training: {:.2f} positive ratio with {}'.format(float(sum(y_train) / len(y_train)),\n",
    "                                                                         len(y_train)))\n",
    "    Debugger.info_print('test: {:.2f} positive ratio with {}'.format(float(sum(y_test) / len(y_test)),\n",
    "                                                                     len(y_test)))\n",
    "\n",
    "    model.fit(X=x_train, Y=y_train, n_splits=args.n_splits)\n",
    "    accu, prec, recall, f1 = evaluate_performance(y_true=y_test, y_pred=model.predict(X=x_test))\n",
    "    Debugger.info_print('res: accu {:.4f}, prec {:.4f}, recall {:.4f}, f1 {:.4f}'.format(accu, prec, recall, f1))\n",
    "    model_cache = '{}/scripts/cache/{}_ttgp_{}.cache'.format(module_path, args.dataset, tflag_str)\n",
    "    model.save_model(model_cache)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t2g_py9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
