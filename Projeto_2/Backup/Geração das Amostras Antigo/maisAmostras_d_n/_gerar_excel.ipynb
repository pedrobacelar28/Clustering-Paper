{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "import os\n",
    "import h5py\n",
    "import ecg_plot\n",
    "import matplotlib.pyplot as plt\n",
    "from openpyxl.worksheet.datavalidation import DataValidation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "order = [\n",
    "    'SB', 'SB', 'SB', 'SB', 'SB',\n",
    "    'SB', 'AF', 'SB', 'AF','SB', 'AF','SB', 'AF','SB', 'AF',\n",
    "    'SB', 'AF', 'LBBB', 'SB', 'AF', 'LBBB','SB', 'AF', 'LBBB',\n",
    "    'SB', 'AF', 'LBBB', 'RBBB' , 'SB', 'AF', 'LBBB', 'RBBB' , 'SB', 'AF', 'LBBB', 'RBBB' , 'SB', 'AF', 'LBBB', 'RBBB' , \n",
    "    'SB', 'AF', 'LBBB', 'RBBB' , 'SB', 'AF', 'LBBB', 'RBBB' , 'SB', 'AF', 'LBBB', 'RBBB' , 'SB', 'AF', 'LBBB', 'RBBB' , \n",
    "    'SB', 'AF', 'LBBB', 'RBBB' , 'SB', 'AF', 'LBBB', 'RBBB' , 'SB', 'AF', 'LBBB', 'RBBB' , 'SB', 'AF', 'LBBB', 'RBBB' , \n",
    "    'SB', 'AF', 'LBBB', 'RBBB' , 'ST', 'SB', 'AF', 'LBBB', 'RBBB' , 'ST', 'SB', 'AF', 'LBBB', 'RBBB' , 'ST', 'SB', 'AF', 'LBBB', 'RBBB' , 'ST', \n",
    "    'SB', 'AF', 'LBBB', 'RBBB' , 'ST', 'SB', 'AF', 'LBBB', 'RBBB' , 'ST', 'SB', 'AF', 'LBBB', 'RBBB' , 'ST', 'SB', 'AF', 'LBBB', 'RBBB' , 'ST', \n",
    "    'ST', 'SB', 'AF', 'LBBB', 'RBBB' , 'ST', \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SB: 33\n",
      "AF: 28\n",
      "LBBB: 23\n",
      "RBBB: 20\n",
      "ST: 8\n",
      "Tamanho inicial: 112\n",
      "Tamanho depois de remover duplicatas: 112\n",
      "Os DataFrames são iguais: True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# Carregar os DataFrames das amostras\n",
    "SB = pd.read_csv('SB_amostras.csv')\n",
    "ST = pd.read_csv('ST_amostras.csv')\n",
    "AF = pd.read_csv('AF_amostras.csv')\n",
    "RBBB = pd.read_csv('RBBB_amostras.csv')\n",
    "LBBB = pd.read_csv('LBBB_amostras.csv')\n",
    "\n",
    "# Definir a ordem desejada dos DataFrames\n",
    "order = [\n",
    "    'SB', 'SB', 'SB', 'SB', 'SB',\n",
    "    'SB', 'AF', 'SB', 'AF', 'SB', 'AF', 'SB', 'AF', 'SB', 'AF',\n",
    "    'SB', 'AF', 'LBBB', 'SB', 'AF', 'LBBB', 'SB', 'AF', 'LBBB',\n",
    "    'SB', 'AF', 'LBBB', 'RBBB', 'SB', 'AF', 'LBBB', 'RBBB', 'SB', 'AF', 'LBBB', 'RBBB',\n",
    "    'SB', 'AF', 'LBBB', 'RBBB', 'SB', 'AF', 'LBBB', 'RBBB', 'SB', 'AF', 'LBBB', 'RBBB',\n",
    "    'SB', 'AF', 'LBBB', 'RBBB', 'SB', 'AF', 'LBBB', 'RBBB', 'SB', 'AF', 'LBBB', 'RBBB',\n",
    "    'SB', 'AF', 'LBBB', 'RBBB', 'SB', 'AF', 'LBBB', 'RBBB', 'SB', 'AF', 'LBBB', 'RBBB',\n",
    "    'ST', 'SB', 'AF', 'LBBB', 'RBBB', 'ST', 'SB', 'AF', 'LBBB', 'RBBB', 'ST', 'SB', 'AF', 'LBBB', 'RBBB',\n",
    "    'ST', 'SB', 'AF', 'LBBB', 'RBBB', 'ST', 'SB', 'AF', 'LBBB', 'RBBB', 'ST', 'SB', 'AF', 'LBBB', 'RBBB',\n",
    "    'ST', 'ST', 'SB', 'AF', 'LBBB', 'RBBB', 'SB', 'AF', 'LBBB', 'RBBB'\n",
    "]\n",
    "\n",
    "# Contar a quantidade de cada tipo\n",
    "contagem = Counter(order)\n",
    "\n",
    "# Exibir a contagem\n",
    "for doenca, quantidade in contagem.items():\n",
    "    print(f\"{doenca}: {quantidade}\")\n",
    "\n",
    "# Mapeia os DataFrames para suas respectivas etiquetas\n",
    "df_list = {\n",
    "    'SB': SB,\n",
    "    'ST': ST,\n",
    "    'AF': AF,\n",
    "    'RBBB': RBBB,\n",
    "    'LBBB': LBBB\n",
    "}\n",
    "\n",
    "# Inicializa um DataFrame vazio para armazenar o resultado\n",
    "dados_selecionados = pd.DataFrame()\n",
    "\n",
    "# Itera sobre a ordem e adiciona uma linha de cada DataFrame\n",
    "for name in order:\n",
    "    if name in df_list and not df_list[name].empty:\n",
    "        # Remove o primeiro índice (linha) do DataFrame atual\n",
    "        row = df_list[name].iloc[0:1].reset_index(drop=True)\n",
    "        dados_selecionados = pd.concat([dados_selecionados, row], ignore_index=True)\n",
    "        # Remove a linha adicionada do DataFrame original\n",
    "        df_list[name] = df_list[name].iloc[1:]\n",
    "\n",
    "print('Tamanho inicial:', dados_selecionados.shape[0])\n",
    "\n",
    "# Salvar o DataFrame concatenado\n",
    "dados_selecionados.to_csv('todas_amostras.csv', index=False)\n",
    "\n",
    "# Identificar e remover duplicatas (mantendo apenas a primeira ocorrência)\n",
    "duplicatas = dados_selecionados[dados_selecionados.duplicated(subset='exam_id', keep='first')]\n",
    "\n",
    "# Remove as duplicatas\n",
    "dados_selecionados = dados_selecionados.drop_duplicates(subset='exam_id')\n",
    "print('Tamanho depois de remover duplicatas:', dados_selecionados.shape[0])\n",
    "\n",
    "# Salvar o DataFrame final sem duplicatas\n",
    "dados_selecionados.to_csv('todas_amostras.csv', index=False)\n",
    "\n",
    "concatenacao_padrao = pd.concat([ST, SB, AF, LBBB, RBBB], ignore_index=False)\n",
    "\n",
    "# Ordenar os DataFrames pela coluna 'exam_id'\n",
    "ordenados = dados_selecionados.sort_values(by='exam_id').reset_index(drop=True)\n",
    "concatenacao_padrao = concatenacao_padrao.sort_values(by='exam_id').reset_index(drop=True)\n",
    "\n",
    "# Verifica se os DataFrames são iguais\n",
    "sao_iguais = ordenados.equals(concatenacao_padrao)\n",
    "\n",
    "print(\"Os DataFrames são iguais:\", sao_iguais)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exam_id               0\n",
      "label               112\n",
      "1dAVb                 0\n",
      "RBBB                 20\n",
      "LBBB                 23\n",
      "SB                   33\n",
      "ST                    8\n",
      "AF                   28\n",
      "normal_ecg            0\n",
      "silhouette_score      0\n",
      "tipo                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar o DataFrame a partir do arquivo CSV\n",
    "df = pd.read_csv('todas_amostras.csv')\n",
    "\n",
    "# Contar o número de True em cada coluna\n",
    "true_counts = df.apply(lambda x: x.eq(True).sum())\n",
    "\n",
    "# Exibir o número de True em cada coluna\n",
    "print(true_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Excel '_planilha_1.xlsx' salvo com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# SALVAR IDS EM EXCEL \n",
    "ids = dados_selecionados['exam_id'].tolist()\n",
    "ids = pd.DataFrame({\n",
    "    'exam_id': ids,\n",
    "    'doenca': [''] * len(ids),\n",
    "    'borderline': [''] * len(ids),\n",
    "    'comentario': [''] * len(ids) \n",
    "})\n",
    "\n",
    "num_parts = 1\n",
    "split_dfs = np.array_split(ids, num_parts)\n",
    "\n",
    "for i, df_part in enumerate(split_dfs):\n",
    "    excel_path = f'_planilha_{i+1}.xlsx'\n",
    "    df_part.to_excel(excel_path, index=False)\n",
    "    print(f\"Arquivo Excel '{excel_path}' salvo com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validação de dados adicionada e arquivo salvo com sucesso.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    excel_path = f'_planilha_{i+1}.xlsx'\n",
    "\n",
    "    # Adicionar validação de dados para a coluna 'doenca'\n",
    "    wb = load_workbook(excel_path)\n",
    "    ws = wb.active\n",
    "\n",
    "    # Criar uma lista de opções para a validação de dados na coluna 'doenca'\n",
    "    doenca_options = ['ST', 'SB', 'AF', 'LBBB', 'RBBB', '1dAVB', 'Outra', 'Nenhuma', 'Interferência']\n",
    "    doenca_dv = DataValidation(type=\"list\", formula1=f'\"{\",\".join(doenca_options)}\"', showDropDown=True)\n",
    "\n",
    "    # Criar uma lista de opções para a validação de dados na coluna 'borderline'\n",
    "    borderline_options = ['Sim', 'Não']\n",
    "    borderline_dv = DataValidation(type=\"list\", formula1=f'\"{\",\".join(borderline_options)}\"', showDropDown=True)\n",
    "\n",
    "    # Adicionar a validação às colunas apropriadas\n",
    "    for row in range(2, len(ids) + 2):   # Começa na linha 2 para pular o cabeçalho\n",
    "        doenca_cell = ws[f'B{row}']      # Coluna B para 'doenca'\n",
    "        borderline_cell = ws[f'C{row}']  # Coluna C para 'borderline'\n",
    "        \n",
    "        ws.add_data_validation(doenca_dv)\n",
    "        ws.add_data_validation(borderline_dv)\n",
    "        \n",
    "        doenca_dv.add(doenca_cell)\n",
    "        borderline_dv.add(borderline_cell)\n",
    "\n",
    "    # Salvar o arquivo com a validação de dados\n",
    "    wb.save(excel_path)\n",
    "    print(\"Validação de dados adicionada e arquivo salvo com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112\n"
     ]
    }
   ],
   "source": [
    "for i, df_part in enumerate(split_dfs):\n",
    "    print(df_part.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucesso: exame ID 1501409 salvo.\n",
      "Sucesso: exame ID 1178266 salvo.\n",
      "Sucesso: exame ID 1628423 salvo.\n",
      "Sucesso: exame ID 1191516 salvo.\n",
      "Sucesso: exame ID 1548151 salvo.\n",
      "Sucesso: exame ID 922482 salvo.\n",
      "Sucesso: exame ID 911598 salvo.\n",
      "Sucesso: exame ID 1847840 salvo.\n",
      "Sucesso: exame ID 609256 salvo.\n",
      "Sucesso: exame ID 909325 salvo.\n",
      "Sucesso: exame ID 1148424 salvo.\n",
      "Sucesso: exame ID 420273 salvo.\n",
      "Sucesso: exame ID 2799973 salvo.\n",
      "Sucesso: exame ID 965401 salvo.\n",
      "Sucesso: exame ID 1840734 salvo.\n",
      "Sucesso: exame ID 1378096 salvo.\n",
      "Sucesso: exame ID 1359191 salvo.\n",
      "Sucesso: exame ID 1056318 salvo.\n",
      "Sucesso: exame ID 1129468 salvo.\n",
      "Sucesso: exame ID 69129 salvo.\n",
      "Sucesso: exame ID 1190545 salvo.\n",
      "Sucesso: exame ID 410553 salvo.\n",
      "Sucesso: exame ID 1032531 salvo.\n",
      "Sucesso: exame ID 1144077 salvo.\n",
      "Sucesso: exame ID 1508797 salvo.\n",
      "Sucesso: exame ID 1171185 salvo.\n",
      "Sucesso: exame ID 646912 salvo.\n",
      "Sucesso: exame ID 2759831 salvo.\n",
      "Sucesso: exame ID 2996677 salvo.\n",
      "Sucesso: exame ID 908935 salvo.\n",
      "Sucesso: exame ID 1117260 salvo.\n",
      "Sucesso: exame ID 1021883 salvo.\n",
      "Sucesso: exame ID 1420035 salvo.\n",
      "Sucesso: exame ID 858646 salvo.\n",
      "Sucesso: exame ID 608457 salvo.\n",
      "Sucesso: exame ID 2824637 salvo.\n",
      "Sucesso: exame ID 924974 salvo.\n",
      "Sucesso: exame ID 2880749 salvo.\n",
      "Sucesso: exame ID 1186259 salvo.\n",
      "Sucesso: exame ID 1360021 salvo.\n",
      "Sucesso: exame ID 350640 salvo.\n",
      "Sucesso: exame ID 1976792 salvo.\n",
      "Sucesso: exame ID 1798307 salvo.\n",
      "Sucesso: exame ID 4393374 salvo.\n",
      "Sucesso: exame ID 2070914 salvo.\n",
      "Sucesso: exame ID 1347577 salvo.\n",
      "Sucesso: exame ID 634974 salvo.\n",
      "Sucesso: exame ID 1413858 salvo.\n",
      "Sucesso: exame ID 1462187 salvo.\n",
      "Sucesso: exame ID 1084481 salvo.\n",
      "Sucesso: exame ID 2876468 salvo.\n",
      "Sucesso: exame ID 2786337 salvo.\n",
      "Sucesso: exame ID 3161162 salvo.\n",
      "Sucesso: exame ID 2767905 salvo.\n",
      "Sucesso: exame ID 165988 salvo.\n",
      "Sucesso: exame ID 4205844 salvo.\n",
      "Sucesso: exame ID 1059431 salvo.\n",
      "Sucesso: exame ID 444258 salvo.\n",
      "Sucesso: exame ID 623371 salvo.\n",
      "Sucesso: exame ID 705403 salvo.\n",
      "Sucesso: exame ID 1274476 salvo.\n",
      "Sucesso: exame ID 1352917 salvo.\n",
      "Sucesso: exame ID 3174726 salvo.\n",
      "Sucesso: exame ID 1262429 salvo.\n",
      "Sucesso: exame ID 1217858 salvo.\n",
      "Sucesso: exame ID 188481 salvo.\n",
      "Sucesso: exame ID 872589 salvo.\n",
      "Sucesso: exame ID 1147648 salvo.\n",
      "Sucesso: exame ID 527658 salvo.\n",
      "Sucesso: exame ID 2682680 salvo.\n",
      "Sucesso: exame ID 3106594 salvo.\n",
      "Sucesso: exame ID 561696 salvo.\n",
      "Sucesso: exame ID 455003 salvo.\n",
      "Sucesso: exame ID 1173440 salvo.\n",
      "Sucesso: exame ID 721109 salvo.\n",
      "Sucesso: exame ID 1252127 salvo.\n",
      "Sucesso: exame ID 1190045 salvo.\n",
      "Sucesso: exame ID 479592 salvo.\n",
      "Sucesso: exame ID 1426207 salvo.\n",
      "Sucesso: exame ID 1095036 salvo.\n",
      "Sucesso: exame ID 1075216 salvo.\n",
      "Sucesso: exame ID 337081 salvo.\n",
      "Sucesso: exame ID 1316132 salvo.\n",
      "Sucesso: exame ID 328520 salvo.\n",
      "Sucesso: exame ID 1155702 salvo.\n",
      "Sucesso: exame ID 262156 salvo.\n",
      "Sucesso: exame ID 234557 salvo.\n",
      "Sucesso: exame ID 1283383 salvo.\n",
      "Sucesso: exame ID 233988 salvo.\n",
      "Sucesso: exame ID 737803 salvo.\n",
      "Sucesso: exame ID 646524 salvo.\n",
      "Sucesso: exame ID 730290 salvo.\n",
      "Sucesso: exame ID 265299 salvo.\n",
      "Sucesso: exame ID 832766 salvo.\n",
      "Sucesso: exame ID 354604 salvo.\n",
      "Sucesso: exame ID 1142753 salvo.\n",
      "Sucesso: exame ID 56621 salvo.\n",
      "Sucesso: exame ID 4210557 salvo.\n",
      "Sucesso: exame ID 851068 salvo.\n",
      "Sucesso: exame ID 647107 salvo.\n",
      "Sucesso: exame ID 214133 salvo.\n",
      "Sucesso: exame ID 2941403 salvo.\n",
      "Sucesso: exame ID 1568921 salvo.\n",
      "Sucesso: exame ID 2752429 salvo.\n",
      "Sucesso: exame ID 1862980 salvo.\n",
      "Sucesso: exame ID 1481500 salvo.\n",
      "Sucesso: exame ID 1397355 salvo.\n",
      "Sucesso: exame ID 354875 salvo.\n",
      "Sucesso: exame ID 1177527 salvo.\n",
      "Sucesso: exame ID 213924 salvo.\n",
      "Sucesso: exame ID 3032658 salvo.\n",
      "Sucesso: exame ID 1683181 salvo.\n",
      "Processo completo!\n"
     ]
    }
   ],
   "source": [
    "def create_folders(base_path, num_folders):\n",
    "    for i in range(num_folders):\n",
    "        folder_path = os.path.join(base_path, f'parte_{i+1}')\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "def plot_and_save_ecgs(split_dfs, arquivos_hdf5, base_path):\n",
    "    create_folders(base_path, len(split_dfs))\n",
    "\n",
    "    # ESCOLHA AQUI QUAL ARTE PROCESSAR (0-3)\n",
    "    i = 0\n",
    "    ex = 1\n",
    "    df_part = split_dfs[i]\n",
    "    folder_path = os.path.join(base_path, f'parte_{i+1}')\n",
    "    exam_ids_to_plot = df_part['exam_id'].tolist()\n",
    "    \n",
    "    for exam_id in exam_ids_to_plot:\n",
    "        found = False  \n",
    "        for arquivo in arquivos_hdf5:\n",
    "            try:\n",
    "                with h5py.File(arquivo, 'r') as f:\n",
    "                    exam_ids = np.array(f['exam_id'])\n",
    "                    exam_index = np.where(exam_ids == exam_id)[0]\n",
    "\n",
    "                    if len(exam_index) == 0:\n",
    "                        continue\n",
    "                    else:\n",
    "                        exam_index = exam_index[0]\n",
    "                        exam_tracings = f['tracings'][exam_index]\n",
    "                        ecg = np.array(exam_tracings).T\n",
    "                        ecg_plot.plot(ecg, sample_rate=400,\n",
    "                            lead_index=['DI', 'DII', 'DIII', 'AVR', 'AVL', 'AVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6'], style='bw')\n",
    "                        # rm ticks\n",
    "                        plt.tick_params(\n",
    "                            axis='both',  # changes apply to the x-axis\n",
    "                            which='both',  # both major and minor ticks are affected\n",
    "                            bottom=False,  # ticks along the bottom edge are off\n",
    "                            top=False,  # ticks along the top edge are off\n",
    "                            left=False,\n",
    "                            right=False,\n",
    "                            labelleft=False,\n",
    "                            labelbottom=False)  # labels along the bottom edge are off\n",
    "                        plt.savefig(os.path.join(folder_path, f'{ex}_{exam_id}.png'), dpi=550)\n",
    "                        plt.close()\n",
    "                        found = True\n",
    "                        ex = ex +1\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar o arquivo {arquivo} para o exam ID {exam_id}: {e}\")\n",
    "\n",
    "        if not found:\n",
    "            print(f\"Erro: exame ID {exam_id} não encontrado em nenhum dos arquivos.\")\n",
    "        if found:\n",
    "            print(f\"Sucesso: exame ID {exam_id} salvo.\")\n",
    "\n",
    "base_path = 'imagens'\n",
    "\n",
    "arquivos_hdf5 = [\n",
    "    \"../../Database/filtered_exams_0_1.hdf5\", \"../../Database/filtered_exams_2_3.hdf5\",\n",
    "    \"../../Database/filtered_exams_4_5.hdf5\", \"../../Database/filtered_exams_6_7.hdf5\",\n",
    "    \"../../Database/filtered_exams_8_9.hdf5\", \"../../Database/filtered_exams_10_11.hdf5\",\n",
    "    \"../../Database/filtered_exams_12_13.hdf5\", \"../../Database/filtered_exams_14_15.hdf5\",\n",
    "    \"../../Database/filtered_exams_16_17.hdf5\"\n",
    "]\n",
    "\n",
    "plot_and_save_ecgs(split_dfs, arquivos_hdf5, base_path)\n",
    "\n",
    "print(\"Processo completo!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
