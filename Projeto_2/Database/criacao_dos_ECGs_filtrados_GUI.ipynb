{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORTS\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import scipy.signal as sgn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "sys.path.append('../Pre-processing')  \n",
    "from filters import ecg_filtrado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos para os arquivoS\n",
    "caminho_csv = \"exams.csv\"\n",
    "caminho_hdf5_origem_16 = \"exams_part2.hdf5\"\n",
    "caminho_hdf5_origem_17 = \"exams_part3.hdf5\"\n",
    "caminho_hdf5_destino = \"filtered_exams_2_3.hdf5\"\n",
    "\n",
    "# Carregar os dados do CSV\n",
    "dados = pd.read_csv(caminho_csv)\n",
    "\n",
    "# Selecionar os índices com base nos critérios fornecidos\n",
    "\n",
    "todos_ecgs_linhas = dados.index[(dados.iloc[:, 14] == \"exams_part2.hdf5\") | (dados.iloc[:, 14] == \"exams_part3.hdf5\")]\n",
    "todos_ecgs_id = dados.iloc[todos_ecgs_linhas, 0].tolist()\n",
    "\n",
    "# Lista de caminhos para arquivos HDF5 de origem\n",
    "caminhos_hdf5_origem = [caminho_hdf5_origem_16, caminho_hdf5_origem_17]\n",
    "\n",
    "# Criar o novo arquivo HDF5\n",
    "with h5py.File(caminho_hdf5_destino, 'w') as f_destino:\n",
    "    # Lista para armazenar os exames filtrados\n",
    "    filtered_tracings_list = []\n",
    "    filtered_exam_id_list = []\n",
    "\n",
    "    for caminho in caminhos_hdf5_origem:\n",
    "        # Abrir o arquivo HDF5 de origem\n",
    "        with h5py.File(caminho, 'r') as f_origem:\n",
    "            tracings = f_origem['tracings']\n",
    "            exam_id = f_origem['exam_id']\n",
    "\n",
    "            # Filtrar apenas os exames que queremos processar\n",
    "            indices_interessantes = [i for i, id_ in enumerate(exam_id) if id_ in todos_ecgs_id]\n",
    "\n",
    "            # Processar e salvar cada exame\n",
    "            for original_idx in indices_interessantes:\n",
    "                # Obter o exame original\n",
    "                original_tracing = tracings[original_idx]\n",
    "\n",
    "                # Aplicar a filtragem em cada lead\n",
    "                filtered_tracing = np.array([ecg_filtrado(lead) for lead in original_tracing.T]).T\n",
    "\n",
    "                # Adicionar o exame filtrado à lista\n",
    "                filtered_tracings_list.append(filtered_tracing)\n",
    "                filtered_exam_id_list.append(exam_id[original_idx])\n",
    "\n",
    "    # Criar datasets para os exames filtrados no arquivo de destino\n",
    "    num_exams = len(filtered_tracings_list)\n",
    "    filtered_tracings = f_destino.create_dataset('tracings', (num_exams, 4096, 12), dtype=np.float32)\n",
    "    filtered_exam_id = f_destino.create_dataset('exam_id', (num_exams,), dtype=np.int32)\n",
    "\n",
    "    # Copiar os dados das listas para os datasets\n",
    "    for idx, (tracing, exam_id) in enumerate(zip(filtered_tracings_list, filtered_exam_id_list)):\n",
    "        filtered_tracings[idx] = tracing\n",
    "        filtered_exam_id[idx] = exam_id\n",
    "\n",
    "print(\"Filtragem e salvamento concluídos!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos para os arquivoS\n",
    "caminho_csv = \"exams.csv\"\n",
    "caminho_hdf5_origem_16 = \"exams_part4.hdf5\"\n",
    "caminho_hdf5_origem_17 = \"exams_part5.hdf5\"\n",
    "caminho_hdf5_destino = \"filtered_exams_2_3.hdf5\"\n",
    "\n",
    "# Carregar os dados do CSV\n",
    "dados = pd.read_csv(caminho_csv)\n",
    "\n",
    "# Selecionar os índices com base nos critérios fornecidos\n",
    "\n",
    "todos_ecgs_linhas = dados.index[(dados.iloc[:, 14] == \"exams_part4.hdf5\") | (dados.iloc[:, 14] == \"exams_part5.hdf5\")]\n",
    "todos_ecgs_id = dados.iloc[todos_ecgs_linhas, 0].tolist()\n",
    "\n",
    "# Lista de caminhos para arquivos HDF5 de origem\n",
    "caminhos_hdf5_origem = [caminho_hdf5_origem_16, caminho_hdf5_origem_17]\n",
    "\n",
    "# Criar o novo arquivo HDF5\n",
    "with h5py.File(caminho_hdf5_destino, 'w') as f_destino:\n",
    "    # Lista para armazenar os exames filtrados\n",
    "    filtered_tracings_list = []\n",
    "    filtered_exam_id_list = []\n",
    "\n",
    "    for caminho in caminhos_hdf5_origem:\n",
    "        # Abrir o arquivo HDF5 de origem\n",
    "        with h5py.File(caminho, 'r') as f_origem:\n",
    "            tracings = f_origem['tracings']\n",
    "            exam_id = f_origem['exam_id']\n",
    "\n",
    "            # Filtrar apenas os exames que queremos processar\n",
    "            indices_interessantes = [i for i, id_ in enumerate(exam_id) if id_ in todos_ecgs_id]\n",
    "\n",
    "            # Processar e salvar cada exame\n",
    "            for original_idx in indices_interessantes:\n",
    "                # Obter o exame original\n",
    "                original_tracing = tracings[original_idx]\n",
    "\n",
    "                # Aplicar a filtragem em cada lead\n",
    "                filtered_tracing = np.array([ecg_filtrado(lead) for lead in original_tracing.T]).T\n",
    "\n",
    "                # Adicionar o exame filtrado à lista\n",
    "                filtered_tracings_list.append(filtered_tracing)\n",
    "                filtered_exam_id_list.append(exam_id[original_idx])\n",
    "\n",
    "    # Criar datasets para os exames filtrados no arquivo de destino\n",
    "    num_exams = len(filtered_tracings_list)\n",
    "    filtered_tracings = f_destino.create_dataset('tracings', (num_exams, 4096, 12), dtype=np.float32)\n",
    "    filtered_exam_id = f_destino.create_dataset('exam_id', (num_exams,), dtype=np.int32)\n",
    "\n",
    "    # Copiar os dados das listas para os datasets\n",
    "    for idx, (tracing, exam_id) in enumerate(zip(filtered_tracings_list, filtered_exam_id_list)):\n",
    "        filtered_tracings[idx] = tracing\n",
    "        filtered_exam_id[idx] = exam_id\n",
    "\n",
    "print(\"Filtragem e salvamento concluídos!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
