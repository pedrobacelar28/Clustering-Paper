{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m PATH_EXAMS \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Carrega os grafos (o arquivo deve conter um dicionário com a chave 'grafos')\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m dados_grafos \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPATH_GRAFOS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m grafos_dict \u001b[38;5;241m=\u001b[39m dados_grafos[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrafos\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Carrega o CSV com as informações dos exames (incluindo as colunas de classe)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/condaclustering/lib/python3.12/site-packages/torch/serialization.py:1026\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1024\u001b[0m             \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1025\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle\u001b[38;5;241m.\u001b[39mUnpicklingError(UNSAFE_MESSAGE \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1026\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1027\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1028\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1029\u001b[0m \u001b[43m                     \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1030\u001b[0m \u001b[43m                     \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1031\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmap can only be used with files saved with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1033\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`torch.save(_use_new_zipfile_serialization=True), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1034\u001b[0m                        \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplease torch.save your checkpoint with this option in order to use mmap.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/condaclustering/lib/python3.12/site-packages/torch/serialization.py:1438\u001b[0m, in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1436\u001b[0m unpickler \u001b[38;5;241m=\u001b[39m UnpicklerWrapper(data_file, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpickle_load_args)\n\u001b[1;32m   1437\u001b[0m unpickler\u001b[38;5;241m.\u001b[39mpersistent_load \u001b[38;5;241m=\u001b[39m persistent_load\n\u001b[0;32m-> 1438\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1440\u001b[0m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_validate_loaded_sparse_tensors()\n\u001b[1;32m   1441\u001b[0m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_log_api_usage_metadata(\n\u001b[1;32m   1442\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch.load.metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mserialization_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: zip_file\u001b[38;5;241m.\u001b[39mserialization_id()}\n\u001b[1;32m   1443\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/condaclustering/lib/python3.12/site-packages/torch/serialization.py:1408\u001b[0m, in \u001b[0;36m_load.<locals>.persistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1407\u001b[0m     nbytes \u001b[38;5;241m=\u001b[39m numel \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39m_utils\u001b[38;5;241m.\u001b[39m_element_size(dtype)\n\u001b[0;32m-> 1408\u001b[0m     typed_storage \u001b[38;5;241m=\u001b[39m \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "File \u001b[0;32m~/anaconda3/envs/condaclustering/lib/python3.12/site-packages/torch/serialization.py:1373\u001b[0m, in \u001b[0;36m_load.<locals>.load_tensor\u001b[0;34m(dtype, numel, key, location)\u001b[0m\n\u001b[1;32m   1371\u001b[0m     storage \u001b[38;5;241m=\u001b[39m overall_storage[storage_offset:storage_offset \u001b[38;5;241m+\u001b[39m numel]\n\u001b[1;32m   1372\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1373\u001b[0m     storage \u001b[38;5;241m=\u001b[39m \u001b[43mzip_file\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_storage_from_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_typed_storage()\u001b[38;5;241m.\u001b[39m_untyped_storage\n\u001b[1;32m   1374\u001b[0m \u001b[38;5;66;03m# swap here if byteswapping is needed\u001b[39;00m\n\u001b[1;32m   1375\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m byteorderdata \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, GINConv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Carregar os grafos salvos e o CSV com as labels\n",
    "# =============================================================================\n",
    "\n",
    "# Paths para os arquivos\n",
    "PATH_GRAFOS = \"/scratch/pedro.bacelar/Clustering-Paper/Grafo/dataset/ecg_visibility_graphs_by_id.pt\"\n",
    "PATH_EXAMS = \"/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams.csv\"\n",
    "\n",
    "# Carrega os grafos (o arquivo deve conter um dicionário com a chave 'grafos')\n",
    "dados_grafos = torch.load(PATH_GRAFOS)\n",
    "grafos_dict = dados_grafos[\"grafos\"]\n",
    "\n",
    "# Carrega o CSV com as informações dos exames (incluindo as colunas de classe)\n",
    "exams_df = pd.read_csv(PATH_EXAMS)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Criar os rótulos a partir do CSV\n",
    "# =============================================================================\n",
    "def get_label(row):\n",
    "    \"\"\"\n",
    "    Para cada linha do CSV, retorna um inteiro que representa o rótulo exclusivo.\n",
    "    Ordem das classes: [\"1dAVb\", \"RBBB\", \"LBBB\", \"SB\", \"ST\", \"AF\"].\n",
    "    Se exatamente uma dessas colunas for True, retorna o índice correspondente (0 a 5).\n",
    "    Se nenhuma for True (exame sem doença), retorna 6, que corresponde à classe \"normal\".\n",
    "    \"\"\"\n",
    "    classes = [\"1dAVb\", \"RBBB\", \"LBBB\", \"SB\", \"ST\", \"AF\"]\n",
    "    values = row[classes].values.astype(bool)\n",
    "    if values.sum() == 1:\n",
    "        return int(np.argmax(values))\n",
    "    else:\n",
    "        return 6  # Rótulo para \"normal\" (sem doença)\n",
    "\n",
    "# Aplica a função e cria uma nova coluna com os rótulos (inteiros)\n",
    "exams_df[\"label_idx\"] = exams_df.apply(get_label, axis=1)\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Construir o dataset do PyTorch Geometric (usando apenas a lead 0)\n",
    "# =============================================================================\n",
    "dataset = []\n",
    "chaves_grafos = list(grafos_dict.keys())\n",
    "\n",
    "for exam_id in chaves_grafos:\n",
    "    # Seleciona as linhas do CSV que têm o mesmo exam_id (convertendo para inteiro)\n",
    "    exam_rows = exams_df[exams_df[\"exam_id\"] == int(exam_id)]\n",
    "    if exam_rows.empty:\n",
    "        print(f\"Exame {exam_id} não encontrado no CSV. Ignorando.\")\n",
    "        continue\n",
    "\n",
    "    exam_info = exam_rows.iloc[0]\n",
    "    label = get_label(exam_info)  # rótulo inteiro (0 a 6)\n",
    "    \n",
    "    try:\n",
    "        grafo_lead0 = grafos_dict[exam_id][\"lead_0\"]\n",
    "    except KeyError:\n",
    "        print(f\"Lead_0 não encontrado para o exam_id {exam_id}. Ignorando.\")\n",
    "        continue\n",
    "\n",
    "    # Cria o objeto Data com os dados do grafo:\n",
    "    # - x: features dos nós (forma: [num_nodes, 3])\n",
    "    # - edge_index: conectividade (forma: [2, num_edges])\n",
    "    # - y: rótulo exclusivo, armazenado como um inteiro (forma: []).\n",
    "    data = Data(\n",
    "        x = grafo_lead0[\"node_features\"],\n",
    "        edge_index = grafo_lead0[\"edge_index\"],\n",
    "        y = torch.tensor(label, dtype=torch.long)  # sem unsqueeze, pois é um escalar\n",
    "    )\n",
    "    data.exam_id = exam_id  # opcional, para referência\n",
    "    dataset.append(data)\n",
    "\n",
    "print(f\"Total de amostras no dataset: {len(dataset)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Dividir o dataset em treino, validação e teste\n",
    "# =============================================================================\n",
    "# 70% para treino e 30% para (validação + teste), depois divide igualmente\n",
    "train_data, temp_data = train_test_split(dataset, test_size=0.30, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.50, random_state=42)\n",
    "\n",
    "print(f\"Número de amostras de treino: {len(train_data)}\")\n",
    "print(f\"Número de amostras de validação: {len(val_data)}\")\n",
    "print(f\"Número de amostras de teste: {len(test_data)}\")\n",
    "\n",
    "# Cria os DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Definir o modelo – nova arquitetura baseada em GIN para classificação exclusiva\n",
    "# =============================================================================\n",
    "class GINExclusive(nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes, dropout=0.2):\n",
    "        \"\"\"\n",
    "        num_features: número de features de entrada por nó (3)\n",
    "        hidden_channels: tamanho do embedding intermediário\n",
    "        num_classes: número de classes exclusivas (neste exemplo, 7: 6 doenças + 1 normal)\n",
    "        dropout: taxa de dropout\n",
    "        \"\"\"\n",
    "        super(GINExclusive, self).__init__()\n",
    "        # Primeira camada GIN\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Linear(num_features, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels)\n",
    "        )\n",
    "        self.conv1 = GINConv(self.mlp1)\n",
    "\n",
    "        # Segunda camada GIN\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels)\n",
    "        )\n",
    "        self.conv2 = GINConv(self.mlp2)\n",
    "\n",
    "        # Terceira camada GIN\n",
    "        self.mlp3 = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels)\n",
    "        )\n",
    "        self.conv3 = GINConv(self.mlp3)\n",
    "\n",
    "        # Camadas finais para converter o embedding global em logits\n",
    "        self.lin1 = nn.Linear(hidden_channels, hidden_channels * 2)\n",
    "        self.bn = nn.BatchNorm1d(hidden_channels * 2)\n",
    "        self.lin2 = nn.Linear(hidden_channels * 2, num_classes)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Agrega os embeddings dos nós de cada grafo em um único vetor\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        # Camadas finais fully-connected com batch norm e dropout\n",
    "        x = self.lin1(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        out = self.lin2(x)  # Saída: logits com formato [num_graphs, num_classes]\n",
    "        return out\n",
    "\n",
    "# Como agora temos 7 classes (índices 0-5 para doenças e 6 para normal)\n",
    "num_classes = 7\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GINExclusive(num_features=3, hidden_channels=64, num_classes=num_classes, dropout=0.2).to(device)\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Preparar o treinamento\n",
    "# =============================================================================\n",
    "# Para classificação exclusiva usamos CrossEntropyLoss (que aplica softmax internamente)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# =============================================================================\n",
    "# 7. Funções de treinamento e avaliação\n",
    "# =============================================================================\n",
    "def train_epoch(loader):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)  # Saída: logits, formato [num_graphs, num_classes]\n",
    "        # CrossEntropyLoss espera: out com shape [N, num_classes] e targets com shape [N]\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Multiplica pela quantidade de exemplos no batch\n",
    "        epoch_loss += loss.item() * data.num_graphs\n",
    "    return epoch_loss / len(loader.dataset)\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_logits = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)  # logits\n",
    "            loss = criterion(out, data.y)\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "            all_logits.append(out.cpu())\n",
    "            all_targets.append(data.y.cpu())\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    all_logits = torch.cat(all_logits, dim=0)  # [N, num_classes]\n",
    "    all_targets = torch.cat(all_targets, dim=0)  # [N]\n",
    "    return avg_loss, all_logits, all_targets\n",
    "\n",
    "# =============================================================================\n",
    "# 8. Treinar o modelo e plotar as curvas de loss\n",
    "# =============================================================================\n",
    "num_epochs = 50\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs+1), desc=\"Treinamento\"):\n",
    "    train_loss = train_epoch(train_loader)\n",
    "    val_loss, _, _ = evaluate(val_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label=\"Treino\")\n",
    "plt.plot(range(1, num_epochs+1), val_losses, label=\"Validação\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Curva de Loss de Treino e Validação\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 9. Avaliação no conjunto de teste e cálculo do F1 Score\n",
    "# =============================================================================\n",
    "test_loss, test_logits, test_targets = evaluate(test_loader)\n",
    "print(f\"Loss no teste: {test_loss:.4f}\")\n",
    "\n",
    "# Para inferência, aplicamos softmax e usamos argmax para obter a classe prevista\n",
    "test_probs = F.softmax(test_logits, dim=1)  # Probabilidades, formato: [N, num_classes]\n",
    "test_preds = test_probs.argmax(dim=1)         # Predição como índice, formato: [N]\n",
    "\n",
    "# Converte para numpy para calcular métricas\n",
    "test_preds_np = test_preds.numpy()\n",
    "test_targets_np = test_targets.numpy()\n",
    "\n",
    "# Calcula o F1 Score para cada classe\n",
    "classes_list = [\"1dAVb\", \"RBBB\", \"LBBB\", \"SB\", \"ST\", \"AF\", \"normal\"]\n",
    "f1_per_class = {}\n",
    "for i, cls in enumerate(classes_list):\n",
    "    f1 = f1_score(test_targets_np == i, test_preds_np == i, zero_division=1)\n",
    "    f1_per_class[cls] = f1\n",
    "\n",
    "print(\"\\nF1 Score por classe:\")\n",
    "for cls in classes_list:\n",
    "    print(f\"{cls}: {f1_per_class[cls]:.4f}\")\n",
    "\n",
    "# Calcula o F1 Macro (média dos F1s)\n",
    "f1_macro = f1_score(test_targets_np, test_preds_np, average='macro', zero_division=1)\n",
    "print(f\"\\nF1 Macro: {f1_macro:.4f}\")\n",
    "\n",
    "# Exibe 5 exemplos do conjunto de teste com seus rótulos verdadeiros e predições\n",
    "num_examples = 5\n",
    "print(\"\\nExemplos do conjunto de teste:\")\n",
    "for i in range(num_examples):\n",
    "    print(f\"Exemplo {i+1}:\")\n",
    "    print(\"  Rótulo verdadeiro: \", test_targets_np[i])\n",
    "    print(\"  Predição (classe): \", test_preds_np[i])\n",
    "    # Opcional: Mostra as probabilidades para cada classe\n",
    "    print(\"  Probabilidades: \", test_probs[i].detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de amostras no dataset: 700\n",
      "Número de amostras de treino: 490\n",
      "Número de amostras de validação: 105\n",
      "Número de amostras de teste: 105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/grad/si/24/guilherme.evangelista/anaconda3/envs/condaclustering/lib/python3.12/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n",
      "Treinamento: 100%|██████████| 10/10 [01:41<00:00, 10.16s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss no teste: 1.9570\n",
      "\n",
      "F1 Score por classe:\n",
      "1dAVb: 0.1667\n",
      "RBBB: 0.0000\n",
      "LBBB: 0.0909\n",
      "SB: 0.0000\n",
      "ST: 0.0000\n",
      "AF: 0.2449\n",
      "normal: 0.0000\n",
      "\n",
      "F1 Macro: 0.0718\n",
      "\n",
      "Exemplos do conjunto de teste:\n",
      "Exemplo 1:\n",
      "  Rótulo verdadeiro:  0\n",
      "  Predição (classe):  0\n",
      "  Probabilidades:  [0.17774864 0.1331824  0.14991595 0.1180075  0.09016263 0.15550673\n",
      " 0.17547612]\n",
      "Exemplo 2:\n",
      "  Rótulo verdadeiro:  1\n",
      "  Predição (classe):  5\n",
      "  Probabilidades:  [0.1403987  0.17100927 0.06416777 0.17058766 0.15464683 0.18126266\n",
      " 0.11792714]\n",
      "Exemplo 3:\n",
      "  Rótulo verdadeiro:  0\n",
      "  Predição (classe):  2\n",
      "  Probabilidades:  [0.18874511 0.10708863 0.19441387 0.10761153 0.07024671 0.13867564\n",
      " 0.19321848]\n",
      "Exemplo 4:\n",
      "  Rótulo verdadeiro:  6\n",
      "  Predição (classe):  5\n",
      "  Probabilidades:  [0.13193536 0.1745975  0.05249048 0.17538716 0.16941427 0.18571992\n",
      " 0.11045534]\n",
      "Exemplo 5:\n",
      "  Rótulo verdadeiro:  6\n",
      "  Predição (classe):  5\n",
      "  Probabilidades:  [0.15441701 0.15583658 0.11046128 0.14051445 0.12001991 0.17112187\n",
      " 0.14762893]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, GINConv\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Carregar os grafos salvos e o CSV com as labels\n",
    "# =============================================================================\n",
    "\n",
    "# Paths para os arquivos\n",
    "# Alteramos o nome do arquivo para o salvo pelo script PyG.\n",
    "PATH_GRAFOS = \"../dataset/ecg_visibility_graphs_by_id_pyg.pt\"\n",
    "PATH_EXAMS = \"/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams.csv\"\n",
    "\n",
    "# Carrega os grafos (o arquivo deve conter um dicionário com a chave 'grafos')\n",
    "dados_grafos = torch.load(PATH_GRAFOS)\n",
    "grafos_dict = dados_grafos[\"grafos\"]\n",
    "\n",
    "# Carrega o CSV com as informações dos exames (incluindo as colunas de classe)\n",
    "exams_df = pd.read_csv(PATH_EXAMS)\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Criar os rótulos a partir do CSV\n",
    "# =============================================================================\n",
    "def get_label(row):\n",
    "    \"\"\"\n",
    "    Para cada linha do CSV, retorna um inteiro que representa o rótulo exclusivo.\n",
    "    Ordem das classes: [\"1dAVb\", \"RBBB\", \"LBBB\", \"SB\", \"ST\", \"AF\"].\n",
    "    Se exatamente uma dessas colunas for True, retorna o índice correspondente (0 a 5).\n",
    "    Se nenhuma for True (exame sem doença), retorna 6, que corresponde à classe \"normal\".\n",
    "    \"\"\"\n",
    "    classes = [\"1dAVb\", \"RBBB\", \"LBBB\", \"SB\", \"ST\", \"AF\"]\n",
    "    values = row[classes].values.astype(bool)\n",
    "    if values.sum() == 1:\n",
    "        return int(np.argmax(values))\n",
    "    else:\n",
    "        return 6  # Rótulo para \"normal\" (sem doença)\n",
    "\n",
    "# Aplica a função e cria uma nova coluna com os rótulos (inteiros)\n",
    "exams_df[\"label_idx\"] = exams_df.apply(get_label, axis=1)\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Construir o dataset do PyTorch Geometric (usando apenas a lead 0)\n",
    "# =============================================================================\n",
    "dataset = []\n",
    "chaves_grafos = list(grafos_dict.keys())\n",
    "\n",
    "for exam_id in chaves_grafos:\n",
    "    # Seleciona as linhas do CSV que têm o mesmo exam_id (convertendo para inteiro)\n",
    "    exam_rows = exams_df[exams_df[\"exam_id\"] == int(exam_id)]\n",
    "    if exam_rows.empty:\n",
    "        print(f\"Exame {exam_id} não encontrado no CSV. Ignorando.\")\n",
    "        continue\n",
    "\n",
    "    exam_info = exam_rows.iloc[0]\n",
    "    label = get_label(exam_info)  # rótulo inteiro (0 a 6)\n",
    "    \n",
    "    try:\n",
    "        # Aqui, agora os grafos são objetos Data do PyG.\n",
    "        grafo_lead0 = grafos_dict[exam_id][\"lead_0\"]\n",
    "    except KeyError:\n",
    "        print(f\"Lead_0 não encontrado para o exam_id {exam_id}. Ignorando.\")\n",
    "        continue\n",
    "\n",
    "    # Cria o objeto Data com os dados do grafo:\n",
    "    # - x: features dos nós (forma: [num_nodes, 3])\n",
    "    # - edge_index: conectividade (forma: [2, num_edges])\n",
    "    # - y: rótulo exclusivo, armazenado como um inteiro (forma: []).\n",
    "    data = Data(\n",
    "        x = grafo_lead0.x,                 # Acessa as features diretamente\n",
    "        edge_index = grafo_lead0.edge_index,  # Acessa as arestas diretamente\n",
    "        y = torch.tensor(label, dtype=torch.long)\n",
    "    )\n",
    "    data.exam_id = exam_id  # opcional, para referência\n",
    "    dataset.append(data)\n",
    "\n",
    "print(f\"Total de amostras no dataset: {len(dataset)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Dividir o dataset em treino, validação e teste\n",
    "# =============================================================================\n",
    "# 70% para treino e 30% para (validação + teste), depois divide igualmente\n",
    "train_data, temp_data = train_test_split(dataset, test_size=0.30, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.50, random_state=42)\n",
    "\n",
    "print(f\"Número de amostras de treino: {len(train_data)}\")\n",
    "print(f\"Número de amostras de validação: {len(val_data)}\")\n",
    "print(f\"Número de amostras de teste: {len(test_data)}\")\n",
    "\n",
    "# Cria os DataLoaders\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Definir o modelo – nova arquitetura baseada em GIN para classificação exclusiva\n",
    "# =============================================================================\n",
    "class GINExclusive(nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes, dropout=0.2):\n",
    "        \"\"\"\n",
    "        num_features: número de features de entrada por nó (3)\n",
    "        hidden_channels: tamanho do embedding intermediário\n",
    "        num_classes: número de classes exclusivas (neste exemplo, 7: 6 doenças + 1 normal)\n",
    "        dropout: taxa de dropout\n",
    "        \"\"\"\n",
    "        super(GINExclusive, self).__init__()\n",
    "        # Primeira camada GIN\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Linear(num_features, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels)\n",
    "        )\n",
    "        self.conv1 = GINConv(self.mlp1)\n",
    "\n",
    "        # Segunda camada GIN\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels)\n",
    "        )\n",
    "        self.conv2 = GINConv(self.mlp2)\n",
    "\n",
    "        # Terceira camada GIN\n",
    "        self.mlp3 = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels)\n",
    "        )\n",
    "        self.conv3 = GINConv(self.mlp3)\n",
    "\n",
    "        # Camadas finais para converter o embedding global em logits\n",
    "        self.lin1 = nn.Linear(hidden_channels, hidden_channels * 2)\n",
    "        self.bn = nn.BatchNorm1d(hidden_channels * 2)\n",
    "        self.lin2 = nn.Linear(hidden_channels * 2, num_classes)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Agrega os embeddings dos nós de cada grafo em um único vetor\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        # Camadas finais fully-connected com batch norm e dropout\n",
    "        x = self.lin1(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        out = self.lin2(x)  # Saída: logits com formato [num_graphs, num_classes]\n",
    "        return out\n",
    "\n",
    "# Como agora temos 7 classes (índices 0-5 para doenças e 6 para normal)\n",
    "num_classes = 7\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GINExclusive(num_features=3, hidden_channels=64, num_classes=num_classes, dropout=0.2).to(device)\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Preparar o treinamento\n",
    "# =============================================================================\n",
    "# Para classificação exclusiva usamos CrossEntropyLoss (que aplica softmax internamente)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# =============================================================================\n",
    "# 7. Funções de treinamento e avaliação\n",
    "# =============================================================================\n",
    "def train_epoch(loader):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)  # Saída: logits, formato [num_graphs, num_classes]\n",
    "        # CrossEntropyLoss espera: out com shape [N, num_classes] e targets com shape [N]\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Multiplica pela quantidade de exemplos no batch\n",
    "        epoch_loss += loss.item() * data.num_graphs\n",
    "    return epoch_loss / len(loader.dataset)\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_logits = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)  # logits\n",
    "            loss = criterion(out, data.y)\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "            all_logits.append(out.cpu())\n",
    "            all_targets.append(data.y.cpu())\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    all_logits = torch.cat(all_logits, dim=0)  # [N, num_classes]\n",
    "    all_targets = torch.cat(all_targets, dim=0)  # [N]\n",
    "    return avg_loss, all_logits, all_targets\n",
    "\n",
    "# =============================================================================\n",
    "# 8. Treinar o modelo e plotar as curvas de loss\n",
    "# =============================================================================\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs+1), desc=\"Treinamento\"):\n",
    "    train_loss = train_epoch(train_loader)\n",
    "    val_loss, _, _ = evaluate(val_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label=\"Treino\")\n",
    "plt.plot(range(1, num_epochs+1), val_losses, label=\"Validação\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Curva de Loss de Treino e Validação\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 9. Avaliação no conjunto de teste e cálculo do F1 Score\n",
    "# =============================================================================\n",
    "test_loss, test_logits, test_targets = evaluate(test_loader)\n",
    "print(f\"Loss no teste: {test_loss:.4f}\")\n",
    "\n",
    "# Para inferência, aplicamos softmax e usamos argmax para obter a classe prevista\n",
    "test_probs = F.softmax(test_logits, dim=1)  # Probabilidades, formato: [N, num_classes]\n",
    "test_preds = test_probs.argmax(dim=1)         # Predição como índice, formato: [N]\n",
    "\n",
    "# Converte para numpy para calcular métricas\n",
    "test_preds_np = test_preds.numpy()\n",
    "test_targets_np = test_targets.numpy()\n",
    "\n",
    "# Calcula o F1 Score para cada classe\n",
    "classes_list = [\"1dAVb\", \"RBBB\", \"LBBB\", \"SB\", \"ST\", \"AF\", \"normal\"]\n",
    "f1_per_class = {}\n",
    "for i, cls in enumerate(classes_list):\n",
    "    f1 = f1_score(test_targets_np == i, test_preds_np == i, zero_division=1)\n",
    "    f1_per_class[cls] = f1\n",
    "\n",
    "print(\"\\nF1 Score por classe:\")\n",
    "for cls in classes_list:\n",
    "    print(f\"{cls}: {f1_per_class[cls]:.4f}\")\n",
    "\n",
    "# Calcula o F1 Macro (média dos F1s)\n",
    "f1_macro = f1_score(test_targets_np, test_preds_np, average='macro', zero_division=1)\n",
    "print(f\"\\nF1 Macro: {f1_macro:.4f}\")\n",
    "\n",
    "# Exibe 5 exemplos do conjunto de teste com seus rótulos verdadeiros e predições\n",
    "num_examples = 5\n",
    "print(\"\\nExemplos do conjunto de teste:\")\n",
    "for i in range(num_examples):\n",
    "    print(f\"Exemplo {i+1}:\")\n",
    "    print(\"  Rótulo verdadeiro: \", test_targets_np[i])\n",
    "    print(\"  Predição (classe): \", test_preds_np[i])\n",
    "    # Opcional: Mostra as probabilidades para cada classe\n",
    "    print(\"  Probabilidades: \", test_probs[i].detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, GINConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================================================================\n",
    "# 1. Definir o mapeamento entre os arquivos e os índices dos rótulos\n",
    "# =============================================================================\n",
    "# Supondo a seguinte correspondência:\n",
    "# \"umdavb.pt\" -> 0 (equivalente a \"1dAVb\")\n",
    "# \"rbbb.pt\"   -> 1 (\"RBBB\")\n",
    "# \"lbbb.pt\"   -> 2 (\"LBBB\")\n",
    "# \"sf.pt\"     -> 3 (\"SB\")     # Se \"sf\" equivale a \"SB\"\n",
    "# \"st.pt\"     -> 4 (\"ST\")\n",
    "# \"af.pt\"     -> 5 (\"AF\")\n",
    "# \"unlabel.pt\"-> 6 (\"normal\")\n",
    "class_files = {\n",
    "    \"umdavb.pt\": 0,\n",
    "    \"rbbb.pt\":   1,\n",
    "    \"lbbb.pt\":   2,\n",
    "    \"sb.pt\":     3,\n",
    "    \"st.pt\":     4,\n",
    "    \"af.pt\":     5,\n",
    "    \"unlabel.pt\":6,\n",
    "}\n",
    "\n",
    "# Pasta onde os arquivos estão armazenados\n",
    "dataset_dir = \"../dataset/\"  # ajuste o caminho conforme necessário\n",
    "\n",
    "# =============================================================================\n",
    "# 2. Carregar os grafos de cada arquivo e construir o dataset do PyG\n",
    "# =============================================================================\n",
    "dataset = []\n",
    "\n",
    "for file_name, label in class_files.items():\n",
    "    file_path = os.path.join(dataset_dir, file_name)\n",
    "    try:\n",
    "        # Supondo que cada arquivo seja salvo com torch.save() e contenha um dicionário\n",
    "        # com a chave 'grafos' que é, por exemplo, outro dicionário ou uma lista.\n",
    "        dados = torch.load(file_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar {file_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Dependendo de como os grafos estão salvos, adapte a iteração.\n",
    "    # Se os grafos estiverem armazenados em um dicionário, por exemplo:\n",
    "    if isinstance(dados, dict) and \"grafos\" in dados:\n",
    "        grafos_dict = dados[\"grafos\"]\n",
    "        for exam_id, graph_info in grafos_dict.items():\n",
    "            try:\n",
    "                # Se cada \"graph_info\" for um dicionário com chaves (por exemplo, \"lead_0\")\n",
    "                # você pode escolher qual lead utilizar.\n",
    "                graph = graph_info[\"lead_0\"]\n",
    "            except KeyError:\n",
    "                print(f\"Lead_0 não encontrado para o exam_id {exam_id} em {file_name}. Ignorando.\")\n",
    "                continue\n",
    "\n",
    "            data = Data(\n",
    "                x = graph.x,                 # features dos nós\n",
    "                edge_index = graph.edge_index,  # conectividade\n",
    "                y = torch.tensor(label, dtype=torch.long)\n",
    "            )\n",
    "            data.exam_id = exam_id  # opcional, para referência\n",
    "            dataset.append(data)\n",
    "    # Se os dados já forem uma lista de objetos Data, você pode iterar diretamente\n",
    "    elif isinstance(dados, list):\n",
    "        for data in dados:\n",
    "            # Certifique-se de que cada objeto Data possua os atributos necessários\n",
    "            data.y = torch.tensor(label, dtype=torch.long)\n",
    "            dataset.append(data)\n",
    "    else:\n",
    "        print(f\"Formato dos dados em {file_name} não reconhecido.\")\n",
    "\n",
    "print(f\"Total de amostras no dataset: {len(dataset)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# 3. Dividir o dataset em treino, validação e teste\n",
    "# =============================================================================\n",
    "train_data, temp_data = train_test_split(dataset, test_size=0.30, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.50, random_state=42)\n",
    "\n",
    "print(f\"Número de amostras de treino: {len(train_data)}\")\n",
    "print(f\"Número de amostras de validação: {len(val_data)}\")\n",
    "print(f\"Número de amostras de teste: {len(test_data)}\")\n",
    "\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# =============================================================================\n",
    "# 4. Definir o modelo – arquitetura baseada em GIN para classificação exclusiva\n",
    "# =============================================================================\n",
    "class GINExclusive(nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes, dropout=0.2):\n",
    "        super(GINExclusive, self).__init__()\n",
    "        # Primeira camada GIN\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Linear(num_features, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels)\n",
    "        )\n",
    "        self.conv1 = GINConv(self.mlp1)\n",
    "\n",
    "        # Segunda camada GIN\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels)\n",
    "        )\n",
    "        self.conv2 = GINConv(self.mlp2)\n",
    "\n",
    "        # Terceira camada GIN\n",
    "        self.mlp3 = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels)\n",
    "        )\n",
    "        self.conv3 = GINConv(self.mlp3)\n",
    "\n",
    "        # Camadas finais para converter o embedding global em logits\n",
    "        self.lin1 = nn.Linear(hidden_channels, hidden_channels * 2)\n",
    "        self.bn = nn.BatchNorm1d(hidden_channels * 2)\n",
    "        self.lin2 = nn.Linear(hidden_channels * 2, num_classes)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Agrega os embeddings dos nós de cada grafo em um único vetor\n",
    "        x = global_mean_pool(x, batch)\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        out = self.lin2(x)\n",
    "        return out\n",
    "\n",
    "# Número de classes: 7 (conforme o mapeamento definido)\n",
    "num_classes = 7\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GINExclusive(num_features=3, hidden_channels=64, num_classes=num_classes, dropout=0.2).to(device)\n",
    "\n",
    "# =============================================================================\n",
    "# 5. Preparar treinamento e avaliação\n",
    "# =============================================================================\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_epoch(loader):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * data.num_graphs\n",
    "    return epoch_loss / len(loader.dataset)\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_logits = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            loss = criterion(out, data.y)\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "            all_logits.append(out.cpu())\n",
    "            all_targets.append(data.y.cpu())\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "    return avg_loss, all_logits, all_targets\n",
    "\n",
    "# =============================================================================\n",
    "# 6. Treinar o modelo e plotar as curvas de loss\n",
    "# =============================================================================\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs+1), desc=\"Treinamento\"):\n",
    "    train_loss = train_epoch(train_loader)\n",
    "    val_loss, _, _ = evaluate(val_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label=\"Treino\")\n",
    "plt.plot(range(1, num_epochs+1), val_losses, label=\"Validação\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Curva de Loss de Treino e Validação\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# =============================================================================\n",
    "# 7. Avaliação no conjunto de teste e cálculo do F1 Score\n",
    "# =============================================================================\n",
    "test_loss, test_logits, test_targets = evaluate(test_loader)\n",
    "print(f\"Loss no teste: {test_loss:.4f}\")\n",
    "\n",
    "test_probs = F.softmax(test_logits, dim=1)\n",
    "test_preds = test_probs.argmax(dim=1)\n",
    "\n",
    "test_preds_np = test_preds.numpy()\n",
    "test_targets_np = test_targets.numpy()\n",
    "\n",
    "# Mapeamento dos índices para nomes das classes (para exibição)\n",
    "classes_list = [\"1dAVb\", \"RBBB\", \"LBBB\", \"SB\", \"ST\", \"AF\", \"normal\"]\n",
    "f1_per_class = {}\n",
    "for i, cls in enumerate(classes_list):\n",
    "    f1 = f1_score(test_targets_np == i, test_preds_np == i, zero_division=1)\n",
    "    f1_per_class[cls] = f1\n",
    "\n",
    "print(\"\\nF1 Score por classe:\")\n",
    "for cls in classes_list:\n",
    "    print(f\"{cls}: {f1_per_class[cls]:.4f}\")\n",
    "\n",
    "f1_macro = f1_score(test_targets_np, test_preds_np, average='macro', zero_division=1)\n",
    "print(f\"\\nF1 Macro: {f1_macro:.4f}\")\n",
    "\n",
    "num_examples = 5\n",
    "print(\"\\nExemplos do conjunto de teste:\")\n",
    "for i in range(num_examples):\n",
    "    print(f\"Exemplo {i+1}:\")\n",
    "    print(\"  Rótulo verdadeiro: \", test_targets_np[i])\n",
    "    print(\"  Predição (classe): \", test_preds_np[i])\n",
    "    print(\"  Probabilidades: \", test_probs[i].detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando dataset pré-processado...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_207211/3412674304.py:88: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  dataset = torch.load(PREPROCESSED_PATH)\n",
      "/home/grad/si/24/pedrobacelar.rigueira/miniconda3/envs/eletro/lib/python3.12/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de amostras de treino: 1120\n",
      "Número de amostras de validação: 240\n",
      "Número de amostras de teste: 240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinamento:   4%|▍         | 2/50 [00:23<09:29, 11.87s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 204\u001b[0m\n\u001b[1;32m    201\u001b[0m val_losses \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, num_epochs\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTreinamento\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 204\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m     val_loss, _, _ \u001b[38;5;241m=\u001b[39m evaluate(val_loader)\n\u001b[1;32m    206\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n",
      "Cell \u001b[0;32mIn[13], line 174\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(loader)\u001b[0m\n\u001b[1;32m    172\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m    173\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 174\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    175\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(out, data\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m    176\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/eletro/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/eletro/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[13], line 146\u001b[0m, in \u001b[0;36mGINExclusive.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data):\n\u001b[1;32m    145\u001b[0m     x, edge_index, batch \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index, data\u001b[38;5;241m.\u001b[39mbatch\n\u001b[0;32m--> 146\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m    148\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[0;32m~/miniconda3/envs/eletro/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/eletro/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/miniconda3/envs/eletro/lib/python3.12/site-packages/torch_geometric/nn/conv/gin_conv.py:90\u001b[0m, in \u001b[0;36mGINConv.forward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m x_r \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     88\u001b[0m     out \u001b[38;5;241m=\u001b[39m out \u001b[38;5;241m+\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meps) \u001b[38;5;241m*\u001b[39m x_r\n\u001b[0;32m---> 90\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m(out)\n",
      "File \u001b[0;32m~/miniconda3/envs/eletro/lib/python3.12/site-packages/torch/nn/modules/module.py:1918\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1909\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;241m=\u001b[39m OrderedDict()\n\u001b[1;32m   1911\u001b[0m \u001b[38;5;66;03m# On the return type:\u001b[39;00m\n\u001b[1;32m   1912\u001b[0m \u001b[38;5;66;03m# We choose to return `Any` in the `__getattr__` type signature instead of a more strict `Union[Tensor, Module]`.\u001b[39;00m\n\u001b[1;32m   1913\u001b[0m \u001b[38;5;66;03m# This is done for better interop with various type checkers for the end users.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[38;5;66;03m# See full discussion on the problems with returning `Union` here\u001b[39;00m\n\u001b[1;32m   1917\u001b[0m \u001b[38;5;66;03m# https://github.com/microsoft/pyright/issues/4213\u001b[39;00m\n\u001b[0;32m-> 1918\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1919\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m:\n\u001b[1;32m   1920\u001b[0m         _parameters \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__dict__\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, GINConv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "##############################################\n",
    "# Função para extrair subgrafo (nós 1000 a 2000)\n",
    "##############################################\n",
    "def extract_subgraph(data, start=1000, end=2000):\n",
    "    num_nodes = data.x.shape[0]\n",
    "    if num_nodes < end:\n",
    "        return data  # Retorna o grafo completo se não houver nós suficientes\n",
    "\n",
    "    node_indices = torch.arange(start, end)\n",
    "    new_x = data.x[node_indices]\n",
    "    \n",
    "    edge_index = data.edge_index\n",
    "    mask = (edge_index[0] >= start) & (edge_index[0] < end) & (edge_index[1] >= start) & (edge_index[1] < end)\n",
    "    new_edge_index = edge_index[:, mask] - start\n",
    "    \n",
    "    new_data = Data(x=new_x, edge_index=new_edge_index)\n",
    "    if hasattr(data, \"y\"):\n",
    "        new_data.y = data.y\n",
    "    if hasattr(data, \"exam_id\"):\n",
    "        new_data.exam_id = data.exam_id\n",
    "    return new_data\n",
    "\n",
    "##############################################\n",
    "# Pré-processamento do dataset\n",
    "##############################################\n",
    "def preprocess_dataset(PATH_GRAFOS, PATH_EXAMS, save_path=\"preprocessed_dataset.pt\"):\n",
    "    # Carregar grafos e CSV\n",
    "    dados_grafos = torch.load(PATH_GRAFOS)\n",
    "    grafos_dict = dados_grafos[\"grafos\"]\n",
    "    exams_df = pd.read_csv(PATH_EXAMS)\n",
    "\n",
    "    # Função para criar rótulo (exclusivo)\n",
    "    def get_label(row):\n",
    "        classes = [\"1dAVb\", \"RBBB\", \"LBBB\", \"SB\", \"ST\", \"AF\"]\n",
    "        values = row[classes].values.astype(bool)\n",
    "        return int(np.argmax(values)) if values.sum() == 1 else 6\n",
    "\n",
    "    exams_df[\"label_idx\"] = exams_df.apply(get_label, axis=1)\n",
    "    \n",
    "    dataset = []\n",
    "    chaves_grafos = list(grafos_dict.keys())\n",
    "    for exam_id in chaves_grafos:\n",
    "        exam_rows = exams_df[exams_df[\"exam_id\"] == int(exam_id)]\n",
    "        if exam_rows.empty:\n",
    "            continue\n",
    "        exam_info = exam_rows.iloc[0]\n",
    "        label = get_label(exam_info)\n",
    "        try:\n",
    "            grafo_lead0 = grafos_dict[exam_id][\"lead_0\"]\n",
    "        except KeyError:\n",
    "            continue\n",
    "        data = Data(\n",
    "            x = grafo_lead0[\"node_features\"],\n",
    "            edge_index = grafo_lead0[\"edge_index\"],\n",
    "            y = torch.tensor(label, dtype=torch.long)\n",
    "        )\n",
    "        data.exam_id = exam_id\n",
    "        # Extrai somente nós de 1000 a 2000\n",
    "        sub_data = extract_subgraph(data, start=1000, end=2000)\n",
    "        if sub_data.x.shape[0] == data.x.shape[0]:\n",
    "            print(f\"Exame {exam_id}: grafo possui menos de 2000 nós. Usando grafo completo.\")\n",
    "        dataset.append(sub_data)\n",
    "    print(f\"Total de amostras pré-processadas: {len(dataset)}\")\n",
    "    torch.save(dataset, save_path)\n",
    "    return dataset\n",
    "\n",
    "##############################################\n",
    "# Carregar ou pré-processar o dataset\n",
    "##############################################\n",
    "PREPROCESSED_PATH = \"preprocessed_dataset.pt\"\n",
    "if os.path.exists(PREPROCESSED_PATH):\n",
    "    print(\"Carregando dataset pré-processado...\")\n",
    "    dataset = torch.load(PREPROCESSED_PATH)\n",
    "else:\n",
    "    print(\"Pré-processando o dataset...\")\n",
    "    PATH_GRAFOS = \"/scratch/pedro.bacelar/Clustering-Paper/Grafo/dataset/ecg_visibility_graphs_by_id.pt\"\n",
    "    PATH_EXAMS = \"/scratch/pedro.bacelar/Clustering-Paper/Projeto/Database/exams.csv\"\n",
    "    dataset = preprocess_dataset(PATH_GRAFOS, PATH_EXAMS, save_path=PREPROCESSED_PATH)\n",
    "\n",
    "##############################################\n",
    "# Dividir o dataset em treino, validação e teste\n",
    "##############################################\n",
    "train_data, temp_data = train_test_split(dataset, test_size=0.30, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.50, random_state=42)\n",
    "\n",
    "print(f\"Número de amostras de treino: {len(train_data)}\")\n",
    "print(f\"Número de amostras de validação: {len(val_data)}\")\n",
    "print(f\"Número de amostras de teste: {len(test_data)}\")\n",
    "\n",
    "##############################################\n",
    "# Criar DataLoaders com num_workers (para paralelismo)\n",
    "##############################################\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "##############################################\n",
    "# (Resto do código: definição do modelo, treinamento e avaliação)\n",
    "##############################################\n",
    "\n",
    "# Exemplo: modelo de classificação com GIN para classes exclusivas (7 classes)\n",
    "class GINExclusive(nn.Module):\n",
    "    def __init__(self, num_features, hidden_channels, num_classes, dropout=0.2):\n",
    "        super(GINExclusive, self).__init__()\n",
    "        self.mlp1 = nn.Sequential(\n",
    "            nn.Linear(num_features, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels)\n",
    "        )\n",
    "        self.conv1 = GINConv(self.mlp1)\n",
    "        self.mlp2 = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels)\n",
    "        )\n",
    "        self.conv2 = GINConv(self.mlp2)\n",
    "        self.mlp3 = nn.Sequential(\n",
    "            nn.Linear(hidden_channels, hidden_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_channels, hidden_channels)\n",
    "        )\n",
    "        self.conv3 = GINConv(self.mlp3)\n",
    "        self.lin1 = nn.Linear(hidden_channels, hidden_channels * 2)\n",
    "        self.bn = nn.BatchNorm1d(hidden_channels * 2)\n",
    "        self.lin2 = nn.Linear(hidden_channels * 2, num_classes)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.conv3(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.lin1(x)\n",
    "        x = self.bn(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        out = self.lin2(x)\n",
    "        return out\n",
    "\n",
    "num_classes = 7\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GINExclusive(num_features=3, hidden_channels=64, num_classes=num_classes, dropout=0.2).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_epoch(loader):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item() * data.num_graphs\n",
    "    return epoch_loss / len(loader.dataset)\n",
    "\n",
    "def evaluate(loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    all_logits = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            data = data.to(device)\n",
    "            out = model(data)\n",
    "            loss = criterion(out, data.y)\n",
    "            total_loss += loss.item() * data.num_graphs\n",
    "            all_logits.append(out.cpu())\n",
    "            all_targets.append(data.y.cpu())\n",
    "    avg_loss = total_loss / len(loader.dataset)\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "    all_targets = torch.cat(all_targets, dim=0)\n",
    "    return avg_loss, all_logits, all_targets\n",
    "\n",
    "num_epochs = 50\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in tqdm(range(1, num_epochs+1), desc=\"Treinamento\"):\n",
    "    train_loss = train_epoch(train_loader)\n",
    "    val_loss, _, _ = evaluate(val_loader)\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, num_epochs+1), train_losses, label=\"Treino\")\n",
    "plt.plot(range(1, num_epochs+1), val_losses, label=\"Validação\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Curva de Loss de Treino e Validação\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "test_loss, test_logits, test_targets = evaluate(test_loader)\n",
    "print(f\"Loss no teste: {test_loss:.4f}\")\n",
    "test_probs = F.softmax(test_logits, dim=1)\n",
    "test_preds = test_probs.argmax(dim=1)\n",
    "\n",
    "test_preds_np = test_preds.numpy()\n",
    "test_targets_np = test_targets.numpy()\n",
    "classes_list = [\"1dAVb\", \"RBBB\", \"LBBB\", \"SB\", \"ST\", \"AF\", \"normal\"]\n",
    "f1_per_class = {}\n",
    "for i, cls in enumerate(classes_list):\n",
    "    f1 = f1_score(test_targets_np == i, test_preds_np == i, zero_division=1)\n",
    "    f1_per_class[cls] = f1\n",
    "\n",
    "print(\"\\nF1 Score por classe:\")\n",
    "for cls in classes_list:\n",
    "    print(f\"{cls}: {f1_per_class[cls]:.4f}\")\n",
    "f1_macro = f1_score(test_targets_np, test_preds_np, average='macro', zero_division=1)\n",
    "print(f\"\\nF1 Macro: {f1_macro:.4f}\")\n",
    "\n",
    "num_examples = 5\n",
    "print(\"\\nExemplos do conjunto de teste:\")\n",
    "for i in range(num_examples):\n",
    "    print(f\"Exemplo {i+1}:\")\n",
    "    print(\"  Rótulo verdadeiro: \", test_targets_np[i])\n",
    "    print(\"  Predição (classe): \", test_preds_np[i])\n",
    "    print(\"  Probabilidades: \", test_probs[i].detach().numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "condaclustering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
