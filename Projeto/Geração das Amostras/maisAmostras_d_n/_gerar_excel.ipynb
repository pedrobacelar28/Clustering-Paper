{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "import os\n",
    "import h5py\n",
    "import ecg_plot\n",
    "import matplotlib.pyplot as plt\n",
    "from openpyxl.worksheet.datavalidation import DataValidation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erros:  56\n",
      "Tamanho inicial: 56\n",
      "Tipos das duplicatas removidas:\n",
      "Empty DataFrame\n",
      "Columns: [exam_id, normal_ecg]\n",
      "Index: []\n",
      "Tamanho depois de remover duplicatas: 56\n"
     ]
    }
   ],
   "source": [
    "# CARREGAR IDS\n",
    "erros = pd.read_csv('_erros.csv')\n",
    "\n",
    "print('Erros: ', erros.shape[0])\n",
    "\n",
    "dados_selecionados = erros.sort_values(by=['exam_id'], ascending=True)\n",
    "print('Tamanho inicial:', dados_selecionados.shape[0])\n",
    "\n",
    "dados_selecionados.to_csv('_teste.csv', index = 0)\n",
    "\n",
    "duplicatas = dados_selecionados[dados_selecionados.duplicated(subset='exam_id', keep='first')]\n",
    "\n",
    "print('Tipos das duplicatas removidas:')\n",
    "print(duplicatas[['exam_id'  ,'normal_ecg'  ]])\n",
    "\n",
    "dados_selecionados = dados_selecionados.drop_duplicates(subset='exam_id')\n",
    "print('Tamanho depois de remover duplicatas:', dados_selecionados.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo Excel 'parte_1.xlsx' salvo com sucesso.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\luisa\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "# SALVAR IDS EM EXCEL \n",
    "ids = dados_selecionados['exam_id'].tolist()\n",
    "ids = pd.DataFrame({\n",
    "    'exam_id': ids,\n",
    "    'doenca': [''] * len(ids),\n",
    "    'borderline': [''] * len(ids),\n",
    "    'comentario': [''] * len(ids) \n",
    "})\n",
    "\n",
    "num_parts = 1\n",
    "split_dfs = np.array_split(ids, num_parts)\n",
    "\n",
    "for i, df_part in enumerate(split_dfs):\n",
    "    excel_path = f'parte_{i+1}.xlsx'\n",
    "    df_part.to_excel(excel_path, index=False)\n",
    "    print(f\"Arquivo Excel '{excel_path}' salvo com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validação de dados adicionada e arquivo salvo com sucesso.\n"
     ]
    }
   ],
   "source": [
    "excel_path = f'parte_1.xlsx'\n",
    "\n",
    "# Adicionar validação de dados para a coluna 'doenca'\n",
    "wb = load_workbook(excel_path)\n",
    "ws = wb.active\n",
    "\n",
    "# Criar uma lista de opções para a validação de dados na coluna 'doenca'\n",
    "doenca_options = ['ST', 'SB', 'AF', 'LBBB', 'RBBB', '1dAVB', 'Outra', 'Nenhuma', 'Interferência']\n",
    "doenca_dv = DataValidation(type=\"list\", formula1=f'\"{\",\".join(doenca_options)}\"', showDropDown=True)\n",
    "\n",
    "# Criar uma lista de opções para a validação de dados na coluna 'borderline'\n",
    "borderline_options = ['Sim', 'Não']\n",
    "borderline_dv = DataValidation(type=\"list\", formula1=f'\"{\",\".join(borderline_options)}\"', showDropDown=True)\n",
    "\n",
    "# Adicionar a validação às colunas apropriadas\n",
    "for row in range(2, len(ids) + 2):   # Começa na linha 2 para pular o cabeçalho\n",
    "    doenca_cell = ws[f'B{row}']      # Coluna B para 'doenca'\n",
    "    borderline_cell = ws[f'C{row}']  # Coluna C para 'borderline'\n",
    "    \n",
    "    ws.add_data_validation(doenca_dv)\n",
    "    ws.add_data_validation(borderline_dv)\n",
    "    \n",
    "    doenca_dv.add(doenca_cell)\n",
    "    borderline_dv.add(borderline_cell)\n",
    "\n",
    "# Salvar o arquivo com a validação de dados\n",
    "wb.save(excel_path)\n",
    "print(\"Validação de dados adicionada e arquivo salvo com sucesso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "for i, df_part in enumerate(split_dfs):\n",
    "    print(df_part.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sucesso: exame ID 144629 salvo.\n",
      "Sucesso: exame ID 177690 salvo.\n",
      "Sucesso: exame ID 255536 salvo.\n",
      "Sucesso: exame ID 321228 salvo.\n",
      "Sucesso: exame ID 385667 salvo.\n",
      "Sucesso: exame ID 483034 salvo.\n",
      "Sucesso: exame ID 485287 salvo.\n",
      "Sucesso: exame ID 489846 salvo.\n",
      "Sucesso: exame ID 629566 salvo.\n"
     ]
    }
   ],
   "source": [
    "def create_folders(base_path, num_folders):\n",
    "    for i in range(num_folders):\n",
    "        folder_path = os.path.join(base_path, f'parte_{i+1}')\n",
    "        os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "def plot_and_save_ecgs(split_dfs, arquivos_hdf5, base_path):\n",
    "    create_folders(base_path, len(split_dfs))\n",
    "\n",
    "    # ESCOLHA AQUI QUAL ARTE PROCESSAR (0-3)\n",
    "    i = 0\n",
    "    df_part = split_dfs[i]\n",
    "    folder_path = os.path.join(base_path, f'parte_{i+1}')\n",
    "    exam_ids_to_plot = df_part['exam_id'].tolist()\n",
    "    \n",
    "    for exam_id in exam_ids_to_plot:\n",
    "        found = False  \n",
    "        for arquivo in arquivos_hdf5:\n",
    "            try:\n",
    "                with h5py.File(arquivo, 'r') as f:\n",
    "                    exam_ids = np.array(f['exam_id'])\n",
    "                    exam_index = np.where(exam_ids == exam_id)[0]\n",
    "\n",
    "                    if len(exam_index) == 0:\n",
    "                        continue\n",
    "                    else:\n",
    "                        exam_index = exam_index[0]\n",
    "                        exam_tracings = f['tracings'][exam_index]\n",
    "                        ecg = np.array(exam_tracings).T\n",
    "                        ecg_plot.plot(ecg, sample_rate=400,\n",
    "                            lead_index=['DI', 'DII', 'DIII', 'AVR', 'AVL', 'AVF', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6'], style='bw')\n",
    "                        # rm ticks\n",
    "                        plt.tick_params(\n",
    "                            axis='both',  # changes apply to the x-axis\n",
    "                            which='both',  # both major and minor ticks are affected\n",
    "                            bottom=False,  # ticks along the bottom edge are off\n",
    "                            top=False,  # ticks along the top edge are off\n",
    "                            left=False,\n",
    "                            right=False,\n",
    "                            labelleft=False,\n",
    "                            labelbottom=False)  # labels along the bottom edge are off\n",
    "                        plt.savefig(os.path.join(folder_path, f'{exam_id}.png'), dpi=550)\n",
    "                        plt.close()\n",
    "                        found = True\n",
    "                        break\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar o arquivo {arquivo} para o exam ID {exam_id}: {e}\")\n",
    "\n",
    "        if not found:\n",
    "            print(f\"Erro: exame ID {exam_id} não encontrado em nenhum dos arquivos.\")\n",
    "        if found:\n",
    "            print(f\"Sucesso: exame ID {exam_id} salvo.\")\n",
    "\n",
    "base_path = 'imagens'\n",
    "\n",
    "arquivos_hdf5 = [\n",
    "    \"../../Database/filtered_exams_0_1.hdf5\", \"../../Database/filtered_exams_2_3.hdf5\",\n",
    "    \"../../Database/filtered_exams_4_5.hdf5\", \"../../Database/filtered_exams_6_7.hdf5\",\n",
    "    \"../../Database/filtered_exams_8_9.hdf5\", \"../../Database/filtered_exams_10_11.hdf5\",\n",
    "    \"../../Database/filtered_exams_12_13.hdf5\", \"../../Database/filtered_exams_14_15.hdf5\",\n",
    "    \"../../Database/filtered_exams_16_17.hdf5\"\n",
    "]\n",
    "\n",
    "plot_and_save_ecgs(split_dfs, arquivos_hdf5, base_path)\n",
    "\n",
    "print(\"Processo completo!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
